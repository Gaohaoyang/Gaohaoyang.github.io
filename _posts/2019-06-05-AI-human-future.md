---
layout: post
title:  "人工智能及未来畅想"
date:   2019-06-04 23:41:00
categories: 人工智能
tags: 人工智能 AI 人类简史 人文 哲学 康德 汉字屋 清华大学 天机 自行车 AGI 类脑 类机
excerpt: 深度思考
mathjax: true
---

* content
{:toc}


> * 全文地址：[【完整版】人类唯一的出路：变成人工智能](https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&mid=2649768466&idx=1&sn=b6b1720b7a2243ab3907c58d2b22a602&chksm=bec3df0f89b456198c4960da99e46075f2bef121320f52a805b19f9143f5c083f6bac9430e97&token=832591528&lang=zh_CN#rd)
> * 原文地址：[英文版-
Neuralink and the Brain’s Magical Future](https://waitbutwhy.com/2017/04/neuralink.html)
> * Word文档版：[腾讯文档](https://share.weiyun.com/5y4D89d)

- ![](https://28oa9i1t08037ue3m1l0i861-wpengine.netdna-ssl.com/wp-content/uploads/2015/03/Logo-sometimes-Pixelmator-577.png)

# 人类唯一的出路：变成人工智能
Tim Urban，之前火热的文章《为什么有很多名人让人们警惕人工智能》也是出自他手，英文原文刊载于waitbutwhy.com，点击文末的阅读原文可以跳转到原文链接。
>Wait but Why的作者Tim Urban 是埃隆马斯克（特斯拉/SpaceX创始人）强烈推荐的科技博主。他写的AI文章是全世界转发量最高的。他的粉丝还包括：Facebook创始人马克扎克伯格，Facebook COO谢丽桑伯格等。Tim也是TED演讲平台上有史以来最受欢迎的演讲者之一

在一个由人工智能和“其他所有生物”组成的未来， 人类只有一条出路：“变成人工智能。

本翻译版本由谢熊猫君提供，全文共六万字。两百余张图片，分成六个章节，将分成五篇推送完成。
- 第一章：人类巨灵 （约7000字）简述人类语言、智能和人类巨灵的崛起
- 第二章：大脑 （约8000字）简述大脑结构，为了解脑机接口提供基础知识
- 第三章：脑机接口（约12000字）讲述脑机接口的基本原理和目前的技术水平
- 第四章：挑战（约8000字）讲述目前脑机接口跨越到全脑接口所要面临的挑战
- 第五章：魔法纪元（约13000字）全脑接口实现后未来的人类会是怎样
- 第六章：大融合（约10000字）人类唯一的出路：变成人工智能

注：原文请看:[【完整版】人类唯一的出路：变成人工智能](https://mp.weixin.qq.com/s?__biz=MjM5ODY2OTQyNg==&mid=2649768466&idx=1&sn=b6b1720b7a2243ab3907c58d2b22a602&chksm=bec3df0f89b456198c4960da99e46075f2bef121320f52a805b19f9143f5c083f6bac9430e97&token=832591528&lang=zh_CN#rd)
 
# 人工智能哲学笔记

- 【2019-10-24】[人工智能哲学笔记](https://yam.gift/2018/04/07/2018-04-07-AI-Philosophy-Note/)

## 背景
- 来源：[复旦大学公开课：人工智能哲学_全 7 集_网易公开课](http://open.163.com/special/cuvocw/rengongzhinengzhexue.html)
- 讲师：徐英瑾教授
- 课程介绍：本课程从人工智能科学发展的科学史概要出发，讨论了哲学思辨和人工智能研究之间的密切关系，并从人工智能的角度，重新审视了近代欧洲哲学对于 “机器是否能够思维” 这个问题的思辨结论。尔后，讨论了如何从当代计算机科学的角度来解读康德哲学，并从中得到一个关于类比推理的计算模型。本课程也讨论了当代美国哲学家塞尔对于 “计算模型如何获得关于符号的语义知识” 的忧虑，并进一步探讨了这一忧虑在计算机科学内部的表达形式：框架问题。

## 为何人工智能科学需要哲学的参与
哲学研究的特点：
- 思考大问题，澄清基本概念。
- 在不同学科的研究成果之间寻找汇通点，而不受某一具体学科视野之局限。
- 重视论证和辩护，相对轻视证据的约束。

就对哲学文化的宽容度而言，AI 就是自然科学界的一个艺术。AI 是头脑风暴的产物。
- 先导者：阿兰·图灵
   - 1950 年 Mind 杂志发表的《计算机器和智能》提出了著名的 “图灵测验”。
   - 行为主义的哲学思想，对外在心灵的判断仅仅是通过外部表现行为来判断，而不是内在活动。
- 美国达特茅斯学院关于计算机实现人类智能的会议
   - 1956 年，会议筹备期间，麦卡锡发明了 Artificial Intelligence 这个词，人工智能学科诞生。还有明斯基、纽厄尔、西蒙等大牛。
   - 会议讨论的子课题：自然语言处理、人工神经元网络、计算理论以及机器的创造性等。

为什么 AI 有哲学维度？
- AI 必须对 “何为智能” 这个问题做出解答。然而，不同的解答往往会导致不同的技术路径。
   - 未雨绸缪，知道的足够多，有很多解决方案：专家系统
   - 人工大脑，对于人工大脑的模拟中，出现了人工神经元这门技术，就是对于人类的神经元网络进行数字模拟，然后在此基础上，希望被模拟出来的系统能够具有人类神经元系统的特点。
   - 行为主义，智能是黑箱，只要找到输入和输出的映射关系就是智能。
- AI 科学研究与一般科学研究相比，缺乏删除不同理论假设的决定性的判定例。AI 科学家一般不做实验，而只做试验，就这一点而言，这么学科似乎更像是工科，而不是理科。
- 关于智能、人类的思维是什么哲学思考的最多。另外，AI 所关注的思维结构某种意义上必须具有抽象性，因为它横跨人和机器，哲学家所提供的那种抽象思维方式也许更有用。
- 不成熟学科，哲学容易参与。

历史层面证明哲学强的国家对 AI 也有反哺作用
- 美欧对比
   - 美国进行 AI 研究的优点：资金充裕，科研机制有活力，哲学和科学互动频繁。
   - 欧洲：财力、体制（如德国的哲学研究偏向人文经典的解读，使得哲学研究难以对当下的热点问题作出及时回应；文理分科问题比较严重；跨学科研究支持力度相对小）等。
- 日本
   - 日本 AI 研究的特点：日本的经济结构不是一个纯粹的西式的自由主义的体系。重大科研项目由政府牵头，集中力量攻关。和我们的思维很像。
   - 日本研究第五代计算机（自然语言处理，听懂 90%+ 的日语）失败的主要原因：看到了 AI 建构的工程学面相，却没有看到其背后的哲学难题（如什么是智能）。
- 前苏联
   - 苏联 AI 研究落后的原因：第一，苏联官方缺乏 AI 研究方面的远见；第二，苏联官方意识形态对于马克思主义的曲解（“人工智能是独立人脑，能够独立产生智慧和生产力” 违背了 “机器只能转移价值不能生产价值” 的观点）。我们的今天的科研体制很大程度上仍然受苏联的影响。
   - 对维纳控制论的反对和赞成也都是站在政治图解的思维里。
   - 归根结底，是对马克思主义做了教条主义的理解，哲学仅仅是意识形态的工具，而不会对实际的工程学研究产生任何积极的思想。
- 中国 AI 研究存在的问题：
   - 长期跟风研究，缺乏真正系统的原创性思维。
   - 注重模仿，轻视原理；缺乏哲学兴趣。
   - 跨学科研究缺乏体制保障。

AI 是科学和工程学的一种奇妙结合，它并不以描述自然为终极目的，而以制造出合乎人类需要的智能机器为工作目标。所以对于如何实现这种目标，如何理解这种目标，AI 本身就具有一个比较大的宽容度，而这种宽容度是使得它能够和哲学相互交流的一个契机。

## 近代欧洲哲学与人工智能

### 希腊文明对 AI 的滋养

- 德谟克利特
   - 受 “机械唯物主义” 影响。
   - “灵魂原子” 只是比别的原子更为精微和灵活而已，并非在本体论上自成一类的对象。
- 毕达哥拉斯
   - 明确把 “数” 视为世界的本原，这就为后世科学对数学语言（以及一般意义上的形式语言）的推崇下了大调子。
- 苏格拉底和柏拉图
   - 对自然语义的歧义进行澄清，然后通过找定义的方式对我们所说的很多概念加以清楚厘定。
   - 自然语言直觉中以为掌握的概念经过哲学反思后发现都不正确，所以要找到精确的泛型，什么东西都要形式化（对问题形式定义）。比如应用题，从 “自然语言” 的描述中得出一个 形式的数学的模型。
- 为什么机器智能的想法没有在古希腊出现
   - 在古希腊人那里，机械唯物主义和形式主义传统基本上还是两个路子，而没有机会在同一个思想体系中得到整合。
   - 心智理论的构建还不是古希腊哲学家的核心关涉，而只是其形而上学理论的一个运用领域。
   - 奴隶制的社会条件下，人工机械的发展水平有限。

### 近代哲学

- 条件发生了变化
   - 知识、人性、理解问题，促进对人类的心智进行思考。
   - 伽利略导致的物理学革命，形式和物理结合。
   - 各种机械日益精进，对机械系统潜力的乐观估计
- 笛卡尔和莱布尼茨
   - 表象（唯理派，传统像符号 AI 重视数理和一般意义上的科学研究）看他们是支持人工智能，其实不是。
      - 理性派认为直觉、经验只不过是改头换面的推理，归根结底一切都是推理。
      - 唯理派认为任何心智活动的实质是符号表征层面上的推理活动；符号 AI 认为任何符号表征层面上的推理活动就是心智活动。
      - 计算机先驱不一定支持人工智能，计算机技术和人工智能是两个不同的东西。
   - 笛卡尔是二元论者，即认为人是占据广延的物质实体和不占据广延的灵魂实体的复合体。智能和灵魂有关，灵魂不能还原为物质，智能是灵魂的一部分，智能不能还原成物质，所以物质的配置形式不可能构造出灵魂的配置形式。
   - 笛卡尔《方法谈》对人工智能正面的讨论（机器智能不可能）：它们不会使用语言和记号，或者不会像我们那样组织。它们在特定领域工作，不会学习。
      - 从 “机器能够表达词语” 出发，我们推不出 “机器能够根据环境的变化而调整语义输出策略”。（反驳：现在的 AI 已经很聪明了）
      - 如果我们真的要做出一台 “智能” 机器的话，我们就需要把所有的问题解决策略预存在其内置方法库中，但在实践上这是不可能的。
   - 莱布尼茨《单子论》
   - 磨坊论证：知觉以及依赖知觉的东西不能用机械的理由来解释，不能用形状和运动来解释，不能用广延的东西来解释。
   - 一个智能体放大，发现零件推动，找不到知觉。机器不能有知觉，所以没有机器智能。（反驳：看不到不等于就没有，比如放大大脑，大脑在知觉时，我们是看不到知觉的，只能看到神经元和电脉冲。再比如灰尘看电视机的画面也是看不到的。）
   - 空间中就不存在单子。
- 霍布斯《利维坦》
   - 所有人类的理智活动归根结底都是一种形式符号的运算。
   - 我们都是理性动物，可以做各种计算。
   - 与物理系统假设想和：对于展现一个一般的智能行动来说，一个物理符号系统具有必要的和充分的手段。物理系统不聪明，只是没有找到好的编程方法。
- 休谟
   - 理性没有什么原则，仅仅是一种习惯。
   - 习惯的根基在于感官经验，而不是在于一些理性的讨论。
   - 核心术语
      - 印象：接近于感官
      - 观念：接近于符号
      - 感觉：中间的东西
   - 习惯实际上是一种统计学机制
   - 联结主义：输入层是印象，中间层是感觉，输出层是观念。每一个神经元都不知道自己在干嘛，是整个 network 在处理，没有很清楚的规则来让它进行推理。
> 习惯是统计学机制，根据维特根斯坦的结论，是否应该将 “习惯” 作为逻辑命题（从习惯、数据中提取规则），而将例外情况作为经验命题？

## 康德、类比推理和 “照猫画虎”

### 康德

- 认为唯理派和经验派对人类认知的看法都有所偏颇，经验派比较重视怎么样从感觉的经验材料出发一步步把符号表征加工出来；唯理派认为感知经验不重要，我们在先天观念的帮助下构成知识。康的认为：概念的能力+直观的能力 = 知识
- 侯世达（美国计算机科学家 Douglas Richard Hofstadter）和他的学生查尔莫斯（澳大利亚哲学家 David John Chalmeres）的 “照猫画虎”
   - 1992 High-level perception representation and analogy: A critique of artificial intelligence
   - 这篇文章是受到康德的影响写出来的：很早人们就知道直觉活动是在不同层面上进行的。康德将心智的直觉活动划分为两个板块：其一是感性能力，其任务是拣选出那些感官信息的原始输入，其二是知性能力，其任务是致力于把这些输入材料整理成一个融贯的、富有意义的世界经验。
- 康德：自下而上的感性能力和自上而下的知性能力的综合。
- Why 康德：
   - if 休谟：人类知识从感官来，那很难说感官经验里得到的信息最后是怎么具有知识的普遍性必然性的。永远面临对知识的普遍性和合法性进行辩护的难题。
   - if 莱布尼茨、沃尔夫：认为知识只和先天观念和先天范畴相关，和经验不相关，就会面临：怎么说明知识和经验世界之间的关系，怎么保证知识不是从书斋里幻想出来的。
   - “自下而上” 与 “自上而下” 两条道路在康德那里整合的根本原因：他既要保证知识在经验中有它的用途，又要保证知识有它的普遍必然性，他就觉得要把两者的优点结合在一起。
   
### 类比推理

人工智能专家不考虑上面哲学家说的问题，他们作为工程师的思维：
   - 尝试不同方法，能搞定的就是好方法。
   - 要拿一件足够有说服力的事情，就是做类比思维的计算机模拟，看哪种方法好。
   - 类比思维在人类日常思维中非常有用的一种思维。即以旧推新。类比思维有时候有效，有时候无效；因为人类碰到的很多新情况和旧情况相比完全不同。

哲学家用语言描述有歧义，计算机模拟要写成程序，是确定的。人工智能使得哲学家变得诚实。——丹尼尔·丹尼特

例子：孔明之于（），可类比与管仲之于（）。A.张飞；B.刘备；C.董卓；D.貂蝉；E.齐桓公。
- if 休谟：看习惯，即已有数据中的共现关系（统计学方法）。
- 统计学的策略有两个根本缺陷：
   - 很多对问题求解有用的新类比关系，往往是缺乏统计数据支持的。没有主动修正过去实际的能力。比如搜狗的热词。
   - 对于系统输入历史的这种高度依赖性，将大大削弱系统对于输入信息的主动鉴别能力。
- if 霍布斯主义者：预先要求我们把所有概念说成很清楚的含义（各种属性和关系），系统就找里面的类比物。孔明-刘备 与 管仲-齐桓公 之间有共同模板。
- 如何在关系中找到共同模板？
   - 计算量太大（如果每个概念的属性很多时）
   - 从康德那里得到启发，建立从高到低和从低到高两种检索，有了 “照猫画虎”

### 照猫画虎

在大量数据（如字符串 abc iijjkk）中找到类比关系
   - abc：两个后继性标签
   - iijjkk：三个同一性标签，两个后继性标签
   - abc 与 iijjkk 都有两个后继性标签，abc 可以类比于 iijjkk

![](http://qnimg.lovevivian.cn/course-pyilosophy-ai2.jpeg)

为了做成这个事情，系统需要的配置：
   - 人工的感性能力：对短码的解读能力。在例子中就是表征 abc iijjkk。
   - 人工想象力：在康德的心智理论中，“想象力” 是介于 “感性” 和 “知性” 之间的一种能力，其任务是对感官输入进行初步处理，以便为知性的高级操作做准备。在例子中就是给 iijjkk 贴标签这个事情，知性就是对这些标签进行一个评估。

例子：看立方体，一次只能看到三个面，但我们知道有六个面，是个立方体。把握立方体的过程就是感性和知性相互协调工作的一个过程，感觉的最基本的能力会在我们看到三个面时抓到一些碎片的特征（如顶点的形状），然后慢慢整合出全面的情况，知性告诉我们这是一个立方体。但是我们不知道哪里是分界。
- 人工范畴表：康德心目中的知性范畴表，大致对应于 “照猫画虎” 程序中的 “滑移网（slipnet）”。基本的思维框架，比如刚刚的：同一性、后继性。再比如：因果性。
- 感性（康德：时间和空间的把控能力，前后就是一种时间关系）会唤醒想象力，想象力会产生很多图形，它告诉你整个认知构架因果范畴的一个感性图形就是时间上的前后相续。在想象力这个中介的帮助下，信息传到了 ”范畴“ 这个更上面的网络了，时间先后关系被唤醒了，所以因果关系也就出来了，它出来后会把更多的注意力注意到前后相续这件事情上，按照因果范畴这样的眼光来看待前后两件事情，其他范畴暂不工作。

例子：斥候相当于感性，司令部相当于知性范畴（佯攻、主攻、投降等等），参谋整合和情报分析相当于想象力。
- 信息的传播是双向的：从底层往上、从上层往下。上面听到下面有个整合的过程，整合完才传到下面。休谟的哲学就是只听下面的，莱布尼茨的哲学就是下面的是机器人。康德的哲学就是上下有灵活的互动。

![](http://qnimg.lovevivian.cn/course-philosophy-ai-3.jpeg)

康德：概念无直观则空，直观无概念则盲。 VS 照猫画虎：滑移网无短码算子则空，短码算子无滑移网则盲。

局限性：
   - 只是在高度模拟（对基本的字母代码进行类比运算），应该在各个感官上全面复制康德对于时间、空间或知性范畴的所有想法。

总结：康德的哲学描述平移到可以操作的、可以编程的工程学层面指导具体工作。不是哲学的问题，而是搞哲学的人的问题，不具备跨学科的能力。

>这块内容和深度神经网络非常类似，从底层传递到高层，再从高层反馈至底层。
有一点需要特别注意，在高层，注意力应该根据任务不同而放到不同的抽象关系上，而不是所有的。
是不是可以把无监督的抽象信息（或者其他方式获取的抽象的关系，比如词性）替换为现有的 Attention（现有的 Attention 其实并不是注意力，而更像是 Memory）呢？

## 汉字屋论证

汉字屋是用来反对人工智能的可能性的一个非常重要的哲学论证。
《心灵大脑与程序》中提出，该论证的重要的一个概念前提就是对强 AI 和弱 AI 的区分。

### 塞尔
塞尔对于强 AI 和弱 AI 的区分：
   - “强人工智能” 这种观点认为 “计算机不仅仅是人们用来研究心灵的一种工具，而且，被恰当编程的计算机本身就是一个心灵。”
   - 直观非常不靠谱，经常引导我们走入思想的泥潭。
   - “弱人工智能” 认为计算机至多只能够成为人们研究心灵的一种工具，或是对心智活动的一种抽象模拟。

塞尔论证的框架：
   - 大前提：每一种真正的心灵或智能都必须有能力在符号与对象之间建立起一种语义关系。
   - 小前提：这种语义关系无法仅仅通过任何一台被恰当编程的计算机所获取。
   - 结论：计算机本身不可能具有真正的心灵，因此强 AI 无法实现。
   
塞尔的汉字屋实验是用来证明小前提的。实际上是一种 ”思想实验“。
- 思想实验：指的是使用想象力去进行的实验，所做的都是在现实中无法做到或现实未做到的实验。

### 汉字屋实验

[中文房间 - Wikiwand](https://www.wikiwand.com/zh-hans/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4)

条件：
   - 初始条件：说英语的被试被关在密闭房间通过传递字条和屋外的懂汉语的人交流；屋外的人判断屋里的人是否真懂汉语，屋里的人要想方设法欺骗屋外的人自己懂汉语。
   - 其他条件：字条本身只能够用汉语写成。
   - 被试的资源条件：不能有英汉或汉英字典；很多写着汉字的卡片，规则书（在面对由哪些汉字所构成的问题时，应当如何从盒子中取出相应的汉字而构成合适的应答）。
   - 行动速度非常快

结论：屋外的人无法判断屋里的人是否真的懂汉语。但是就算计算机真的达到这种程度了，它也不可能真正具有智能，因为它并没有真正的理解语言。塞尔认为它只是机械地搬运各种符号，而不理解符号的真正含义。

汉字屋实验是图灵测验（计算机和人类交谈时，人类是否能够发现对方是计算机）的衍生版本，反过来用：即使通过了图灵测验，仍然没有智能。

### 反驳

- 他心应答：子非鱼安知鱼之乐。汉字屋的论证让我们可以怀疑任何一个人是否懂任何一种语言，这和初衷（人和机器不一样，人比机器高明，按照这个标准，人都是不懂任何语言的）不一样。因为没有人认为人本身都是不懂任何语言的，所以我们用来捍卫人的标准也可以用来捍卫机器，一视同仁。
- 系统论证（以偏概全）：承认一句话是对的：”被试不懂语言“。但是计算机不仅仅是被试，还包括规则书，规则书+被试=系统，系统懂汉语。

- 计算机没有办法在语言符号和所代表的外界事物之间所建立的联系，但是我们可以把这种联系加上去。但是塞尔反驳，即使建立联系，那种信息仍然是数码化的。他认为这种转换是有问题的，整个计算系统和原始世界的原始关系已经被破坏了。再反驳：人类也是进行一些转换。

- 从根本上反驳（课程老师的反驳）：
   - 塞尔的三个预设：
      - 汉字屋系统和计算机系统之间是同构的。
      - 即使整个汉字屋系统能够通过汉语测试，汉字屋中的被试也不懂汉语。
      - 行为主义是错的，也就是说，从系统的外部行为特征中，我们无法确保其内部状态是否具有智能。
   - 这三点放在一起有逻辑矛盾。反证法（12 步）：
      - 第一步：汉字屋系统和计算机系统存在着实质性的可类比关系。（塞尔说的，假设是对的）
      - 第二步：汉字屋论证的有效性，必须以（1）为必要前提（这一点是自明的）。
      - 第三步：汉字屋论证的一个核心目标，就是指出：一个系统在外部行为上具有语言智能，并不能够代表其真的有智能。（塞尔预设的一部分）
      - 第四步：由于（1），汉字屋中的规则书对应于计算机系统中的程序，或者是万能图灵机的机表（根据塞尔自己的叙述）。
      - 第五步：在假设系统的硬件条件不变的情况下，一个 AI 系统的智能程度的高下，关键在于如何编制程序。不执行任何程序的纯硬件没有任何智能。（计算机聪明不聪明看程序）
      - 第六步：由于（4）和（5）整个汉字屋系统通过汉语测试的能力的高下，取决于规则书的编制水平，而被试本身是谈不上智能的，它必须要执行某种程序，才能体现出这种程序的智能。
      - 第七步：即使整个汉字屋系统能够通过汉语测试，汉字屋中的被试也不懂汉语。（塞尔的话）
      - 第八步：塞尔如何确定第七步是真的呢？在逻辑上只有两种可能性（反省和行为）：
         - 8A：我们可以确定被试具有某种内部反思能力，以确定自己依然不懂汉语
         - 8B：我们可以从被试的外部行为中确定他不懂汉语。
      - 第九步：（8A）若是真的，则和（6）矛盾，因为被试的内部反思能力的存在就等于说他可以执行一个独立于汉语规则书的程序。为了维护汉字屋系统和计算机系统之间的可类比性，我们就必须得删除（8A）。
      - 第十步：（8B）若是真的，则和（3）矛盾，因为根据（3），从汉字屋系统的外部行为中我们无法判断出被试是否真懂汉语。为了不和汉字屋论证的最终目标相抵触，我们就必须得删除（8B）。
      - 第十一步：塞尔没有理由说清，为何即使整个汉字屋系统能够通过汉语测试，汉字屋中的被试也不懂汉语。这自然会造成整个汉字屋论证的崩溃。
      - 第十二步：之所以可以得出（11），乃是因为我们发现（8A）归根结底会和（1）不相容，而（8B）归根结底会和（3）不相容。也就是说，为了维护 “汉字屋中的被试也不懂汉语” 这个步骤的有效性，我们要么就去否定汉字屋系统和计算机系统之间的类比的有效性，要么就去放弃整个论证的反行为主义目标。但无论如何选择，我们都将再次导致整个汉字屋论证的崩溃。

小结：
- 塞尔的哲学风格比较清明，避免使用过于难的哲学词汇，过于技术性的表达。所以他觉得计算机太难，汉字屋比较直观，所以他用类比来做，但这个类比有些地方不太成功，他过多把直觉牵扯进来，没有看清楚这种类比可能有缺陷。和莱布尼茨的磨坊论证有点类似，都是诉诸于某一种直观，但直观在很大程度上没有普遍的合法性。再次说明，直观要慎用。
- 也让我们怀疑现象学的研究方法，因为对现象学直观的界定都非常主观。

前面三个是预设塞尔所说的计算机系统和汉字屋系统的同构性是没问题的。在此基础上进行反驳。老师的认为同构性就可能有问题。

### 衍生性问题讨论

- 塞尔脑子里：语义关系和意向性关系是有关的。
   - 塞尔的哲学观点：人类所有的言语行为归根结底是一种心智活动。
   - 塞尔对意向性实质的看法：实际是指心灵的内部状态朝向外的一种能力。也就是说，它能够被用来指涉它以外的事物。
   - 塞尔对语义关系的看法：语义关系也应该是朝向心灵以外的某种东西。
- 对上述观点有两个问题：
   - 意义真的奠基在意向性当中吗？
   - 意向性真的如塞尔所说，指的是一种心灵的内部状态和外部事物的一种奠基能力吗？
- 对上述问题的争论：
   - 角度一：恒温计在一定程度上也可以看作是按照语义（程序的语句）的规则来行事，但恒温计没有意向性；而且又与客观世界有关（客观世界温度变化，它也变化）。所以，恒温计与语义有关，与外部世界有关，但好像与意向性无关。所以，塞尔所说的语义关系一定要奠基在意向性里面，并且通过意向性才能获得它和外部世界的关联。这个观点似乎有些问题。
   - 角度二：意向性本身的一个界说。如果说意向的对象是你与外部的一个关系，那完全可以意向指向一个不存在的东西。所以，意向性是可以存在，但它所指涉的核心对象是不存在的，也就不能说意向性就指和外部世界的一种关系，除非这个外部世界包括柏拉图所说的理念世界（理念中的东西），如此一来，整个理论应该以柏拉图的理论作为预设。
   
### 其他讨论

- 什么是意向性对象
   - 意向性的根源是在一定的语言游戏，在一定的社会共同体里面。比如画出来的麒麟、方的圆之类。

总结：塞尔的实验和对塞尔的反驳让我们真正感受到了哲学的魅力。

在哲学上，如果真的有这样的中文屋，我们可以判断它是智能的。
其实这也取决于我们对于智能是怎么看待的，因为人类语言的灵活多变和复杂性，规则书要做的事其实和人要做的事一模一样。

更进一步，就按塞尔规则书的模式进行这样的转换（不知道具体意思，只是知道一些关系），但因为词的组合造成句子根本无法穷尽，所以其实规则书能做到这一步（就是知道进来问题的分词及其语义关系），它已经能够理解意思了，而不仅仅只是抽纸条。所以塞尔所要求的本身就是不可能的。

## 维特根斯坦、“颜色不相容”、框架问题和拆弹机器人

### 早期《逻辑哲学论》

- 《逻辑哲学论》三件事情：
   - 世界本身的形而上学的构建应当是怎样的
   - 对于这个形而上学的世界怎样在话语中和言语中加以符号表征
   - 哪些事情是不能够用言语表征的
- 《逻辑哲学论》与人工智能科学的 “知识表征” 任务的三个环节：
   - 对于被表征对象的形而上学理论
   - 对于知识表征的技术手段，特别是逻辑技术手段的选择问题
   - 在选定一个特定的表征手段的前提下，对于知识表征范围的可能性边界的划定问题
- 《逻辑哲学论》与海耶斯的 “朴素物理学宣言”：
   - 一个基本想法是用弗雷格和罗素所发明的谓词演算的技术手段把人类的日常物理学知识整编成公理集，物理世界中的所有行动和活动都是公理集的推论。
   
### 晚期《哲学研究》

- 本书关心的大问题：agent（智能体）应该在怎样的规范性条件的约束下，在历史的动态环境中，利用相关的表征工具，特别是日常语言完成某些特定任务。
- 为何后期维氏超越了早期维氏？
   - 从 AI 的角度看，《哲学研究》超越《逻辑哲学论》的最大地方，就在于它不再把静态的知识体系规整视为哲学理论的聚焦点，而是把焦点转移到了智能体的行动，转移到了对于信息的实时处理。
   - “实时” 意味着任务有时间限制。所以著述形式的散漫，因为问题太复杂，要考虑不同的智能体在不同的语境中面对不同的实时问题求解语境所给出的不同的问题求解策略，以至于他不可能以某种规整的、统一的、一劳永逸的方式（早期）对这些问题进行解决。
   - 其实现在的人工智能教材在处理各种技术问题时也基本是一种散漫的形式，最典型的例子就是每个章节讨论一个技术问题，如：经典逻辑、贝叶斯、神经网络、遗传算法等等，章节之间基本没有技术联系。不过底层还是数学、统计学。
- 工程学相关语录
   - 想一想工具箱里的工具，那里有锤子、钳子、锯子、螺丝刀、尺子、胶锅、胶水、钉子和螺丝钉。正如这些工具的功能各不相同一样，词的功能也是各不相同的。（不过，两者都有一些相似之处。）
   - 好比机器有两个界面，一个界面是用户友好的界面，另一个界面是机器内部操作的界面。第一个界面可能分不清不同语词之间的用法，但也许在第二个更深层次的界面上，也许它们之间有不同的输入输出对应关系。
   - 相似理论还可见西蒙的《人工科学》
   
## 维特根斯坦和框架问题

### 心灵模块论

福多（美国的哲学家和认知心理学家），认为人类的心智构架可以分为两大部分：
- 中央推理系统
   - 类似于司令部
   - 统一任务是在全局性的实践推理中，把所有的信息整合在一起，能够看看有什么一般性的东西。
   - 中央推理系统没法程序化（计算机模拟），因为两个特点：
      - 各向同性：在全局性的智能推理中，各个领域的信息都必须被智能体放在一个平面上予以考量。
      - 蒯因式的特点：
         - 蒯因的一个观点：如果有一个观察命题要对某个假设命题进行支持的话，要考虑到整个假说体系的一个支持力度。一个证据和假设之间不是孤立地建立一个正式的关系，还要看背景知识，看整个信念体系的支持力度。（有点贝叶斯的感觉）
         - 引入该观点：如果有一个信念，该信念要对其他一个信念的真值提出修正，会牵扯到对于和被修正的那个信念相关的一大堆其他信念的真值修正，导致一种牵一发而动全身的局面，而这种局面在计算上是不可控的，计算机无法模拟这种全局性问题。
- 边缘性模块
   - 类似于司令部下辖不同组织机关
   - 模块的信息处理：速度快、封装性
   - 边缘性模块可以利用计算机理论计算（可以写成程序）
   
由此得出福多的结论：针对心智架构的计算机模型，只能够适用于该架构中的模块部分，却不能够施加于中央语义系统。

### 拆弹机器人

- 任务：假设有一个能量快耗完的机器人，备用电池放在一辆拖车上，拖车锁在某个房间里，拖车上还有一个定时炸弹。计算机事先已经知道所有的事件。
怎么办？进房间拖出拖车，但同时也会将炸弹拖出来。
   - 所以需要对程序进行修正：程序需要预先知道哪些事件会引起哪些事件，或者说哪些事件类型彼此之间是相关的。但这其实很难，因为：在经典逻辑的技术支持下，在一个庞大的信念库中对于某些信念之间 “相关性” 的语义标注，将不会自动导致对于诸信念之间 “非相关性” 的语义标注。
   - 这和人类不一样，当你告诉计算机哪些相关的时候，它不会自动排除掉那些不相关的。比如，程序让机器人知道拉出拖车和拉出炸弹是相关的，但是还得告诉机器人其他信息（机器不知道），如拉出拖车和改变拖车的形状是不相关的、拉出拖车不会改变拖车下面轮子的数量、拉出拖车不会改变那个房间的颜色……因为人类具有朴素的物理先验知识，但机器人没有。所以，结果就是机器人不能在短时间内搞定这个任务，虽然看起来很容易。上面的故事来自丹尼尔·丹尼特，他讨论拆弹机器人例子的经典论文：《认知之轮：人工智能的框架问题》。
- 印证了福多对于中央语义推理系统可计算性的悲观态度（他认为框架问题在很大程度上就体现了这个问题），我们没有办法对全局性的语义相关性和非相关性进行一种快速的直觉的把握。
- 回到维特根斯坦：如果维特根斯坦看到框架问题，他会说：“我在批评逻辑哲学论的时候已经说过，你们要用经典逻辑来刻画信念系统当中的诸信念之间相关性和不相关性就会导致问题。”这个问题在很大程度上和 “颜色不相容” 问题相关。

### 颜色不相容

- 背景：维特根斯坦对于 “命题” 的分类
   - 经验命题：可真可假，如 “中石油宣布明天降价”，需要验证。
   - 逻辑命题：永真的，如 “明天要么下雨，要么不下雨”，总是对的。
- 颜色不相容
   - 这是红的。——经验命题
   - 这是红的，所以它不是绿的。——逻辑命题
      - 应该符合逻辑运算的规则
      - 但维特根斯坦发现并不是。比如命题逻辑中的合取规则：“这是红的，所以它不是绿的 & 这是绿的，所以它不是红的”，应该是真的，（真&真），但实际却是假的。
   - 这就意味着 “命题” 二分法的有效性遭到怀疑。这个问题为什么和框架问题有些像：
      - 因为对于框架问题来说，拖出被拖出这个命题对于拖车的颜色没有被改变这个命题应该有一种蕴含关系，但因为从逻辑里面没有办法表征出这种蕴含关系，所以只能写很多否定性命题，A 发生不会引起 B 发生。颜色不相容问题也类似，得事先告诉系统红色和绿色彼此不同，否则系统不会自动进行颜色不相容推演。
      - 于是，日常生活中最简单的语义推理逻辑就变成逻辑搞不定的东西，也就是说，我们的先验知识让我们 “自动” 地知道了某些事情之间的关系，但这种关系却不被机器知晓。
- 解决方案
   - 方案一：康德式
     - 颜色不相容问题是特殊命题，既不是先天分析判断，也不是后天综合判断，而是先天综合判断。
     - 这种独立的划分实际并未解决问题。
   - 方案二：蒯因式
     - 所有判断都看成经验的。
     - 对解决问题也没帮助，因为即使是纯粹的分析判断，也要想办法付出很多的表征资源进行表征，这实际是扩大了困难。
   - 方案三：维特有关的
     - 放弃真值函项理论或经典逻辑的主导地位，用更宽松的理论标准界定逻辑命题和经验命题的界限。
     - 维特根斯坦的建议可以归纳为两点：
        - 经典逻辑考虑的基本单位是句子，没有能力考虑概念。
           - 弗雷格的逻辑在形式化方面取得了大规模进步，但他的逻辑是为数学语言准备的，在应付日常语言时捉襟见肘。
           - 回到亚里士多德的道路，从语词的角度而非句子，制造很多概念层级。但很难形式化。
        - 《论确定性》中谈到的信念网的分布问题。
           - 把人类的信念系统看成非公理化却具有动力学特征的一种网络连接，网络连接中有不同的概念的节点。人在想起一件事时，当中的关键词就可以作为一个概念的节点。比如：“饿”，旁边有：面包等。一个网被激活后，其他邻近的网也可能会被激活。而且激活的次序看两点：第一，它和这个被激活的最早的那个节点之间的毗邻关系；第二，两者之间的信息通道的通畅程度。
           - 河渠的比喻：因为 “历史原因” 而形成的高权重信息通道就会构成网内信息流动的 “自然河渠”，并因为这种 “自然性” 而成为系统的 “缄默预设”，而不再成为系统自主知识表征的目标。（_正如人类自然而然的常识_）只有新问题（没有旧有的道路可以依赖）需要中央语义系统开拓新的道路。例子：兔鸭头图（既可以看成兔子也可以看成鸭子），假如看到的就是兔子或鸭子，就不会有在兔子和鸭子之间进行来回比较的心智过程。而现在两个概念节点被激活，它们都在争取对你感官印象的解释权，你的推理通道不知道该往哪边走，这时候的心智损耗就会很大。这种判断是经验判断。如果是非常容易的（兔子或鸭子），就可以快速推理，逻辑判断。
           - 按照上面的标准，维特根斯坦对分析判断和经验判断的标准变成一个心理学和语境论的标准：在当下语境下心理消耗的资源，而康德和休谟时代很大程度上是看一个知识论的标准。按照这个思路，框架问题也可以解决：为什么由某个行动不会引起的效果不需要在一个知识推理过程中得到系统的表征呢？因为这个系统的信息流向已经由这个信念系统自然的河渠流向来规定，对河渠外的事情不需要考虑。
      - 补充：
        - 传统的知识论的思路是指这个命题本身的性质是和它经验外部的那个关系，如果是先天命题就不需要通过经验来证实。是否需要经验验证 VS 是否需要付出心智的努力来思考。
        - 举例：很复杂的重言式，它的真不受任何经验的牵导或者牵制，和花多少时间计算无关，但计算的过程是真实的损耗。维特根斯坦考虑问题是在人的立场上，付出多少损耗的立场上。所以这种我们认为是分析判断的命题在维特根斯坦看来是经验判断，他认为证明很复杂的重言式在日常生活中是没用的，可能只有在应付逻辑考试时才用，而且做这件事需要大量的心智损耗。相反一些很简单的命题，因为它们和我们的日常生活非常相关（如 “我有两只手”）所以像分析判断，尽管按照传统知识论是经验判断。
        - 维特把传统看做知识、经验的东西看做逻辑，去分析；就是那些很简单的逻辑推理，但它们非常重要。传统的逻辑判断以逻辑体系为基础的。这是根本不同。

## 结论
- 维特根斯坦的思想宝库里有大量的金矿等着 AI 专家挖掘。
- 哲学家必须更多关心工程学实践，工程师也必须更多地熟悉哲学，能够在两者之间搭建互相熟悉的桥梁。


# [清华“天机”芯片登上Nature封面：全球首款异构融合类脑芯片](https://www.tmtpost.com/4099136.html)

2019-08-01 16:25

摘要： 
>这也是中国的人工智能芯片，首次登上Nature。

![](https://images.tmtpost.com/uploads/images/2019/08/20190801162443828.jpg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x649/gravity/center/crop/!1400x649&ext=.jpg)
   
近日，权威科技杂志《自然》(Nature)封面报道了来自清华大学团队的“天机”类脑芯片，论文标题为“Towards artificial general intelligence with hybrid Tianjic chip architecture”(面向通用人工智能的异构融合“天机”芯片架构)。
![](https://img1.mydrivers.com/img/20190801/f583e6ba-4539-4b0c-9ffe-8e85758f1451.jpg)

传统芯片均基于冯诺依曼架构，清华天机则是一种类似人类大脑机制的非传统结构，类似Intel正在研究的神经拟态芯片Loihi。

其实早在2015年，清华团队就完成了第一代“天机”芯片，2017年进化为第二代，速度更快，性能更高，功耗更低，相比于当前世界先进的IBM TrueNorth，也具备功能更全、灵活性、扩展更好的优点，密度高出20%，速度高出至少10倍，带宽高出至少100倍。

最新一代天机芯片采用28nm工艺制造，核心面积仅仅3.8×3.8毫米，包含156个FCores核心，拥有大约40000个神经元和1000万个神经突触，可以同时支持机器学习算法和类脑电路。

它不仅算力高、功耗低、支持多种不同AI算法，而且采用了存算一体技术，不需要外挂DDR缓存，可大大节省空间、功耗和成本。

![](https://img1.mydrivers.com/img/20190801/S7d431361-7176-4c6e-aee6-8ed3e6360faf.jpg)

## 自行车

今天，一辆来自清华的无人驾驶自行车登上了Nature的封面。

在论文中，研究团队描述了天机芯片如何帮助机器响应语音命令，识别周围世界，避开障碍，并保持平衡，展示了搭载该芯片的自动驾驶自行车如何自动控制平衡，并在操场上对目标人物进行识别、跟随、自动避障。

这个无人智能自行车系统包括激光测速、陀螺仪、摄像头等传感器，刹车电机、转向电机、驱动电机等制动器，以及控制平台、计算平台、天机板级系统等处理平台等。

据介绍，天机芯片目前还是非常初步的研究，但是团队已经启动了下一代芯片的研发，预期明年初完成。

![](https://img1.mydrivers.com/img/20190801/c4ded3bb9e914162a8c3aba36747d54e.gif)

S型路线跟踪

![](https://img1.mydrivers.com/img/20190801/3d029837c4b042e0ac978e153ae819e6.gif)

语音控制“左转”

![](https://img1.mydrivers.com/img/20190801/23e7680d94764435bd4f6a3b7283d064.gif)

语音控制“直行和加速”
这辆自行车不仅可以平衡自身，还可以绕过障碍物，甚至可以响应简单的声音命令。
      
![](https://images.tmtpost.com/uploads/images/2019/08/1dd7f2fdf7a3a4de36bf7bba1e17aff3_1564647942.gif?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x786/gravity/center/crop/!1400x786&ext=.gif)

自行车能够按照声音命令改变方向或调整速度
 
自行车检测并跟踪移动的人，并在必要时避开障碍物

这辆自行车能够如此平衡、顺利的自主运行，靠的是自行车背后的大脑。它采用了一种名为“天机（Tianjic）”的新型计算机芯片，用于实时物体检测，跟踪，语音识别，避障和平衡控制。

邓磊介绍，无人自行车系统的语音识别、自主决策、视觉追踪功能运用了模拟大脑的模型，而目标探测、运动控制和躲避障碍功能运用了机器学习算法模型。

研究团队还指出：“通过随机将新变量实时引入环境中可以产生高时空复杂性，例如不同的道路条件、噪声、天气因素、多种语言、更多人等等。通过探索允许适应这些环境变化的解决方案，可以检查对AGI至关重要的问题，比如概括、稳健性和自主学习。”

这只来自清华的团队也凭借Tianjic芯片，登上了8月1日发布的最新一期Nature封面。

这也是中国的人工智能芯片，首次登上Nature。

![](https://images.tmtpost.com/uploads/images/2019/08/1ed34cccf47ff53e8c057e5d5493dbea_1564647942.png?imageMogr2/strip/interlace/1/quality/85/format/jpg/thumbnail/1400x489/gravity/center/crop/!1400x489&ext=.png)        

论文的通讯作者、清华大学精密仪器系教授、类脑计算中心主任施路平教授表示，虽然这还是非常初步的一个研究，但或许能够推动通用人工智能（AGI）计算平台的进一步发展。

![](https://images.tmtpost.com/uploads/images/2019/08/5171b180a36d673c0796c5600d2c28a1_1564647942.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x919/gravity/center/crop/!1400x919&ext=.jpeg)       

本次的论文作者来自清华大学、北京灵汐科技、北京师范大学、新加坡理工大学和美国加州大学圣塔芭芭拉分校等机构。
- 论文链接：https://www.nature.com/articles/s41586-019-1424-8

![](https://images.tmtpost.com/uploads/images/2019/08/16a9e04d6af244ea188966b594f14dee_1564647943.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1848&ext=.jpeg)    

## 什么是AGI？

这款芯片可以同时融合两种方案正是其受到关注的关键所在。`通用人工智能`（Artificial General Intelligence，AGI），是一个尚未实现的研究课题，有时也被称作强人工智能，它所描述的机器智能可以理解或学习人类所能完成的任何智力任务。

![](https://static.leiphone.com/uploads/new/images/20190801/5d4264e2de9ca.png?imageView2/2/w/740)

对于AGI，部分人工智能学者认为，AGI的概念并不严肃，在实践中基本不可能实现。

另一些人则十分看好人工通用智能的发展，认为它有可能塑造人类的发展轨迹。

在Nature论文的新闻发布会中，施路平表示，“AGI是一个非常难的研究课题，但我们相信它是一定会实现的”。

施路平认为，发展通用人工智能的最佳方案之一是：<font color='red'>把人脑和电脑的优势结合起来</font>。

这种研究思路也就意味着要将`计算机科学导向`和`神经科学导向`这两种发展AGI的方法结合在一起。但是这两种方式在公式和编码方案上存在根本差异，想要结合困难重重。

也就是说，这种结合的核心挑战在于`脉冲神经网络`（SNN）和`人工神经网络`（ANN）的融合。

在生物大脑中，每个神经元都与各种输入相连。一些输入在神经元中产生激发，而另一些输入则抑制它，对于SNN（脉冲神经网络），在达到由变量（或者可能具有函数）描述的特定阈值状态时，神经元发出脉冲信号。

ANN则是是从信息处理角度对人脑神经元网络进行抽象，目前热门的AI神经网络CNN、RNN都属于ANN。

就可以理解SNN和ANN最大的差异
- ANN以精确的多位值处理信息
- 而SNN以脉冲处理信息

为了在一个平台上实现两种模型，脉冲需要表示为数字序列（1或0），以便与数字编码格式的ANN兼容。

当然，两者之间还存在其它差异，比如
- SNN在时空域中运行，而ANN依靠时钟在每个周期刷新信息。
- SNN的计算包括膜电位积分，阈值交叉和电位复位，ANN主要与乘法累加（MAC）操作和激活变换相关。
- SNN的处理需要比特可编程存储器和额外的高精度存储器来存储膜电位，发射阈值和不应期，ANN仅需要用字节存储器来进行激活存储和变换。

## 计算机科学+神经科学双导向，构建更普遍的通用平台

开发通用人工智能有两种主要方法：
- 一种是`神经科学导向`，植根于神经科学，并试图构建与大脑非常相似的电路。
- 另一种是`计算机科学导向`，以计算机科学为基础，并使用计算机来执行机器学习算法。

因为在制剂和编码方案的基本差异，这两种方法依赖于不同的和不兼容的平台，延缓了AGI的发展。

因此，通用人工智能的发展亟待一个支持更普遍的、基于计算机科学的人工神经网络以及神经科学启发的模型和算法的通用平台。

![](https://images.tmtpost.com/uploads/images/2019/08/7151e687d18f34311cd74692f5671527_1564647943.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x792/gravity/center/crop/!1400x792&ext=.jpeg)      

### 两种方法的结合促进AGI发展

这款天机（Tianjic）芯片则集成了两种方法，以提供混合、协同平台。

天机芯片采用多核架构，可重构构建模块和采用混合编码方案的流线型数据流，不仅可以适应基于计算机科学的机器学习算法，还可以轻松实现脑启动电路和多种编码方案。

![](https://images.tmtpost.com/uploads/images/2019/08/b1739c3b76e2147df3d20e7fc224d119_1564647943.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1228/gravity/center/crop/!1400x1228&ext=.jpeg)      

“天机”芯片示意图

通过资源复用，天机芯片只需百分之三的额外面积即可同时运行计算机科学和神经科学导向的绝大多数神经网络模型，支持异构网络的混合建模，形成时空域协调调度系统，发挥它们各自的优势，既能降低能耗，提高速度，又能保持高准确度。

天机芯片同时具有多个功能核心，可轻松地重新配置，使其能够适应机器学习算法和大脑启发电路。研究人员通过将其中一个芯片整合到无人驾驶的自行车中来证明这种方法的潜力，这种自行车可以实现自我平衡，通过语音控制并且可以检测和避开障碍物。

![](https://images.tmtpost.com/uploads/images/2019/08/527f1b98d719c2ffe824a14a67540858_1564647944.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1606/gravity/center/crop/!1400x1606&ext=.jpeg)      

芯片评估建模示例

在论文中，该团队表示，仅使用一个芯片，就可以在无人驾驶自行车系统中同时处理多种算法和模型，实现实时物体检测、跟踪、语音控制、避障和平衡控制。

![](https://images.tmtpost.com/uploads/images/2019/08/db856781ceda5d8aa886e72bfbcf7ed9_1564647944.jpeg?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x1386/gravity/center/crop/!1400x1386&ext=.jpeg)     

基于天机芯片的自动驾驶自行车多模态集成示例图

## 跨学科组队，七个院系共同参与，七年磨一“芯”

在7月30日的电话新闻发布会中，论文通讯作者、清华大学精密仪器系教授`施路平`介绍了论文的研究思路。研究团队在接受媒体的采访时表示，从2012年孕育这项研究开始，团队遇到的最大挑战不来自于科学、也不来自技术，而是在于学科的分布不利于解决当前的问题。

因此，研究团队成立了七个院系组成的类脑计算研究中心，覆盖脑科学、计算机、微电子、电子、精仪、自动化、材料等学科。

团队成员之一，加州大学圣塔芭芭拉分校博士后邓磊表示，在芯片方面，遇到的最大挑战是**如何实现深度和高效的融合**。计算机科学导向和神经科学导向是目前流行的两类神经网络模型，这两种模型的语言、计算原理、信号编码方式、应用场景都有很大不同，所以需要的计算架构和存储架构大相径庭，甚至设计的优化目标都很不一样。一些深度学习加速器和神经形态芯片，基本上都是独立的设计体系，因此深度融合并不简单。

深度融合不是深度学习加速模块和神经形态模块简单的拼合，难点在于每部分的比例难以确认，因为现实中的应用复杂多变。而且，如果构建异构的混合模型，可能还需要在两个模块之间添加专门的信号转换单元，这又会有很多额外成本，所以，如何设计一套芯片架构兼容两类模型，可以灵活的配置同时又具有高性能，是团队芯片设计中的一大挑战。

2015年，施路平团队设计出第一代“天机芯”，经不断改进设计，2017年第二代“天机芯”问世。相比于当前世界先进的IBM的TrueNorth 芯片，2017年流片成功的第二代“天机芯”密度提升20%，速度提高至少10倍，带宽提高至少100倍，灵活性和扩展性更好。

也正如MIT科技评论报道所说，“该芯片暗示了**中国在开发自己的芯片设计能力方面取得的进展**。中国研究人员表明，他们可以制造专门的AI芯片以及任何芯片。” 

## 类脑可以超越人脑吗？

其实早在3年前，谷歌就曾在愚人节那天发布过一辆理想中的自动驾驶自行车。

在谷歌的想象中，这辆“自行车”不仅平衡力超高

![](https://images.tmtpost.com/uploads/images/2019/08/a4f3742b87d55b8989267c079983c4ff_1564647945.gif?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x763&ext=.gif)       

还能够自动通过红绿灯路口，自主导航找到你的位置。

![](https://images.tmtpost.com/uploads/images/2019/08/eb45d1790480037035f7d53a4b5a0428_1564647945.gif?imageMogr2/strip/interlace/1/quality/85/thumbnail/1400x763&ext=.gif)       

但作为“愚人节视频“发布，也说明了这一技术的难点和不易实现。

而在今天，清华施路平团队终于初步实现了这一想象。这样的黑科技似乎也带着一丝科幻色彩，让人畅想AGI到来的那天。

在接受采访时，施路平教授表示，类脑能否超越人脑的问题，其实和电脑是否能超越人脑的问题类似。

电脑在某些方面其实早就超过了人类，其精准快速的运算能力、强大的记忆让我们叹为观止。然而，目前在很多智能的层次，计算机和人脑还是有相当大的距离。 特别是对于不确定性的问题，比如学习、自主决策等领域。

计算机会逐渐缩小差距，至于最后能否全面超过人脑，施路平教授觉得从技术的层面来看会越来越多，“因为计算机的发展有一个特点，就是`它从不退步，它一直往前走`。但是我相信我们人是有智慧的，我们会在发展的过程当中来逐渐的完善我们对于研究领域的一个理解，来把控它的风险，因为我相信人们之所以对这个问题重视，是因为我们担心会不会像科幻电影说的那样毁灭人类。”

关于AGI是否会超越人类智慧，吴恩达在AI For Everyone课程中也表示，`完全的AGI的出现可能还需要几十甚至上百年，从时间上来说，我们也不需要多度担心`。


## [从“天机”芯片看脑科学与AI的融合](https://zhuanlan.zhihu.com/p/76323171)

许铁-巡洋舰科技

7月31日Nature杂志封面刊登了清华类脑计算团队的最新成果： 天机芯片以及由其操控的自行车。

Towards artificial general intelligence with hybrid Tianjic chip architecture[1]

Letter | Published: 31 July 2019

Towards artificial general intelligence with hybrid Tianjic chip architecture
这则信息在一天之内在AI圈子引起了热议，而大部分吃瓜群众的状态则是云里雾里。 这篇文章从脑与人工智能结合的潜力与背景， 看这系列最新工作的意义。

我们说这个新工作的核心是能够同时在芯片上高效实现人工神经网络ANN和脉冲神经网络SNN， 所谓的ANN和SNN， 事实上是神经网络发展过程的两个分支。 欲了解其背景先了解其历史。

### 神经网络家族的分合故事。

神经网络的故事从模拟单个神经元开始： 神经元是神经网络信息传输的“原子”。通过一定的方法连接这些原子，就可以得到具有智能的系统， 这算是整个人工智能“连接主义”流派的哲学根基。

那么如何构建这个认知的“原子” ？ 我们来看看最早的把连接主义引入机器学习的尝试。 最早的模拟大脑的单个神经元的尝试， 是Warren McCulloch 和 Walter Pitts 在1943 提出而来神经元的模型。 这个模型类似于某种二极管或逻辑门电路。 一定的输入进来，被神经元汇集加和， 如何这个和的总量大于一个阈值，神经元就放电， 小于一个阈值，神经元就不放电。 这个东西就好像某个微小的决策装置， 把很多因素加载在一起， 做一个最终的决策。 我们想象无数的二极管可以构成一个计算机，那么无数这这样的神经元不就可以构成一个具有计算功能的大脑吗？ 这就是感知器的概念。

这个高度简化的神经元事实上就是后来的人工神经网络ANN的基础， 简化得到的神经元事实上每一个的数学形式等价于一个加入了非线性过滤的线性回归。

![](https://www.zhihu.com/equation?tex=y+%3D+%5Cphi%28%5Csum+W_%7Bij%7DX_j+%2B+b%29+)

如果把无数这样的神经元连接起来， 就构成了所谓的人工神经网络（ANN）。

当下的深度学习工具， 无论是CNN还是RNN， 都是在这个方程基础上把更多的神经元连接起来加入不同的限制条件得来的。

然而事实上， 这个架构与真正的生物神经网络相差极远， 这个差距首要集中在单个神经元模型上。 刚刚的方程是一个把原来的生化过程简化到不能再简的结果。 这里面最致命的区别在于， spike。 通过观察上述方程我们可以看出， 神经网络输出y是一个实数。而事实上， 真实的生物神经元输出， 更加基接近的是一个0，1过程， 当神经元经历的电压超过一个数值， 它就放电。 那是不是说明这个spiking反而更简单？ 其实不是， 这里面人们忽略掉的一个信息就是spike timing以及背后的电压变化。 真实神经元的放电过程由一组微分方程(Hodykin Huxley equations 1952)表达 :

![](https://www.zhihu.com/equation?tex=+%5Cbegin%7Bgather%2A%7D+I+%3D+C_m+dV_m+%2F+dt+%2B%5Cbar%7Bg_K%7Dn%5E4%28V_m+-+V_K%29++%2B+%5Cbar%7Bg_%7BNa%7D%7Dm%5E3+h%28V_m+-+V_%7BNa%7D%29+%2B+%5Cbar%7Bg_l%7D%28V_m+-+V_l%29%5C%5C+dn%2Fdt+%3D+%5Calpha_n%28V_m%29%281-n%29+-+%5Cbeta_n%28V_m%29n%5C%5C+dm%2Fdt+%3D+%5Calpha_m%28V_m%29%281-n%29+-+%5Cbeta_m%28V_m%29n+%5C%5C+dh%2Fdt%3D+%5Calpha_h%28V_m%29%281-h%29+-+%5Cbeta_h%28V_m%29h%5C%5C+%5Clabel%7Beq%3A001%7D+++%5Cend%7Bgather%2A%7D+)

这组微分方程的解就是spiking的过程， 如下图是电压随时间的变化， 当电压积累达到一定阈值， 这个爆发的尖峰就是spike，通过spike ， 神经元可以向其它神经元发射信号。我们所谓的脑电波， 无非是大量这样的神经元的集体放电在颅外所检测到的一组信号。

![](https://pic2.zhimg.com/80/v2-d887fabe6d956a3c9b6949596eb595b1_hd.jpg)

如果用上述这种包含了重要生物细节spiking的神经元连接成网络， 我们就得到了SNN（脉冲神经网络） 也就是受， 无论SNN还是ANN，本质都是对生物神经网络的模拟， 但就其抽象程度且相差疏远。

我们看到用SNN可以用神经脉冲表达信息， 如果用ANN表达一个类似的事情是什么样的呢？ 我们用一个数字Y来表达时间窗的spike个数（频率）， 而丢弃了所有其它信息， 比如波形，相位， 不同神经元之间spike和spike之间的同步等。 这意味着什么？ 两种可能的解释：
- 1， 波形，相位， 不同的神经元之间的同步是没有意义的冗余， 去掉它们整个神经网络表达的信息没有变化， 神经元的系统等于取定时间窗后的平均发放。
- 2， 波形，相位， 不同神经元之间的同步包含很多有用的信息， 去掉它们， 可能丢失了一些关键性的信息。 然而在最粗粒化的信息处理阶段， 这种保留是足够的。

那么哪一个更准确呢？ 普林斯顿的大牛Williams Bialek 的一系列作品都指出， 神经元spike间的同步（相关性）包含和神经编码相关的关键性信息，也就是说除了平均值外， spike所包含的不同神经元之间的发放同步（或相关性）依然包含了大量的信息。

1, Weak pairwise correlations imply strongly correlated network states in a neural population 2006 Nauture [2]

2, Collective Behavior of Place and Non-place Neurons in the Hippocampal Network 2017 Neuron[3]

![](https://pic2.zhimg.com/80/v2-c53bb05a4cfa8510e3572ebde93a346d_hd.jpg)

Weak pairwise correlations imply strongly correlated network states in a neural population 2006 Nauture, 这张图说明了如果用0，1事件表达spike， 那么一个（视网膜网络）里的神经元的同步放电频率远高于用高斯独立假设得到的频率， 也就是说spike之间的同步不可忽略， 构成一种潜在编码
这两部作品的共同特点是说， 神经元spike发放之间的spike correlation可以编码大量的信息， 如果记录这些spike之间的pairwise correlation， 那么我们就可以恢复出神经活动里的大部分有用信息。

这意味着什么？ 假如神经元spike间的同步可以编码信息， 那么我们就可能用更少的spike编码更多的信息， 而这无疑对用最少的神经元放电得到更多的信息（稀疏性）大有帮助。 除此之外， 通过在spiking神经元的那组微分方程里加入更多的核膜常数（代表不同时间尺度的信息， 因为spike方程本身是一个包含大量不同时间尺度的非线性方程），我们可以得到大量局部存储的不同时间尺度的记忆（此处联想“忆阻器”）， 我们甚至可以得到某些类似LSTM非线性门的特性。这些， 都代表着Spiking Neural Network（SNN）相比当下ANN的优势。 用一个不恰当的比喻， ANN的神经元用实数表达每个神经元的状态， 而SNN好比进入到了复数域，有了相位。 在物理领域，实数到复数支撑了从经典力学到量子力学的升级。 有次看， 把SNN看成下一代的神经网络技术不言而喻。当然如果SNN这么好为什么现在工业没有用呢？ 难点在于SNN依赖于对微分方程的模拟， 对于当下的冯诺伊曼结构的计算机， 这是一个成本消耗非常大的运算。也就是说计算机为了模拟本来节省能量的生物计算可能更加耗能，同时也更加不好训练。 解决这个问题的方法， 显然是从基本硬件基础出发，去改良硬件的架构， 这也是神经拟态芯片的意义之所在。我们把树突和轴突直接用芯片来刻画， 无形之间， 就得到了一个长在硬件上的脉冲神经网络（SNN），它的能耗效率要比普通芯片高12-10000倍。

当然ANN也有一类专门的芯片来提高当下深度学习运行的效率，这就是深度学习芯片， 例如大家都了解得寒武纪等。

清华的这个天机芯片在于， 把神经拟态芯片和深度学习芯片得优势结合起来， 可以同时提高这两类神经网络ANN和SNN的效率。 我个人背景不是芯片， 所以此处不在深谈， 我们多从算法角度谈谈两者结合得意义。

![](https://pic3.zhimg.com/80/v2-ef41f7d6e1d84886b2ddda3a7e729346_hd.jpg)

Towards artificial general intelligence with hybrid Tianjic chip architecture
这一次Nature文章里的例子是自动驾驶自行车， 当然这个例子被很多人诟病，认为这个不就是一个简单的平衡游戏吗。 大家可以去github搜索cart pooling或者双足行走，这一类的toy model还不少吗？

然而我认为思考一个新发现的意义不在于它所干的那个任务low不low ， 而是看它是如何完成的。 最初的火车甚至跑不过马车，但是它的架构决定了它的上限和马车不可同日而语， 通过数年时间迭代，两者已是云泥之别。

那么我们来看一下让ANN和SNN同时在一个芯片上运行， 带来的潜力是什么。 一言以蔽之， 当下的深度学习模型，可以和大量没有被好好利用起来的计算神经科学模型， 天衣无缝的嫁接在一起。 这从无人驾驶自行车的网络架构可以略知一二。

![](https://pic3.zhimg.com/80/v2-7faf9a7000d36d819ae6fea27643819a_hd.jpg)

Towards artificial general intelligence with hybrid Tianjic chip architecture
我们来理解一下这个流程图， 首先， 这个架构可以把多模态信息融合。 比如视觉， 听觉。我们注意到， 处理听觉的是脉冲神经网络SNN（更多时间相关信息）。 处理视觉信号的网络是经典的CNN卷积神经网络，属于人工神经网络ANN家族。 然而故事还没有结束， 在CNN的下面， 有一个主管视觉追踪的CANN网络， 虽然只有一个字母之差， 这可不是卷积神经网络， 这四个字母的含义是continous attractor neural networks - 连续吸引子网络。所谓空间吸引子， 说的是一种特化了的循环神经网络， 网络的动力学导致一系列可以根据外界信号连续变化的吸引子构成， 人们通常认为，海马体内的位置细胞就是由这种连续吸引子产生的， 它们可以天然的和速度信号进行耦合， 形成对空间的神经表示， 这个CANN，就是一种连续吸引子网络， 它直接把视觉物体(人)转化为一个可以追踪的空间目标（之后可以用于躲避行人）。 大家注意， 这是一个典型的脱胎于计算神经科学的网络架构，矩阵的连接还用到了树突计算。

然后我们来看中间的那个模块， neural state machine：神经状态机。 这个网络把连续的听觉和视觉信号转化为离散的事件， 这些事件构成一个有限状态的机器，也就是我们通常说的马尔可夫链。 这一步大家已经可以看到和决策有关的网络的联系，因为一旦把连续变化的信号抽象成了这种离散的马尔可夫链， 下一步就可以交给决策网络来决策了， 这里的决策主动是动作输出， 可以控制自行车在保持平衡的同时躲避障碍， 并对周围物体发出警戒信号。 这个网络也是由一个脉冲神经网络SNN构成。

在这里， 我们不难看出这是一个典型的人工设计与机器学习结合的模块化网络， 不能不让我们想起这类工作的先行之作： Science(Eliasmith, Chris, et al. "A large-scale model of the functioning brain."science338.6111 (2012): 1202-1205.) 在这个工作里， 研究人员构建了一个叫spaun的模块化网络， 可以进行多任务学习。

Spaun的每个部分都是一个人工神经网络， 且可以与真实的脑区对应上， 比如视觉输入对应V1-V4 视皮层，它把真实的视觉信息压缩成一种低维度的编码（每个图像称为这一空间的一个点， 被称为pointer）。 这种低维的信息表示形式很容易放入到工作记忆模块里（working memory）， 最终由解码网络转换（decoding）， 被动作输出网络执行（motor）。 神经网络整体状态的调控由模拟basal ganglia的网络完成（Action Selection），它可以根据当下的任务整体调节信息的流动（如同一个综控系统， 调节每个网络之前的输入阀门）， 从而让大脑在不同的工作状态间灵活转换。 这也体现了功能大脑的概念， 我们不必拘泥于某个脑区的名称， 而是记住每个脑区对应信息处理的功能。最终我们通过监督学习或强化学习来让这个系统掌握8种截然不同的任务， 包括： 1， 抄写数字 2， 图像识别 3， 奖励学习， 4， 多个数字的工作记忆 5， 数数 6， 回答问题 7 简单的数学推理。

![](https://pic3.zhimg.com/80/v2-ca6d04c9ec0559dfca62dc7acccd5b2e_hd.jpg)

A large-scale model of the functioning brain

而当下清华的工作， 正是打造了适合这一类执行多任务的“虚拟”生物的硬件系统， 在之上， 你可以自由的搭建无论是经典的深度学习模型， 还是那些超前了的计算神经科学模型， 把他们一起组成模块化的网络， 执行多种多样的功能。

这个潜力也就不只局限在自行车了， 可以是流水线的机器人， 陪护老人的机器人，随便你去发挥想象力，无论上述那个机器人， 都需要进行多模块的信息整合以及多任务执行。假如这种建立在神经网络芯片上的模块化的网络系统可以以较低能耗长时间在真实环境里运作， 那么它带来的好处显然是特别巨大的， 这相当于引入了一个实时不间断的训练数据， 如果结合无监督学习， 强化学习，甚至神经进化等算法实时对网络进行优化，其潜力是无可限量的。

事实上， 类脑计算和AI的结合之潜力此处仅是冰山一角， 在巡洋舰之前的一些文章里，进行了更详尽的论述：
- 许铁-巡洋舰科技：[AI和脑科学是否会再度握手？](https://zhuanlan.zhihu.com/p/53779357)
- 许铁-巡洋舰科技：[深度学习与脑科学的握手-圣城会议归来](https://zhuanlan.zhihu.com/p/55925386)

参考
- https://www.nature.com/articles/s41586-019-1424-8
- https://www.nature.com/articles/nature04701
- https://www.ncbi.nlm.nih.gov/pubmed/29154129

