---
layout: post
title:  "在线实验笔记-online-experimentation"
date:   2020-08-03 18:22:00
categories: 技术工具 数学基础
tags: A/B实验 假设检验 因果推理
excerpt: 互联网公司常用的在线实验方法讲解
author: 鹤啸九天
mathjax: true
---

* content
{:toc}

# 总结

- [Innovating Faster on Personalization Algorithms at Netflix Using Interleaving](https://medium.com/netflix-techblog/interleaving-in-online-experiments-at-netflix-a04ee392ec55)，中文版本：[Netflix推荐系统(Part Seven)-改善实验系统](https://blog.csdn.net/wqw547243068/article/details/107783748)

![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzMwLzE2NjI4NDM3Mzg3Y2RlNjg?x-oss-process=image/format,png)

![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC85LzMwLzE2NjI4NGJjMjU2MWI0ZWI?x-oss-process=image/format,png)


# 数学知识

## 什么是显著性检验

- “`显著性检验`”的英文名称是“significance test”。在统计学中，显著性检验是“**统计假设检验**”(Statistical hypothesis tesing)的一种，显著性检验是检测科学实验中的<font color='blue'>实验组与对照组之间是否存在差异及差异是否显著</font>的办法。
- “统计假设检验”指出了“显著性检验”的前提条件是“统计假设”，换言之“无假设，不检验”。任何人在使用显著性检验之前必须知道假设是什么。
- 一般而言，把要检验的假设称之为`原假设`，记为H0，把与H0相对应的假设称之为`备择假设`，记为H1。
    - 第一类错误-**弃真**（α）：如果原假设为真，而检验的结论却劝你放弃原假设，称为**第一类错误**，出现的概率记为α。
    - 第二类错误-**存伪**（β）：如果原假设不为真，而检验的结论却劝你接受原假设，称为**第二类错误**，出现的概率记为β。
- 通常只限定犯第一类错误的最大概率α， 不考虑犯第二类错误的概率β。这样的假设检验称为`显著性检验`，概率α称为`显著性水平`。
- 显著性水平是数学界约定俗成的，一般有α =0.05,0.025.0.01这三种情况。代表着显著性检验的结论错误率必须低于5%或2.5%或1%（统计学中，通常把在现实世界中发生几率小于5%的事件称之为“**不可能事件**”）（问：不是小概率事件吗？）。

## 什么是卡方检验

- 卡方检验(Chi-Square Test)在大数据技术场景中，通常用来检验某个变量或特征是不是**和应变量有显著关系**。
- 如：观察性别和在线买不买生鲜食品有没有关系。
    - ![](https://math.jianshu.com/math?formula=X%5E%7B2%7D%3D%5CSigma%20%5Cfrac%7B(observed-expected)%5E2%7D%7Bexpected%7D)

## 假设检验基本理论
-------

- 参考：[用Python如何实现“假设检验”](https://zhuanlan.zhihu.com/p/50190968)

![](https://pic4.zhimg.com/80/v2-f9031f3a6fe3328584e9df11d4b93fd5_720w.jpg?source=1940ef5c)

假设检验现实生活实例可参考 [假设检验的逻辑是什么？](https://www.zhihu.com/collection/288499050)
 
1. 先确定原假设（零假设）和备则假设
    - 原假设（H0）：某个断言
    - 备则假设（H1）：原假设对立的断言
2. 假设检验实际是对假设检验的断言进行试验，你对假设保持怀疑，随后如果有足够的拒绝证据，则拒绝；
3. 假设检验无法给出绝对的证明，假定原假设为真的前提下，通过假设检验了解结果到底有多可靠。如果结果极不可能发生，就会成为证明原假设为假的证据
4. 基本概念：
    * 检验统计量：用于对假设进行检验的统计量  
    * 显著性水平：用 α 表示， 表明希望在观察结果的不可能程度达到多大时，拒绝H0;

P(X<c) < α 其中X为检验统计量，c为临界值，α为显著性水平。
 
如果α=5%，表示如果样本中的检验中的检验统计量落在概率分布的最低5%范围内，将否定断言（原假设H0）
 
![](https://pic4.zhimg.com/80/v2-1ebfdc371235086068e7aa6eff21c2ee_720w.jpg)
 
* P值：某个小于或者等于拒绝域方向上的一个样本数值的概率；它是取得样本中的各种结果或者取得拒绝域方向上的某些更为极端的结果的概率；P值是在假定原假设为真时，得到与样本相同或者更极端的结果的概率。
    
- 如果P只位于拒绝域中，则拒绝H0；
- 如果P只位于拒绝域外，则没有充足证据，那么接受H0
 
5. 假设检验分类：（主要通过备则假设判断）
    * 单尾检验：拒绝域落在数据集一侧

* 如果H1是 '<' 符号 左尾 此时拒绝域位于数据的低端
 
![](https://pic2.zhimg.com/80/v2-ad9cf12c11e5f550bb87ae4603565b81_720w.jpg)
 
* 如果H1是 '>' 符号 右尾
 
![](https://pic4.zhimg.com/80/v2-e3c2a7f4d5b37110c6b633ecec8f2d7b_720w.jpg)
 
举例：某制药公司断言，某款药品针对某种病治愈率为90%患者，那么
- 原假设H0：P=0.9
- 备则假设H1: P<0.9
 
这就是左尾检验

无论是左尾检验还是右尾检验，P<α 即拒绝H0。 
*   双尾检验：拒绝域一分为而于数据集两侧

如果H1是 '≠' 符号 双尾
 
![](https://picb.zhimg.com/80/v2-d56ae1398ef74e216da2ba3e66896801_720w.jpg)
 
如果备则假设H1≠0.9， 则我们应使用双尾检验，我们应该查看检验统计量是否显著多于90%或者显著少于90%。
 
![](https://pic3.zhimg.com/80/v2-4bc25346eee2a7f31cda02149622543d_720w.jpg)
 
6. 几个概念的区别

* 置信区间：代表“总体参数位于两个极限之间”这一结果的具有的可信程度  
* 置信水平：总体参数位于置信区间的概率
* 显著性水平：反映数值位于某个极限以外的概率，一般为5%
 
显著性水平越小，则证据力度越大；为了拒绝H0，样本结果需要达到的不可能程度越高。

7. 假设检验六个步骤：

*   确定进行检验的假设（H0, H1）    
*   选择检验统计量
*   确定拒绝域
*   求出检验统计量的P值
*   查看样本结果是否位于拒绝域为
*   做出决策


# A/B实验

- 名言
    - 不是每个想法都是好的，大部分想法都是不好的。
    - Many times，we have to tell people that their new beautiful baby is actually…ugly。
- 在互联网背景下，快速试错已经成为产品持续迭代的必备能力。借鉴传统行业(医学等)成熟的实验理论(因果推断)，互联网逐渐发展了以AB Test为核心的数据驱动决策之路。在以下场景中可以考虑使用A/B Test:
    - 重大产品功能很难决策，不确定哪个方案效果最优。
    - "后验"成本高，如果改版失败，业务风险较大。
- 通过 abtest 系统对迭代方案进行实验, 并结合数据进行分析，反向再验证和驱动方案，是一个发现问题、提出假设、印证猜想、不断优化的过程
    - ![](https://pic1.zhimg.com/80/v2-f5104c5a1a06e7b6feeb97a8e2cece98_1440w.jpg)

## 因果推断

- 因果推断(Causal Inference)是指在一种现象已经发生的情况下推出因果关系结论的过程。比如说全球气候变暖，需要分析是什么因素导致的，各个因素对全球气候变暖影响有多大。
- 因果推断要做的是识别因果关系，量化因果作用。而这也是A/B测试要做的事情，即根据实验结果判断新版(B)相比原版(A)有无显著提升，如果有，提升了多少。
- 上面提到了因果关系，所谓因果关系(causality或causation)，是一个事件(即"因")和第二个事件(即"果") 之间的作用关系，其中后一事件被认为是前一事件的结果。一般来说，一个事件是很多原因综合产生的结果，而且原因都发生在较早时间点，而该事件又可以成为其他事件的原因。
- 因果关系举例:
    - 1). 睡得晚(因)，长黑眼圈(果)。
    - 2). 如果水温达到100度(因)，水会沸腾(果)。
    - 3). 长时间看电视(因)，影响孩子视力(果)。
- 因果关系的结构可表示成顺序的因果逻辑：
    - 因为事件A(前提:事件A已经发生)，所以事件B(结论:事件B将要发生)
- 注意：相关 ≠ 因果
- 机器学习算法更加关注特征之间的相关性，而无法识别特征之间的因果性，而很多时候在做决策与判断的时候，我们需要的是因果性。分析因果关系的目的是通过改变"因"，从而对真实世界做出改变("果")，这也是与相关关系最大不同。
- 传统的因果推断思想中，从因到果是一个封闭的系统。人们往往采用"控制"的方法，将影响结果的所有其他因素控制住，仅让关心的变量变化，这样结果的变化就是"关心的变量"造成的影响。随机化实验方法就是"控制"其他变量不变的常用手段，因此随机化试验是因果推断的黄金法则，而A/B Test恰好是随机化试验在互联网的应用。
- 机器学习大多数情况下仅作为一种可以拟合数据的特别函数f(x)[p(y\|x)]，近年来将机器学习方法应用到因果推理[p(y\|do(x))]逐渐成为研究热点，图林获奖者获奖得者Judea Pearl(另一作者Dana Mackenzie)的新书，《The Book of Why: The New Science of Cause and Effect》，将因果推断带入大家视野。

## 什么是A/B测试

- A/B Test是一个系统工程，互联网实际应用中多参考Google的分层实验模型《Overlapping Experiment Infrastructure: More, Better, Faster Experimentation》
    - 不同域之间共享100%流量，如上域1分流30%，域2分流70%。
    - 同一个域的不同层之间，会重复使用这个域中的流量，且每次各层进入流量会重新打散，保证互相不影响。
    - ![](https://pic3.zhimg.com/80/v2-07923499443ab75805dc0d06e5f35e16_720w.jpg)
- 完整的A/B Test是一个**衡量->发现->迭代->验证**的持续循环过程，除去基本的分流和实验管理功能外，A/B Test还应该包括**实验数据收集**和**实验数据分析**功能，系统流程
    - AB实验配置平台：产品经理/研发配置新实验。
    - 分流服务：读取AB实验配置平台的配置数据，执行具体分流算法。
    - 集成方应用：客户端上报实验分组和埋点(实验数据回收)。
    - 数据分析：分析打点数据，生成报表数据。
    - AB实验展示平台：实验数据可视化，用于辅助决策。
    - ![](https://pic3.zhimg.com/80/v2-7ce5932a82c8ee6d972372e18b7b8d26_720w.jpg)

- A/B测试是一种用于提升App/H5/小程序产品转化率、优化获客成本的数据决策方法。

![](https://pic1.zhimg.com/80/v2-11077994efe44dbf82e6512608dd2260_720w.jpg)

## A/B的意义

- 基于A/B测试的灰度发布更重要的不是优化，而是保护性发布，先通过小流量的实际用户测试，有BUG或者新版本体验不好，可以立即回滚到老版本，简单有效。
- ![](https://pic4.zhimg.com/80/72cdd3a4d3bba3ba4a4f0be795be831f_720w.jpg?source=1940ef5c)
- ![](https://pic2.zhimg.com/80/v2-313699ae4192816761bdcb7301c62112_720w.jpg?source=1940ef5c)

### 辛普森悖论

- **辛普森悖论**（Simpson's Paradox）亦有人译为辛普森诡论，为英国统计学家E.H.辛普森（E.H.Simpson）于1951年提出的悖论，即在某个条件下的两组数据，分别讨论时都会满足某种性质，可是一旦合并考虑，却可能导致相反的结论。

### 区群谬误

- 区群谬误（Ecological fallacy），又称生态谬误，层次谬误，是一种在分析统计资料时常犯的错误。和以偏概全相反，区群谬误是一种以全概偏，如果仅基于群体的统计数据就对其下属的个体性质作出推论，就是犯上区群谬误。这谬误假设了群体中的所有个体都有群体的性质(因此塑型(Sterotypes)也可能犯上区群谬误)。区群谬误的相反情况为化约主义（Reductionism)。

### 解决

- 很多的测试行为并不科学，特别是很多定向的用户测试经常会有这个弊端
- 要解决这个问题，对采样、聚类、流量分割等要求非常的高，这也是为什么A/B测试工具不能像很多统计工具一样，埋个点看数据，再根据数据反推业务逻辑，而是要充分与业务结合，从一开始就应该考虑业务策略，让用户去选择适合其口味的产品。


## 灰度发布

- A/B测试就是上两个方案，部署后看效果。根据效果和一些结果参数决定采用哪个方案。
- 灰度发布是切一部分业务使用新方案，看效果如何，是否有bug，会遇到什么问题。如果一切OK，就把全部业务切到新的方案上执行。
- A/B测试系统的一个常用场景是App/小程序/后端服务精细化运营过程中的上线迭代管理，通常被称为灰度测试或者灰度上线。

![](https://pic1.zhimg.com/80/v2-a5bfd4a6e475603afe930b26f7b2eff4_720w.jpg?source=1940ef5c)

## 抽样策略

- 在灰度测试的技术实现里，一个关键的部分是试用用户样本的选择策略。也就是说，新版本上线测试的首批（以及后续批次）灰度用户是怎么筛选出来，决定了灰度测试的技术选型和具体实现。每一个新功能分别由哪些测试用户来试用，谁扮演“小白鼠”的角色
- 广泛使用的样本选择策略
    - 白名单
    - 随机抽样
    - 按照某种规则抽样
    - A/B测试科学采样
### 实验组划分

- 实验分组的成功与否直接影响实验的数据，从而影响到实验的结果和结论。根据前文所述，随机化分组是控制实验无关变量(各组样本的条件尽量一致)的有效手段

#### 2.1 完全随机化分组
 
- 随机抽样一般借助Hash函数依据实验对象ID(Hash因子)将实验对象映射到实验分桶。
 
```
BucketID=Hash(实验对象ID，策略ID，流量层ID)%100+1
```
 
- 这样每个实验对象会得到唯一的BucketID，同时会随机均匀散落在\[1，100\]范围内。在配置实验时，根据实际需求，为各个版本均匀切分流量。譬如A版本划分10%的流量，则BucketID从0~10的用户被划分到 A 版本，以此类推。
- 在实际应用中，假如实验对象为用户，实验对象ID可以取用户ID、用户手机号等。在大流量业务中(推荐、搜索等)，完全随机化实验基本可以达到控制无关变量(消除无关变量影响)的目的。
 
#### 2.2 分层随机抽样(Stratified sampling)
 
![](https://pic1.zhimg.com/80/v2-57c71702ac1027c780913b5f397a1a10_720w.jpg)
 
- 在试验对象数量较小的情况下，比如2000量级左右，完全随机抽样可能无法保证试验分组的无偏性。比如，在网约车业务中，司机的做单能力存在天然差异且方差较大，此时采用随机抽样存在试验各分组司机做单能力存在较大差异的风险，进而影响策略效果评估。此时，可以考虑分层随机抽样，即先根据司机的历史做单能力将司机分为不同的分组，然后在各分组内再随机抽样。
 
#### 2.3 时间片分组
 
![](https://pic2.zhimg.com/80/v2-89410b08c8d1c49072701ad7328bce25_720w.jpg)
 
- 传统业务中，比如推荐、搜索等，流量因子是相互独立的、随机的，服从独立同分布。但是在O2O业务中，比如外卖、网约车等，实验对象(骑手、商家、司机等)面临着复杂的线下环境，由于存在一定程度的竞争关系，使得实验对象不再独立，此时传统的实验方式可能会存在问题。一种解决方法是采用时间片轮转分组方法。示意图如下:
 
![](https://pic3.zhimg.com/80/v2-5e9404dba0344599baf1c7c970fde296_720w.jpg)
 
#### 2.4 分组合理性评估(A/A Test)
 
- 实验分组方案确定后，正式实验开始前，在有条件的情况下可以通过A/A Test确认分组间的无偏性，即是否控制住了无关变量。
 
![](https://pic4.zhimg.com/80/v2-06087dbfacb7a47fcee10d838137cc8f_720w.jpg)
 
- 所谓的A/A Test是指实验组与对照组采用相同的策略，用来验证试验分组是否存在天然的差异(比如点击率、平均阅读时长、留存、人均GMV、司机做单能力等)。
 
####  2.5 实验分组比例设计
 
- 根据不同 目的和实验风险，选择不同的实验划分方案，如下图:
 
![](https://pic1.zhimg.com/80/v2-effa555cdc601a3734e803af4d94dbd8_720w.jpg)

- 参考：[策略算法工程师之路-因果分析.科学实验评估](https://zhuanlan.zhihu.com/p/161387546)


## A/B实验三大特性

- A/B测试具有三大特性：先验性、并行性和科学性。
    - 先验性：互联网以往的方式是先发布版本，再通过数据验证效果，分析版本的好坏。而A/B 测试是通过采用代表性样本、用户流量划分以及小流量测试等方式，来获得具有代表性的试验结论。简单来说，就是先通过低代价，小流量的试验，再推广到全流量的用户。
    - 并行性：将两个或两个以上的版本同时试验，确保每个版本所处环境的一致性，即其他条件都相同，同时发布同时生效，这样便于更加科学客观地进行对比。同时，可以节省验证的时间，无需在验证完一个版本之后再验证另一个。
    - 科学性：即用户流量分配的科学性。将相似特征的用户均匀的分配到试验组中，确保每个组别的用户特征的相似性，从而避免出现数据偏差，使得试验的结果更有代表性。

## A/B 测试的使用误区

- 误区一：轮流展现不同版本
    - 先发布A版本一段时间后，再发布B版本，通过对比两个版本的数据情况来评定版本的好坏。这种做法并不能保证每个版本所处的环境相同，受众群体可能会有明显区别。以至于难以判断最终效果是否有差异，或导致效果不同的原因。
    - 正确做法：不同版本并行（同时）上线试验，尽可能降低所有版本的测试环境差别。
- 误区二：选择不同应用市场投放/随机选取用户测试
    - 将不同版本打包，分别投放到不同的应用市场，最终根据数据反馈最优的版本，将该版本全量上线。或随机选取一部分用户（甚至是公司内部人员）进行前期试用，根据数据反馈决定迭代版本。这种做法违背A/B测试的科学流量分配的原则。
    - 正确做法：科学的进行流量分配，保证每个试验版本的用户特征类似。
- 误区三：让用户自主选择版本
    - 同时发布多个版本，在产品界面提供版本入口，由用户自主选择使用哪一版本，再根据数据进行分析，从而评估出最好版本。这种做法无法预估每个版本的用户数、用户使用时长以及用户特征，最终导致了试验结果的不准确。正确做法：让用户展现对不同版本的真实使用体验，应实时关注各版本的数据表现，并根据数据反馈及时调整试验流量。
- 误区四：对试验结果的认知和分析过浅
    - 这一误区又包括了两个不同的内容：
        - 认为只有当试验版本结果优于原始版本时，试验才算成功。事实上，A/B 测试是用于选择最佳版本的工具。试验可能出现的结果分为三种：试验版本有提升（试验版本最佳）、无明显差异（试验版本和原始版本均可）、试验版本的表现比原始版本糟糕（原始版本最佳），但这三种结果均可说明试验的成功。
        - 单从试验的整体数据结果，就推论所有场景的表现效果。例如：当A/B测试的数据表明试验版本差于原始版本时，就认定所有的地区或渠道的效果都是负面的。但如果细分每个版本中不同浏览器的数据，可能会发现：由于某一浏览器的明显劣势，导致整体试验数据不佳。
    - 因此，不要只专注于试验数据的整体表现，而忽略了细分场景下可能导致的结果偏差。
    - 正确做法：在分析试验整体数据的同时，需要从多个维度细分考量试验数据结果

## A/B方案

- AB实验的基本原理是“控制变量法”。
- 设指标数值=F（{隐变量列}、{显变量列（含方案变量）}）


# interleaving

- abtest的好处是能够对多个策略的效果差异给出定量的评估，但是也存在一些问题，比如，如果两个策略的效果差异较小，abtest容易给出波动较大的结果，需要较长时间（一般是一周）才能判断结果，会导致效果迭代速度较慢。
- 为了解决这个问题，采用interleaving效果评估方式作为补充。
- Interleaving方式的好处是所需流量较小，灵敏度较高，一般24小时之内可以给出结论，但是它**只能给定性结论而不能给定量结论**。
- Interleaving的基本思想是把两个策略的结果混合在一起，通过统计分析用户选择哪个策略的概率更大。具体列表混合的实现方式有多种。下面介绍比较简单使用的一种，叫Balanced方式。



# 应用

- 【2021-1-11】[策略算法工程师之路-因果分析.科学实验评估](https://zhuanlan.zhihu.com/p/161387546)
    - 1. A/B Test原理
    - 2. 实验分组划分
    - 3. 实验指标设计
    - 4. 实验效果评估
    - 5. 离线指标测算
    - 6. 实验结果分析


# 结束


