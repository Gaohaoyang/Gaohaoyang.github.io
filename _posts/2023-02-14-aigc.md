---
layout: post
title:  "AIGC行业笔记 - AIGC人工智能生成内容"
date:   2023-02-14 19:02:00
categories: 人工智能
tags: AIGC GPT
excerpt: 人工智能生成内容行业发展信息
author: 鹤啸九天
mathjax: true
permalink: /aigc
---

* content
{:toc}

# AIGC

AIGC 全称是：**Artificial Intelligence generated content**。翻译成中文就是**人工智能生产内容**。大家比较熟悉的AI，就是人工智能的简称，而GC就是创作内容。
- AIGC(人工智能生成内容，AI Generated Content)，也叫做`生成式AI`，就是用人工智能来生成内容，它可以用输入数据生成相同或不同种类型的内容

2022年是AI的奇迹年
- GAI：`生成式AI`（Generative AI），出现著名模型
  - DALL-E 2、Imagen、Stable Diffusion
- AGI：`通用人工智能`（Artificial AI），出现的模型
  - PaLM、LaMDA、ChatGPT

2021年之前，AIGC生成的还主要是文字，而新一代的模型可以处理任何内容格式，文字、语音、代码、图像、视频、3D模型、游戏机的按键、机器人的动作等等。在不断地把不同类型的数据用同一种思路做抽象，且都取得了很好的效果之后，我们隐约发现了一条可能通往通用人工智能（AGI）的路。


## 资料

【2023-2-28】[AIGC工具大全](https://aigc.cn/)，覆盖N多AIGC领域工具

【2023-2-14】[IDEA研究院](https://idea.edu.cn/)(粤港澳大湾区数字经济研究院) 张家兴
- [2023年，你需要在爆发前夕了解这些AIGC技术与应用](https://redian.news/wxnews/214448)
- 【2023-2-28】[深度解析对比中国和硅谷的AIGC赛道](https://www.toutiao.com/article/7202570334938235427)

[Fengshenbang-LM](https://github.com/IDEA-CCNL/Fengshenbang-LM)(封神榜大模型)是IDEA研究院认知计算与自然语言研究中心主导的大模型开源体系，成为中文AIGC和认知智能的基础设施。
- IDEA-CCNL的[huggingface社区](https://huggingface.co/IDEA-CCNL)下载中文开源模型
- ![model](https://github.com/IDEA-CCNL/Fengshenbang-LM/raw/main/pics/fengshenbang_process1.png)

## AIGC 概貌

ChatGPT的出现，彻底将生成AI推向爆发。但AI生成模型可不止 ChatGPT 一个，光是基于**文本输入**的就有7种：图像、视频、代码、3D模型、音频、文本、科学知识 ……

中国的AIGC产业大多还是一片蓝海。两张市场地图
- ![国内](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr4Zt8PbPpLe~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=6emr120cF3%2FnA4qSUMa0vdIBvgw%3D)
- ![国际](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr4dqF7uqiM0~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=oC1pYy7wgnRb%2F5HyRfLvWT%2FWFc4%3D)

尤其2022年，效果好的AI生成模型层出不穷，又以 `OpenAI`、`Meta`、`DeepMind` 和 `谷歌` 等为核心，发了不少达到SOTA的模型。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/7bf81e9821d44f828056b045ddab2fb3~noop.image?_iz=58558&from=article.pc_detail&x-expires=1675989263&x-signature=DYEyfQtpUfb0IyuUzfwhp2PQp%2Fg%3D)
- `OpenAI`: DALL-E 2、ChatGPT、Jukebox、Whisper
- `Google`: Imagen、Muse、DreamFusion、Phenaki、Minerva、AudioLM、LaMDA
- `DeepMind`: Flamingo、AlphaCode、Alphatensor、GATO
  - Alpha系列：AlphaCode、AlphaGo、AlphaFold
- `Meta`: PEER、Speech From Brain、Galactica
- `runway`: Stable Diffusion、Soundfly
- `Nvidia`: Magic 3D

AIGC预训练模型一览
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/11cb1660d4b04155910b5d4a625ababc~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676258271&x-signature=rO%2FReI3%2FXscbMOm%2B2TEZKr2LLn4%3D)

论文对2022年新出现的主流生成模型进行了年终盘点
- [ChatGPT is not all you need](https://arxiv.org/abs/2301.04655), [twiiter](https://twitter.com/1littlecoder/status/1615352215090384899)
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/7ae4ac40a3a84173ab52b5f2196fea14~noop.image?_iz=58558&from=article.pc_detail&x-expires=1675989263&x-signature=YRO2H1gdIfvBvmOPDX7Cxc6VPgg%3D)

AI生成模型分成了9大类 详见[原文](https://www.toutiao.com/article/7193210190974714371)
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/a3d62347f83247f9906a379cabe57853~noop.image?_iz=58558&from=article.pc_detail&x-expires=1675989263&x-signature=ZDQPfUcGn5FvVrRVieY098WuEeE%3D)
- `Text-to-Text`: ChatGPT3、LaMDA、PEE、Speech From Brain
- `Text-to-Code`: Codex、AlphaCode
- `Text-to-Image`: DALL-E 2、Stable Diffusion、Imagen、Muse
- `Text-to-Audio`: AudioLM、Whisper、Jukebox
- `Text-to-Video`: Phenaki、Soundify
- `Text-to-3D`: Dreamfusion、Magic 3D
- `Text-to-Science`: Galactica、Minerva
- `Image-to-Text`: Flamingo、VisualGPT

### Text-to-Text

`Text-to-Text`: ChatGPT3、LaMDA、PEE、Speech From Brain
- ChatGPT由OpenAI生成，是一个对话生成AI，懂得回答问题、拒绝不正当的问题请求并质疑不正确的问题前提，基于Transformer打造。它用人类打造的对话数据集、以及InstructGPT数据集的对话格式进行训练，此外也可以生成代码和进行简单数学运算。
- LaMDA基于Transformer打造，利用了其在文本中呈现的长程依赖关系能力。其具有1370亿参数，在1.56T的公共对话数据集和网页文本上进行训练，只有0.001%的训练数据被用于微调，这也是它效果好的原因之一。
- PEER由Meta AI打造，基于维基百科编辑历史进行训练，直到模型掌握完整的写作流程。具体来说，模型允许将写作任务分解成更多子任务，并允许人类随时干预，引导模型写出人类想要的作品。
- Speech from Brain由Meta AI打造，用于帮助无法通过语音、打字或手势进行交流的人，通过对比学习训练wave2vec 2.0自监督模型，基于非侵入式脑机接口发出的脑电波进行解读，并解码大脑生成的内容，从而合成对应语音。

### Text-to-Code

`Text-to-Code`: Codex、AlphaCode
- Codex是OpenAI打造的编程模型，基于GPT-3微调，可以基于文本需求生成代码。首先模型会将问题分解成更简单的编程问题，随后从现有代码（包含库、API等）中找到对应的解决方案，基于GitHub数据进行训练。
- AlphaCode由DeepMind打造，基于Transformer模型打造，通过采用GitHub中715.1GB的代码进行预训练，并从Codeforces中引入一个数据集进行微调，随后基于Codecontests数据集进行模型验证，并进一步改善了模型输出性能。

### Text-to-Image

`Text-to-Image`: DALL-E 2、Stable Diffusion、Imagen、Muse
- DALL·E2是来自OpenAI的生成模型，在零样本学习上做出大突破。与DALL·E一样，两点依旧是CLIP模型，除了训练数据庞大，CLIP基于Transformer对图像块建模，并采用对比学习训练，最终帮助DALL·E2取得了不错的生成效果。
- Imagen来自谷歌，基于Transformer模型搭建，其中语言模型在纯文本数据集上进行了预训练。Imagen增加了语言模型参数量，发现效果比提升扩散模型参数量更好。
- Stable Diffusion由慕尼黑大学的CompVis小组开发，基于潜在扩散模型打造，这个扩散模型可以通过在潜表示空间中迭代去噪以生成图像，并将结果解码成完整图像。
- Muse由谷歌开发，基于Transformer模型取得了比扩散模型更好的结果，只有900M参数，但在推理时间上比Stable Diffusion1.4版本快3倍，比Imagen-3B和Parti-3B快10倍。

#### Stable Diffusion

补充

#### IDEA 太乙

在StabilityAI发布Stable Diffusion模型之后不久，国内的`IDEA`研究院`封神榜`团队很快就训练出了名为“`太乙`”的中文版Stable Diffusion。与原版的Stable Diffusion不同，太乙Stable Diffusion可以更好地理解中文的语言文化环境。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr4QTEmySohL~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=gYfmYX%2FkWUzH%2F7pJHBy4fObMzkk%3D)

#### 文心一格

百度

### Text-to-Audio

`Text-to-Audio`: AudioLM、Whisper、Jukebox
- AudioLM由谷歌开发，将输入音频映射到一系列离散标记中，并将音频生成转换成语言建模任务，学会基于提示词产生自然连贯的音色。在人类评估中，认为它是人类语音的占51.2%、与合成语音比率接近，说明合成效果接近真人。
- Jukebox由OpenAI开发的音乐模型，可生成带有唱词的音乐。通过分层VQ-VAE体系将音频压缩到离散空间中，损失函数被设计为保留最大量信息，用于解决AI难以学习音频中的高级特征的问题。不过目前模型仍然局限于英语。
- Whisper由OpenAI开发，实现了多语言语音识别、翻译和语言识别，目前模型已经开源并可以用pip安装。模型基于68万小时标记音频数据训练，包括录音、扬声器、语音音频等，确保由人而非AI生成。

### Text-to-Video

`Text-to-Video`: `Phenaki` 、 `Soundify`
- `Phenaki` 由谷歌打造，基于新的编解码器架构C-ViViT将视频压缩为离散嵌入，能够在时空两个维度上压缩视频，在时间上保持自回归的同时，还能自回归生成任意长度的视频
- `Soundify` 是 Runway 开发的一个系统，目的是将声音效果与视频进行匹配，即制作音效。具体包括分类、同步和混合三个模块，首先模型通过对声音进行分类，将效果与视频匹配，随后将效果与每一帧进行比较，插入对应的音效。

#### 示例

AIGC [视频生成工具汇总](https://aigc.cn/#term-635)
- [artflow](https://artflow.ai), 支持换人、背景、音色。 换脸，卡通，真人，图像，跟着内容自动变换表情
- [synthesia](https://www.synthesia.io/free-ai-video-demo#SalesPitchNew)
- [invideo](https://invideo.io/make/add-text-to-video-online/): Text to video maker, Convert Blog and Article to Videos

【2023-3-22】阿里达摩院已在AI模型社区“魔搭”ModelScope上线了“文本生成视频大模型”。
- 整体模型参数约17亿，目前只支持英文输入。扩散模型采用Unet3D结构，通过从纯高斯噪声视频中，迭代去噪的过程，实现视频生成的功能。
- 模型还不支持中文输入，而且生成的视频长度多在2-4秒，等待时间从20多秒到1分多钟不等，画面的真实度、清晰度以及长度等方面还有待提升。
- 扩散模型采用 Unet3D 结构，通过从纯高斯噪声视频中，迭代去噪的过程，实现视频生成的功能
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/d8270a324501430a92d7b341c88a6f93~tplv-obj:256:256.image?_iz=97245&from=post&x-expires=1687392000&x-signature=CWJsHaBungH1EZQ8TnuAFKHo2Dw%3D)
- [体验地址](https://modelscope.cn/studios/damo/text-to-video-synthesis/summary)


### Text-to-3D

`Text-to-3D`: Dreamfusion、Magic 3D
- 没有把OpenAI的Point·E统计进去，可能是生成效果上没有达到SOTA
- DreamFusion由谷歌和UC伯克利开发，基于预训练文本-2D图像扩散模型实现文本生成3D模型。采用类似NeRF的三维场景参数化定义映射，无需任何3D数据或修改扩散模型，就能实现文本生成3D图像的效果。
- Magic3D由英伟达开发，旨在缩短DreamFusion图像生成时间、同时提升生成质量。具体来说，Magic3D可以在40分钟内创建高质量3D网格模型，比DreamFusion快2倍，同时实现了更高分辨率，并在人类评估中以61.7%的比率超过DreamFusion。
- 【2023-2-16】[AI终于能生成流畅3D动作片了，不同动作过渡衔接不出bug，准确识别文本指令](https://zhuanlan.zhihu.com/p/570968101)， 输入文本（看向地面并抓住高尔夫球杆，挥动球杆，小跑一段，蹲下），直接生成3D动画：
- ![img](https://pic2.zhimg.com/v2-59e590384ae4fec248e6541a05f4e845_b.webp)
- 以前，AI控制的3D人体模型基本只能“每次做一个动作”或“每次完成一条指令”，难以连续完成指令。现在，无需剪辑或编辑，只需按顺序输入几条命令，3D人物就能自动完成每一套动作，全程丝滑无bug。
- AI（TEACH）输入几句话就能搞定（不同颜色代表不同动作），TEACH的架构，基于团队不久前提出的另一个3D人体运动生成框架TEMOS。TEMOS基于Transformer架构设计，利用人体真实运动数据进行训练。它在训练时会采用两个编码器，分别是动作编码器（Motion Encoder）和文本编码器（Text Encoder），同时通过动作解码器（Motion Decoder）输出。

#### Action-GPT

【2023-3-22】Action-GPT：[利用GPT实现任意文本生成动作](https://zhuanlan.zhihu.com/p/615905432)

除了文本生成图片，也有许多其他的文本引导生成任务，例如基于文本生成视频，基于文本生成动作，这些研究在诸如娱乐，虚拟现实和机器人等领域均有大量应用。
- 论文：[Action-GPT: Leveraging Large-scale Language Models for Improved and Generalized Action Generation](https://arxiv.org/pdf/2211.15603.pdf), [demo](https://actiongpt.github.io/)
- ![](https://actiongpt.github.io/images/actiongpt/teaser.gif), [code](https://github.com/actiongpt/actiongpt)
- Action-GPT是一种插即用的框架，可用于将大型语言模型 (LLM) 合并到基于文本的动作生成模型中。鉴于当前的动作短语运动捕捉数据集包含最少的和最重要的信息， Action-GPT首先通过为 LLM 精心制作prompt提示，生成更丰富、更细粒度的动作描述，再利用这些详细描述来代替原始动作短语，从而更好的对齐文本和运动空间。
- Action-GPT主要由Text Encoder，Motion Encoder，Motion Decoder组成，其中Text Encoder，Motion Encoder分别将文本序列和动作序列编码为特征向量。
- 给定一个动作短语x，首先使用prompt函数 fprompt(x)生成一个合适的prompt文本xprompt。然后将xprompt输入到大规模语言模型（GPT-3）中获取包含更细粒度动作细节的多个动作描述Di。
- 然后利用一个Description Embedder获得每个Di相应的深度文本表征vi，再利用Embedding Aggregator进行融合后输入到Text Encoder中。
- ![](https://pic1.zhimg.com/80/v2-03cf0082610adf1a7416adfde1ec7a1c_1440w.jpg)

训练数据集
- 大规模BABEL数据集 ，其中的语言标注描述了 mocap 序列中正在进行的动作。 包括来自 AMASS 数据集的约 43 小时的 mocap 序列的动作标注。
- ![](https://pic2.zhimg.com/80/v2-29dd42d410db5d1f49e9d9940a41cc55_1440w.webp)

实验表明
- 基于 MotionCLIP， TEMOS 以及 TEACH 三种方法，Action-GPT 框架在BABEL测试集上的结果均有较大提升：
- Action-GPT更强大的能力在于零样本生成（Zero-Shot Generations）。利用GPT-3的强大语言能力，Action-GPT还可以根据未见过的文本短语生成动作序列 。


### Text-to-Science

`Text-to-Science`: Galactica、Minerva
- Galatica是Meta AI推出的1200亿参数论文写作辅助模型，又被称之为“写论文的Copilot模型”，目的是帮助人们快速总结并从新增论文中得到新结论，在包括生成文本、数学公式、代码、化学式和蛋白质序列等任务上取得了不错的效果，然而一度因为内容生成不可靠被迫下架。
- Minerva由谷歌开发，目的是通过逐步推理解决数学定量问题，可以主动生成相关公式、常数和涉及数值计算的解决方案，也能生成LaTeX、MathJax等公式，而不需要借助计算器来得到最终数学答案。

### Image-to-Text

`Image-to-Text`: Flamingo、VisualGPT
- Flamingo是DeepMind推出的小样本学习模型，基于可以分析视觉场景的视觉模型和执行基本推理的大语言模型打造，其中大语言模型基于文本数据集训练。输入带有图像或视频的问题后，模型会自动输出一段文本作为回答。
- VisualGPT是OpenAI制作的图像-文本模型，基于预训练GPT-2提出了一种新的注意力机制，来衔接不同模态之间的语义差异，无需大量图像-文本数据训练，就能提升文本生成效率。

### 游戏

游戏NPC
- 利用文本生成能力可以创建非常多样、丰富、有趣的游戏NPC的能力。
- 游戏里面的主角，可以跟游戏里面的NPC进行自由对话，所有的NPC的回答都是根据设置的词语提示实时生成的。

比如说，游戏开始时给模型的词语是
- 提示：下面的对话是一个游戏玩家和AI助手之间的对话，助手的目的是帮助玩家完成所有的任务。助手是乐于助人、有创造性、聪明和友好的。
- 现在玩家在deadwood小镇。
- 任务：用钥匙去开银行后台的保险箱

当玩家问到，“我现在在哪，我应该做什么？”的时候，模型会生成下面的内容，并语音播放。
- 你现在身处Deadwood小镇的中央，你的任务是找到钥匙并用它打开银行后台的保险箱。

### 数字人

AI视频领域有着比较强的竞争力。特别是虚拟人和短视频方面，中国的公司更加懂得结合实用性和娱乐性，而西方的公司的产品往往只有实用性。

拿中国的`小冰`和英国的`Synthethia`虚拟人公司来做个对比。
- Synthethia做出来的虚拟人跟普通公司白领无异，而小冰生成的万科虚拟员工崔筱盼却长着一副明星脸。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr5Mc2QWCiYo~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=VtjHebUS1kI%2FT65BDbr2JNexZ8s%3D)
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr5NUBdj0uXo~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=mJKMMKNJC%2Fl%2FtiBrUWwsr1pRTSg%3D)

中国的虚拟人产业近几年逐渐人们的视野。不论是清华大学首位虚拟学生“`华智冰`”，还是冬奥会上`谷爱凌`的虚拟分身，每次虚拟人的亮相都能够引起舆论关注。比起专注于2B赛道的西方公司，中国的AIGC公司因为要做2C的业务，所以特别懂得吸睛引流。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr5Os5HmAeRQ~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=xhskcVXfSawjeb1TyVo77%2FvnB8M%3D)

详见元宇宙-[数字人专题](https://wqw547243068.github.io/2021/11/03/meta-universe/#%E6%95%B0%E5%AD%97%E4%BA%BA)

### Other Models

`Other Models`: AlphaTensor、AlphaFold、GATO、Human Motion Diffusion Model
- AlphaTensor由DeepMind开发，懂得自己改进矩阵乘法并提升计算速度，不仅改进了目前最优的4×4矩阵解法，也提升了70多种不同大小矩阵的计算速度，基于“棋类AI”AlphaZero打造，其中棋盘代表要解决的乘法问题，下棋步骤代表解决问题的步骤。
- GATO由DeepMind开发，基于强化学习教会大模型完成600多个不同的任务，包含离散控制如Atari小游戏、推箱子游戏，以及连续控制如机器人、机械臂，还有NLP对话和视觉生成等，进一步加速了通用人工智能的进度。
- PhysDiff是英伟达推出的人体运动生成扩散模型，进一步解决了AI人体生成中漂浮、脚滑或穿模等问题，教会AI模仿使用物理模拟器生成的运行模型，并在大规模人体运动数据集上达到了最先进的效果。
- 除了谷歌LaMDA和Muse以外，所有模型均为2022年发布。
  - 谷歌LaMDA虽然是2021年发布的，但在2022年又爆火了一波；
  - Muse则是2023年刚发布的，但论文声称自己在图像生成性能上达到SOTA，因此也统计了进去。
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/0796479323fd4f75914bd65906eb2af3~noop.image?_iz=58558&from=article.pc_detail&x-expires=1675989263&x-signature=gz99QiqjLcQ2VpXaqvf%2BsKkPwoY%3D)


## AIGC 应用

AIGC 应用领域
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/7737b01f24b74c878e37b7125598b427~tplv-obj:960:540.image?_iz=97245&from=post&x-expires=1685318400&x-signature=S2%2B0279oLoVV8bitsBcvtgIvCDg%3D)

详见：[甲子光年](https://www.jazzyear.com/index.html)的《2023AIGC市场研究报告及ChatGPT推动的变革趋势与投资机会》

### AI作画

2022年下半年以来，**AI绘画**已经成为元宇宙图景中当之无愧的技术热点。只需要输入几个关键词，便能在几十秒内生成一幅精美画作，还能根据用户喜爱的画风调整不同的方案，没有人不为这样极低门槛的创作方式所心动。
- 目前，小红书“AI绘画”相关笔记最高点赞量18.5万，屡屡成为搜索热词；
- 抖音上有关“AI绘画”的短视频最高点赞量甚至接近140万。

不少人惊呼：AI绘画元年已经到来。

而伴随AI绘画的流行，一个崭新的合成词`AIGC`也出现在各大互联网平台。

【2023-2-2】[AI绘画爆火出圈，AIGC迎来野蛮生长时代](https://view.inews.qq.com/a/20230130A06EXR00)
- 2022年9月，在美国科罗拉多州的一场艺术博览会上，一幅名为《太空歌剧院》的作品勇夺数字艺术类别冠军，建筑场景的恢弘感，人物刻画的细腻程度，令人为之惊叹。
  - ![img](http://inews.gtimg.com/newsapp_bt/0/15634638368/641)
- 2022年12月8日，全球首幅AIGC画作《未完·待续》拍卖以110万元落槌成交，这幅画作是对民国才女陆小曼未尽稿的续画，通过深度学习陆小曼作品的山水画元素，AI完成了续画、上色、生产诗词等环节。
  - ![img](http://inews.gtimg.com/newsapp_bt/0/15634638380/641)
- 2022年，国内知名摇滚乐队万能青年旅店的作品《杀死那个石家庄人》在B站火出圈了。原因很特别：这首歌的每一句歌词，都被一个名为“Midjourney”的AI生成艺术工具配上了画面。
  - ![img](http://inews.gtimg.com/newsapp_bt/0/15634639126/641)
  - 随后周杰伦的知名代表作品《七里香》也都被AI绘画配图，每一帧画面都和歌词完美契合，带给用户视觉听觉上的双重享受。
  - ![img](http://inews.gtimg.com/newsapp_bt/0/15634639142/641)
  - `网易天音`依托大量的歌曲曲库，精准分析大众审美，率先于行业部署工业出版级智能编曲系统，能快速生成一首对标人编1-1.5万元左右的出版级编曲，在歌词创作方面省时省力。
  - `网易天音`成功打造出《醒来》《春启正阳》等多首广受欢迎的 AI 原创歌曲，《春启正阳》将沧桑古老的正阳门故事吟唱出令人惊艳的少年气，在网易云音乐一经上线就收获好评不断。

AIGC动画短片《[犬与少年](https://www.youtube.com/watch?v=J9DpusAZV_0)》
- 1月31日，Netflix宣布，其与小冰公司日本分部（rinna）、WIT STUDIO共同创作的首支AIGC动画短片《犬与少年》，已于今日正式公开。这是Netflix动画创作者计划的第一支作品，通过人工智能技术绘制完整动画场景，为动画制作揭开新的未来。
- AIGC目前已成为全球热点，但多数仍停留在技术演示阶段，普遍尚未实现作品级落地。《犬与少年》是AIGC技术辅助商业化动画片的首支发行级别作品。该片讲述了一个小孩与一只机器狗的重逢故事。正编映像已同步在Youtube公开
- ![img](https://n.sinaimg.cn/sinakd20230131s/662/w964h498/20230131/aa70-055e4197a5f3f22a4b728f9705fb83d6.jpg)

工业化大批量生产的能力极大地满足用户个性化的需求
- 留校过年的学生用天音给宿管阿姨写歌，表达感谢；
- 小情侣用天音给彼此写歌，创造专属的甜蜜记忆……

内容生产方和用户的利益都得到了满足。
- 东京奥运会期间，基于快手多项人工智能技术，快手云剪启用了一条智能生产的自动化流水线，在比赛热点发生后自动化产出短视频内容，为传播比赛最新赛况提供了视频素材，极大地提高了赛事报道的时效性，为奥运会这一国际顶级体育IP注入短视频、直播时代的科技特质，也探索了内容生产模式的更多可能。
- ![img](http://inews.gtimg.com/newsapp_bt/0/15634639355/641)

AI作曲、AI编剧、AI续写小说、AI配音、AI虚拟偶像、AI电竞选手, AIGC已经完成了从文字输出到静态画面再到动态影像，对影音制品的全面渗透，各种日新月异的新技术正在改变着文娱行业。


## AIGC 技术与伦理的博弈

专业绘画人士的感慨也道出了当下内容创作者的深深忧虑。
- “学了五六年美术，画功不如AI输入词条几十秒就出的画”。
- ![img](http://inews.gtimg.com/newsapp_bt/0/15634639572/641)
- 依托精密的算法体系，发展迅猛的AIGC展示出了较低的创作门槛和较高的工作频率，假以时日，其流量号召力不容小觑。这对于需要和其同台竞技的内容创作者而言，冲击是巨大的。
- 当AI技术被引入写作领域，受到冲击的主要是文字工作者。而当AI技术被引入影音领域，波及到的内容创作者则显然更为多元。导演、策划、编剧、字幕、配音，整个影视创作链条上的工种或多或少都会受到影响。
- 在创意无限、产出高频的AIGC面前，不少专业内容创作者第一次意识到了什么叫“降维打击”，这种“降维打击”的程度甚至远远超过了人与人之间的内卷。
除了专业的内容创作者，短视频平台所依靠的海量自发上传用户，在内容输出的频率上也难以与AIGC进行抗衡。

不过这并不意味着AIGC的发展将一帆风顺。AIGC的高歌猛进中，充斥着许多**技术伦理**的问题。
- AI生成模型应用的门槛较低，从某种程度上而言，这无疑是一把双刃剑，它既有可能提高创作频率，但又有可能被滥用、误用，比如被用于抄袭、恶搞等，近年来女明星被AI换脸的负面新闻已经屡见不鲜。
- AI生成内容是否受版权保护也存在争议，一方面AI创作内容随机性较强，且由算法进行主导。这种缺少思想的表达尚无法满足当下版权法中所要求的独创性。而且AIGC自身所依靠的深度学习模型训练中的大型数据，本身也有可能包含受版权保护的作品。
  - 目前海内外关于AIGC的法律监管，依然存在着一定的滞后性。当技术伦理的达摩克利斯之剑始终高悬，《银翼杀手》中所描绘的智能机器人时代距离我们便依然遥远。
- 人文艺术领域，不管是文字创作还是影音创作，都蕴藏着诸多情感和文学性，思想性内核，而这些显然是无法由算法所决定的。当AI技术被引入写作，市场曾一度悲观，认为文字工作者或将被取代，而现在看来这种担心完全是多余的。也有不少内容创作者坚持AI将无法与人工相抗衡。一个最简单的例子，在大量的电影二创剪辑视频中，富有情感起伏的人工配音解说总是要比毫无波澜、机械的AI配音解说的转发量高出许多。

内容创作者究竟该怎样与AIGC相处？是抵制还是与之和平共处？我们目前还无法给出正确的答案。技术革新倒逼市场迎来新的无序生长阶段，让子弹先飞一会儿或许是最佳的方式。而对于现阶段的内容创作者而言，所能做到的就是放下担忧，尽可能提升创作品质，筑牢内容的护城河。

## AIGC 投资

用户沉浸在AI绘画低门槛创作的乐趣中时，敏锐的资本已经捕捉到`AIGC`创作有可能成为`PGC`（专业内容生产）和`UGC`（海量用户自发生产）之后崭新的内容产业升级方向，一场新的资本布局正在悄然展开。
- 国外企业在AIGC领域布局可谓是先声夺人，这其中既有科技巨头谷歌、Meta、微软等，也有AIGC的新晋独角兽 Stability AI、Jasper、OpenAI等，并且这些企业已经很快将AI作画的热度延续到了AI生成视频。
  - 无论是Meta所推出的由文本到视频的系统 Make-A-Video，再到谷歌根据简单文本提示便可生产高清视频的 Imagen Video 和 Phenaki，都可以看出AIGC在海外如火如荼的高速发展态势。
  - ![img](http://inews.gtimg.com/newsapp_bt/0/15634638578/641)
- 国内百度腾讯阿里巴巴等资本巨头也紧随其后。
  - 百度推出的AI作画平台`文心一格`，展开了数字艺术品的新叙事。前文所提到的以110万元落锤成交的《未完·待续》，便是由百度文心一格续画。
  - 近日，百度与视觉中国正式签署战略合作协议，AI作画平台文心一格将与视觉中国在创作者赋能和版权保护等方面展开多项合作，共探AIGC内容产业发展方向。
  - ![img](http://inews.gtimg.com/newsapp_bt/0/15634638740/641)
  - 阿里巴巴旗下的AI在线设计平台鲁班Lubanner，致力于提升设计师的工作效率，帮助营销人员生产Banner，让创意不再有界限。
- 滚滚浪潮之下，国内资本巨头与时俱进， AIGC 版图布局也从文字等**平面**领域扩张至**音乐视频**等创作产品领域。
  - 目前，字节跳动旗下的`剪映`，快手`云剪`都能提供AI生成视频，快手云剪提供了智能封面、自动配音、自动字幕、画质增强、视频去抖、自动横屏转竖屏等系列智能工具，以技术赋能内容创作者。更有一帧秒创这样无需剪辑，一键成片的软件，短视频成片效果让人叹为观止。
  - 早在两年前，网易便已经开始了AI音乐创作技术的研究探索，时值新年之际，网易也推出一站式AI音乐创作平台“**网易天音**”，用户只需在微信搜索“网易天音”拜年小程序，输入祝福对象、祝福语，10秒就能搞定词曲编唱，定制一首拜年歌。
- 在资本的助推下，当下AIGC已并非遥不可及的存在，这一技术创新手段已被广泛应用在文字、图像、音频、游戏和代码的生成当中。

AIGC成为了币圈之后的投资新焦点。在 GPT-3 发布的两年内，风投资本对 AIGC 的投资增长了四倍，在 2022 年更是达到了 21 亿美元。 
- ![img](https://img.36krcdn.com/hsossms/20230131/v2_263194e805844f63b1d2051b05164c9e_oswg57406oswg1080oswg986_img_000)

### AIGC 报告

研究报告
- 2023年02月07日，国泰君安：ChatGPT研究框架(2023)，[微云地址](https://share.weiyun.com/tAE492tL)， [公众号文章](https://mp.weixin.qq.com/s/fKQiGhoIfU6bVfcGWLkvyw)
- 【2023-2-7】中信建投证券：[从CHAT_GPT到生成式AI（Generative AI）：人工智能新范式，重新定义生产力](https://www.baogaoting.com/info/236385)
- 【2022-9-19】红杉发布《[Generative AI: A Creative New World](https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/)》

AIGC下游场景 [img](https://picx.zhimg.com/80/v2-11f6012c92a0732e8a995284db33ae18_1440w.webp?source=1940ef5c)
- ![img](https://picx.zhimg.com/80/v2-11f6012c92a0732e8a995284db33ae18_1440w.webp?source=1940ef5c)

【2023-1-31】腾讯研究院AIGC发展趋势研究报告
- [官方公众号](https://mp.weixin.qq.com/s/9AjTpyL4HmQ6BDhWIDbD0A), ppt[微云地址](https://share.weiyun.com/usQ7SfzI)
- 生成算法、预训练模型、多模态技术等AI技术汇聚发展，为AIGC的爆发提供了肥沃的技术土壤。
- AIGC面临许多科技治理问题的挑战。目前主要是知识产权、安全、伦理和环境四个方面的挑战。

思考：
- 1、传统的**判别式模型**解决了模态识别问题，而**生成模型**赋予了人工智能灵魂，从一个工具变成了一个“人”工智能。
- 2、算法推动了技术的发展 ，但算法就像艺术品，很难去投资算法，更多是去欣赏，观察技术奇点过后的应用爆发+大模型带来的产业变化。

AI发展多年，过去解决的多是**模态识别**的问题，比如最成功的案例,图像识别。采用CNN算法，把信息与图能够通过AI训练的方式给训练出来，教会了AI去识别某个模态，在教科书里，被称为`判别式模型` (Discriminant Model) 。
- 抽象来看，就是训练一个巨大的神经网络（多层多参数）来实现输入和输出的映射关系。
- 从数学来看，就是学习输入输出的**条件概率分布**，类似于因果关系。算法的本质是想更准确的控制映射关系。

除此之外，还有一种叫`生成式模型` (Generative Model)， 是学习数据中的**联合概率分布**，类似于相关性，算法的本质并不是准确控制映射关系，而是在有相关性的基础上学习一个分布。

## AIGC企业

### AIGC TOP 机构

AIGC模型十大开发机构
- Google ＞ META ＞ OpenAI ＞ BAAI ＞ 清华 ＞ Microsoft ＞ 百度 ＞ 阿里巴巴 ＞ DeepMind ＞ AI2
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr4Nu73RdU4Y~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=8BMrlkYv4fQcQ5cNMjwqCNEM%2Bks%3D)

从AIGC模型数量上来看，全世界前十的AIGC模型研发者中，中国机构占了四个。其中有**学院派**的BAAI智源研究院和清华大学，也有**产业界**的百度和阿里巴巴研究院。顶级的西方AI机构谷歌、Meta还有OpenAI当然也榜上有名。值得一提的是，除了英美之外，虽然以色列有AI21，加拿大有Cohere，只有中国有多家机构在研发AI模型。

中国企业近几年在自主研发上下的功夫也为AIGC产业打下了基础。
- 百度的飞桨`PaddlePaddle`和华为`MindSpore`开源框架。
- 这些框架和国外常用框架（比如`TensorFlow`和`PyTorch`）的不兼容可能会限制国产框架的发展，但是例如`Ivy`这样的框架转换器或许能成为中西方AI框架的桥梁。

从预训练语言模型的参数量来看，很多中国模型其实并不比西方逊色。但是站在用户体验的角度，ChatGPT确实要领先于中国的语言模型，还有西方其他公司的模型。中国的开发者总能够赶上西方的领头羊，但是这个技术追赶的过程却需要2-3年。比如，OpenAI在2020年6月推出GPT-3模型，中国的智源、华为、百度在差不多一年之后才研发出了体量与之相当的模型，又用了一段时间才让模型的技能和GPT-3相媲美。
- ![](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TWUr4PJIiUhvJM~noop.image?_iz=58558&from=article.pc_detail&x-expires=1678177682&x-signature=Ft0aXJwijD8KvI6DdH6mVJMStCY%3D)


### AIGC 受益厂商

AIGC 受益厂商: 参考[ChatGPT 持续创造历史记录：AIGC，人工智能的旷世之作](https://www.toutiao.com/article/7196594313236251196)
- 1）AI **处理器**厂商：
  - AI 处理器芯片可以支持深度神经网络的学习和加速计算，相比于 GPU 和 CPU 拥有成倍的性能提升，和极低的耗电水平。
  - 受益标的：`寒武纪`、`商汤`、`海光信息`；
- 2）AI **商业算法落地**厂商；
  - AI 算法的龙头厂商在自然语言处理、机器视觉、数据标注方面都具有先发优势。
  - 收益标的：`科大讯飞`、`拓尔思`，其他：`汉王科技`、`海天瑞声`、`虹软科技`、`云从科技`、`格灵深瞳`；
- 3）AIGC 相关**技术储备应用**厂商。应用厂商有望打开海量市场:
  - 相关娱乐、传媒、新闻、游戏、搜索引擎等厂商具备海量文本创作、图片生成、视频生成等需求，随着 AIGC 的逐渐成熟，相关 AI 算法不断成熟完善，并结合相关应用，相关厂商在降本增效的同时，有望提升其创作内容的质量、减少有害性内容传播等问题，实现创意激发，提升内容多样性，AIGC 有望极大推动相关厂商商业化的发展，从而打开海量空间。
  - 受益标的：`万兴科技`、`中文在线`、`阅文集团`、`昆仑万维`、`视觉中国`。
- 总结
  - 科大讯飞: 自然语言处理的全球龙头厂商。2022 年初正式发布了“讯飞超脑 2030 计划”，其目的是向“全球人工智能产业领导者”的长期愿景迈进。
  - 拓尔思: 语义智能领导者，数据要素市场综合服务商。子公司天行网安提供数据安全传输和交换产品及服务
  - 汉王科技: 人工智能领域领先者，成立于 1998 年，是人脸识别、大数据、智能交互技术、产品及服务的提供商。e 典笔、汉王电纸书、汉王笔、文本王、名片通、绘图板等
  - 云从科技: 人机协同生态体系赋能商。云从科技是一家专注于提供人机操作系统和行业解决方案的人工智能企业

国内外已有多家科技巨头在AIGC领域布局。国内BAT、字节、网易等公司，国外谷歌、Meta、微软等多家公司，均推出了AIGC的应用产品。
- 国内外科技公司在AIGC上的布局
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TV58W5vBAyReYE~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676359273&x-signature=UZByEfy0uHIAOT3%2FiaMNj8aVdVk%3D)
- AIGC公司估值
- ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TV3vlskAr59sWo~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676359273&x-signature=9%2BEBONIbDv14bN5bOElzqiyasV0%3D)
- 参考：[ChatGPT爆火，一年吸金数十亿，一文读懂AIGC赛道风口](https://www.toutiao.com/article/7196926614918627899)

【2023-1-31】[从ChatGPT说起，AIGC生成模型如何演进](https://m.gelonghui.com/p/572090)

什么样的企业，才是这波浪潮的“宠儿”？ 
- 首先，无疑是掌握核心前沿技术的行业引领者。全球TOP3的人工智能研究机构，都在各出奇招、争夺AIGC主导地位。
  - OpenAI是文字生成领域的领航员。 不光吸引了“生成对抗网络之父”Ian Goodfellow加盟，还早早获得了微软的10亿美元投资。从GPT到GPT3.5，OpenAI不断迭代，也不断带给行业惊喜。这一次的ChatGPT更加获得了微软的认可。而通过开放GPT-3受控API的模式，OpenAI也将赋能更多公司和创业者。 
  - DeepMind是通用型AI的探路人。2016年，AlphaGo击败人类围棋的最高代表韩国棋手李世石，Go背后正是谷歌旗下的DeepMind。但DeepMind的目标并不是下棋，而是通用型AI，比如能预测蛋白质结构的AlphaFold、能解决复杂数学计算的AlphaTensor等等。但这些AI始终面临着一个瓶颈，即无法像人类一样进行“无中生有”的创作。 
  - 这两年，DeepMind终于向通用型AI又推近了一步。在对话机器人Sparrow、剧本创作机器人Dramatron等背后的语言大模型中找到灵感，构建了会聊天、会干活、会玩游戏的Gato。 
  - Meta在加速AI的商业化落地。重组调整AI部门，将其分布式地下放到各实际业务中，而FAIR被并入元宇宙核心部门Reality Labs Research，成为新场景探索者的一员。 Meta首席人工智能科学家Yann LeCun对ChatGPT的评价并不高，他认为从底层技术上看，ChatGPT并不是什么创新性、革命性的发明，除了谷歌和Meta，至少有六家初创公司拥有类似的技术。 
- 其次，另一类宠儿，则是押对应用场景的企业们，在“绘画”之外吸纳了不少资本支持与人才投入。
  - 在所有内容生成式AI中，输出文字和音乐的已经先一步找到了财富密码。最早出现的AI生成文字在遍历了写新闻稿、写诗、写小剧本等颇受关注的应用方式后，终于在营销场景找到了能够稳定变现的商业模式，成为写作辅助的效率工具，帮助从业者写邮件、文案、甚至策划。专注于音乐的LifeScore，则让人工智能学会了即时编曲，按照场景、长度的需要，组织艺术家同事人工创作、演奏的音乐素材，在人类的创作流程中找到了自己的位置。 
  - 能够互动的聊天机器人，则在客服和游戏这两个相去甚远的行业分别“打工”。区别于当下只会提供预设问题解答，有时还会答非所问的“智能客服”，真正的AI需要结合用户的行为和上下文来理解人类的真正意图。在游戏领域，AI则被用来协助人类，高效地创造内容丰富、体验良好的游戏内容，从而延长用户的游戏时间。 

显然，宠儿是少的。而经历了过去一年多“科技股大回落”后，投资者们也谨慎一些了，当下的AIGC虽然很好，但等大模型出来也许更香。 

大模型，也许是企业比拼的护城河
- 模型是人工智能的灵魂，本质上它是一套计算公式和数学模型。“参数”可以看做是模型里的一个个公式，这意味着，参数量越大，模型越复杂，做出来的预测就越准确。 
- 小模型就像“偏科的机器”，只学习针对特定应用场景的有限数据，“举一反三”能力不足，一些智能产品被用户调侃为“人工智障”的情况时有发生。 
- 大模型就是参数量极大的模型，目前业界主流的AIGC模型都是千亿级、万亿级参数量的水平。通过学习各行各业各类数据，除了能给出相较于小模型更准确的预测结果之外，它也展现出了惊人的泛化能力、迁移能力，产出内容质量更高、更智能，这也是当前AIGC工具让人眼前一亮的原因。 

而大模型的快速发展，对行业发展起到了明显的推动作用。例如ChatGPT是基于GPT-3模型进行优化所产生的，引领AI绘画发展的DALL·E 2也离不开GPT-3的贡献。类似的还有Deepmind的Chinchilla、百度的文心大模型等等。 

大模型，很大概率是行业淘汰与否的判断要素。
- 首先，训练数据量大，OpenAI为了让GPT-3的表现更接近人类，用了45TB的数据量、近 1 万亿个单词来训练它，大概是1351万本牛津词典。
  - 这就带来了两个问题：巨大的算力需求与资金消耗。训练和运行模型都需要庞大的算力，有研究估测，训练 1750 亿参数语言大模型 GPT-3，需要有上万个 CPU/GPU 24 小时不间输入数据，所需能耗相当于开车往返地球和月球，且一次运算就要花费450万美元。 
  - 国内也不例外。目前国内自研的大模型包括百度的文心大模型、阿里的M6大模型、腾讯的混元大模型，针对中文语境，国内厂商的表现要比国外大厂要好得多。而且国内的大模型发展速度也很惊人。 
  - 采用稀疏MoE结构的M6大模型，2021年3月仅1000亿参数，3个月后就达到了万亿级，又过了五个月模型参数达到了十万亿级，成为全球最大的AI预训练模型。混元模型也是万亿级别，成本大幅降低，最快用256张卡，1天内就能训练完成。而采用稠密结构（可以粗糙理解是和稀疏相比，密度更大）的文心大模型，2021年，参数规模达到2600亿。2022年，百度又先后发布了数十个大模型，其中有11个行业大模型。 
  - 这样高的研发门槛，注定目前主流的大模型多由大企业、或是背靠大企业的研究机构掌握，中小企业只能望而却步。因此，大模型，也就成为企业的“护城河”。 
- 大模型的研发只是“成功第一步”，还有三个维度的比拼，也非常重要。 
  - 一是数据资源。 有研究表明，到2026年就没有更多高质量的数据可以训练AI了。此外，基于现实生活中已有的数据来训练模型只能解决一些已知问题，对于一些我们还没有发现的、潜在的、未知的问题，现在的模型未必能解决。因此有一些研究人员提出了合成数据的概念，即通过计算机程序人工合成的数据，一方面补充高质量的训练数据，另一方面填补一些极端或者边缘的案例，增加模型的可靠性。 
  - 二是绿色发展。 虽然模型越大效果越好，但无限“大”下去并不经济，对自然资源消耗、数据资源都带来巨大压力。而过高的资源消耗，也不利于平民化普及。 
  - 三是应用场景 。商业和纯理论研究不同，不能拿着技术的锤子，瞎找钉子，而是要结合应用来发展技术。而国内厂商要想拿出Stable Diffusion、ChatGPT这样的杀手级应用，还需要更多的思考和努力： 




## AIGC为什么火

【2023-2-1】AIGC为什么火？

《[腾讯研究院AIGC发展趋势报告](https://www.baogaoting.com/info/237112)》中提到：内容创作模式的四个发展阶段
- `PGC`：专家制作，2000年左右的web 1.0门户网站时代，专业新闻机构发文章
- `UGC`：用户创作，2010年左右web 2.0时代（微博、人人之类），以及移动互联网时代（公众号），用户主导创作，专家审核
- `AIUGC`：用户主要创作，机器（算法）辅助审核，如在抖音、头条、公众号上发视频、文章，先通过算法预判，再人工复核，在成本与质量中均衡
- `AIGC`：AI主导创作，以2022年底先后出现的扩散模型、ChatGPT为代表，创作过程中，几乎不需要人工介入，只需一句话描述需求即可。
- ![img](https://picx.zhimg.com/80/v2-52d428e29c44a22a9a06f7bf85a8fd27_720w.webp?source=1940ef5c)

AI自动生成内容的方式实现了AI从感知到生成的跃迁

2022年,gartner将AIGC列为最有影响力的5大技术之一。2022年也被称为AIGC元年.

技术角度上，过去几年**生成算法**（VAE/GAN）、**预训练模型**（Transformer/GPT）、**多模态技术**（CLIP/DALL-E/扩散模型）的不断积累、融合，催生了AIGC的爆发
- ![img](https://picx.zhimg.com/80/v2-7395e865a5c99747f398095629227b4b_720w.webp?source=1940ef5c)

AIGC产业生态逐步成型，分为上中下三层架构。
- 第一层为**基础层**：就是由预模型 AIGC 技术搭建的基础设施层，目前企业为头部科技企业例如 OPEN AI 和 Stability 等。
- 第二层为**中间层**：即垂直化、场景化的模型和应用工具，通过使用基础层的模型生成应用程 序，供应用层使用可以在基础层的基础上快速生成场景化、定制化、个性化的模型和程序，例如 Novel-AI；
- 第三层为**应用层**：即面向 C 端用户文字、图片、音视频等内容生成服务。
- ![img](https://pica.zhimg.com/80/v2-0066f7a5012587119552fd189ce45113_720w.webp?source=1940ef5c)

知乎作答：[为什么生成式 AI 会变得火爆？ - 鹤啸九天的回答](https://www.zhihu.com/question/575987790/answer/2869714170)

## AIGC 是如何一步步突破的

【2023-1-31】[从ChatGPT说起，AIGC生成模型如何演进](https://m.gelonghui.com/p/572090)

AI懂创作、会画画，可以说是人工智能的一个“跨越式”提升。虽然人工智能在生活中不断普及，比如我们习惯了机器代替人去搬运重物、制造精密的产品、完成复杂的计算等等。但是，如果人工智能更接近人，那就必须具备人类“创作”的能力。这就是AIGC的意义。 

AI能力的提升，并不是一蹴而就，而大部分则经历了“模型突破-大幅提升-规模化生产-遇到障碍-再模型突破-大幅提升”的循环发展。而要实现落地、走进人类生活，则必须具备“规模化生产”的能力，在资源消耗、学习门槛等方面大幅降低到平民化。 

比如以AI画画为例，则经历了三个关键节点： 
- 第一个节点，早期突破：2014年，**对抗生成网络**（GAN）诞生，真正“教会”AI自己画画。
  - GAN包含两个模型，一个是生成网络G、一个是判别网络D。G负责把接收到的随机噪声生成图片，D则要判断这张图是G画的、还是现实世界就存在的。G、D互相博弈，能力也不断提升，而当D不再能判断出G生成的图片时，训练就达到了平衡。 
  - GAN的开创性在于，精巧地设计了一种“自监督学习”方式，跳出了以往监督学习需要大量标签数据的应用困境，可以广泛应用于图像生成、风格迁移、AI艺术和黑白老照片上色修复。 
  - 但其缺陷也正来源于这一开创性：由于需要同步训练两个模型，GAN的稳定性较差，容易出现模式崩溃。以及另一个有趣的现象“海奥维提卡现象”（the helvetica scenario）：如果G模型发现了一个能够骗过D模型的bug，它就会开始偷懒，一直用这张图片来欺骗D，导致整个平衡的无效。 模型也会躺平，这鸡贼的特性，真是有人的风格。 
- 第二个节点，大幅提升：2020年，一篇关于**扩散模型**（Diffusion Model）的学术论文，大幅提升AI的画画水平。
  - 扩散模型的原理是“先增噪后降噪”。首先给现有的图像逐步施加高斯噪声，直到图像被完全破坏，然后再根据给定的高斯噪声，逆向逐步还原出原图。当模型训练完成后，输入一个随机的高斯噪声，便能“无中生有”出一张图像了。 
  - 这样的设计大大降低了模型训练难度，突破了GAN模型的局限，在逼真的基础上兼具多样性，也就能够更快、更稳定的生成图片。 
  - 扩散模型在AI业界的“起飞”源于2021年1月，Open AI基于此开发出DALL·E文字生成图片模型，能够生成接近真实生活但并不真实存在的图片，让AI业界震了三震。但由于在像素空间进行了大量计算，这一模型仍存在进程缓慢、内存消耗大的缺陷。 
- 第三个节点，**批量生产**：2022年夏天诞生的Stable Diffusion，让高大上的学术理论变得“接地气”。
  - 去年8月，Stability AI将扩散过程放到更低维度的潜空间（Latent Diffusion），从而开发出了Stable Diffusion模型。这个模型带来的提升，在于资源消耗大幅降低，消费级显卡就可以驱动的，可以操作也更为方便，普通人也可以体会到人工智能惊艳的创作能力。而且开发团队还把所有代码、模型和权重参数库都进行了开源，践行了Geek的共享精神、去中心化主义。 
  - 门槛降低、效果提升，因此，大受欢迎。发布10天后，活跃数据达到了每天1700万张，如果都用A4纸打印出来叠一起，相当于一座52层高的大楼。 
  - 共享，也是Stability AI的另一特色。在开源社区中，除了更小的内存和更快的速度，Stable Diffusion收获了更完善的指南与教程、共享提示词、新UI，也依靠集体的智慧，走进了Photoshop、Figma等经典软件，汇入创作者们的既有工作流中。可谓是，依靠群众、回馈群众。 

从技术实现突破、到技术提升、再到规模化降低门槛，AI创作能力也不断提升。
- 2022年10月，美国一名男子用AI绘画工具Midjourney，生成了一幅名为《太空歌剧院》的作品，并获得了第一名。这引起了一波不小的争论，也终于形成了一条新赛道。
- 2022年以AI绘画为代表的各种生成式AI工具，如雨后春笋般疯狂冒尖，比如盗梦师、意间AI、6pen、novelAI等等。 

而在文本AI领域也是如此。如今大火的ChatGPT则是基于GPT3.5模型，已经迭代了4次。而对话一次的平均成本为0.01-0.2美元，也就是六毛到一块钱人民币，成本依然需要不断降低。但整体而言，无论画画、还是聊天，AI已经体现出智慧涌现。


## AIGC 技术进展

`算力`、`算法`、训练`多模型`、`多模态`等 AI 技术融合极大的催生了 AIGC 的爆发。
- 1）`基础算力`：人工智能的本质及数据的海量运算，相较于 AI 算法，数据才是重中之重。算力作为数据加速处理的动力源泉，其重要性不言而喻。
  - 根据机器学习的算法步骤，可分为训练和推断两个环节，训练环节需要极为庞大的数据输入才能支持一个复杂的神经网络模型，训练过程中由于复杂的神经网络结构和海量训练数据，运算量巨大，因此对于处理器的算力、效率(能耗)要求极大。
- 2）`算法模型`：Transformer 算法是一种采用自注意力机制的深度学习模型，这一机制可以按照输入数据各部分的重要性的不同而分配不同的权重，现在熟知 ChatGPT 和 AI 作图等都是基于 Transformer 算法建立的；
  - ![img](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/1122923c43d243f4aed78b7b533d66e2~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676258271&x-signature=V3RsD1OVm3OdiEmWzloCJy3o%2Fho%3D)
  -  Transformer 它的结构和人脑里面的整个 neocortex （新皮层）一个 6 层的神经元之间的结构是有一定相似度的。
- 3）`预训练模型`：预训练模型引发了 AIGC 技术能力的质变，在该模型问世之前，具有使用门槛高、训练成本低、内容生成简单和质量偏低等问题。
  - 而在 AIGC 领域，AI 预训练模型，AI 预模型可以实现多任务、多语言、多方式等至关重要的作用，模型比如谷歌的 LaMDA 和 PaLM，Open AI 的 GPT 系列。
  - ![AIGC预训练模型一览](https://p3-sign.toutiaoimg.com/tos-cn-i-qvj2lq49k0/11cb1660d4b04155910b5d4a625ababc~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676258271&x-signature=rO%2FReI3%2FXscbMOm%2B2TEZKr2LLn4%3D)
- 4) `多模态`：极大推升 AIGC 的多样性，预测模型更具备通用性、多样性。例如 Open AI 团队的 CLIP 模型，可以使文字和图像进行关联，比如将文字“狗”与图像进行关联，且关联特征非常丰富。

AIGC技术场景中的内容分支及具体应用
- ![AIGC技术场景中的内容分支及具体应用](https://p3-sign.toutiaoimg.com/tos-cn-i-tjoges91tu/TV3vkM2HVU1AwG~noop.image?_iz=58558&from=article.pc_detail&x-expires=1676359273&x-signature=dEA7Z%2FTv9IWKEva5gx51%2FSJaRAg%3D)
- 参考：[ChatGPT爆火，一年吸金数十亿，一文读懂AIGC赛道风口](https://www.toutiao.com/article/7196926614918627899)

AIGC 的应用生态和内容消费市场逐渐繁荣: AIGC 在学习通用知识和理解泛化上具备更好的表现，在内容生成领域中具备以下特征。
- 1) 自动生成内容：大型语言和图像 AI 模型可用于自动生成内容，例如文章、博客、社交媒体和帖子。
- 2) 提高内容质量：我们认为 AI 生成内容质量较高，原因是人工智能模型可从大量数据中学习，且信息准确，例如 DALL·E 的效果已经接近中等画师的水平。
- 3) 增加内容多样性：AIGC 模型可以生成多种类型的内容，包括文本、图像和音视频、3D 内容等，这些内容可以和专业认识创建更多样化、有趣的内容，有望吸引更广泛的人群。
- 4) 内容制作成本低：基于 AIGC，内容制作的成本显著降低、效率显著提高，且可以创造出有独特价值和独立视角的内容。
- 5) 可实现个性化内容生成：人工智能模型可根据个人用户喜好生成个性化内容，例如 Stable Diffusion 的二次元画风生成工具 Novel-AI，可以满足小众二次元群体的喜好和内容需求。

AIGC 前景广阔，且已经有多种落地场景：比如目前火热的 ChatGPT，ChatGPT 是采用 WEB 浏览器上的对话形式交互，可以满足人类对话的基本功能，能够回答后续问题、承认错误、质疑不正确的请求，我们认为 ChatGPT 的编码能力和 AI 问答系统能力已经大幅提升，并且可以一定程度上替代搜索引擎。

数字人也是 AIGC 的应用场景之一：数字人是数字智能体智能交互的新模式，目前已有诸多应用，包括元宇宙应用的 NPC 虚拟角色、用户虚拟等。

AIGC 大大提升了数字人的制作能效，用户可提供图片、视频，通过 AIGC 生成写实的类型数字人，具有时间短、成本低、可定制特点，同时，3D 数字人建模已经初具产业化。

此外，AIGC 支撑了 AI 驱动数字人多模态交互中的识别感知和分析决策功能，使其更神似人。



# 结束