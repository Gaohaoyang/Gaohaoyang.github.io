---
layout: post
title:  "知识追踪-knowledge tracing"
date:   2020-11-20 16:01:00
categories: 深度学习
tags: 知识追踪 HMM 在线教育 认知诊断 可解释 GPT 
excerpt: 教育、培训领域，跟踪学员对某个知识点的掌握情况
author: 鹤啸九天
mathjax: true
---

* content
{:toc}

# 总结

- 【2022-8-5】[可解释深度知识追踪模型](https://crad.ict.ac.cn/CN/10.7544/issn1000-1239.2021.20211021)
  - 当前知识追踪方法多针对知识点建模，忽略了习题信息建模与用户个性化表征，并且对于预测结果缺乏可解释性.
  - 针对以上问题，提出了一个**可解释**的深度知识追踪框架.首先引入习题的上下文信息挖掘习题与知识点间的隐含关系，得到更有表征能力的习题与知识点表示，缓解数据稀疏问题.接着建模用户答题序列获得其当前知识状态，并以此学习个性化注意力，进而得到当前习题基于用户知识状态的个性化表示.最后，对于预测结果，依据个性化注意力选择一条推理路径作为其解释.相较于现有方法，所提模型不仅取得了更好的预测结果，还能为预测结果提供推理路径层面的解释，体现了其优越性.
- [knowledge-tracing最新进展](https://paperswithcode.com/task/knowledge-tracing)
  - [GIKT: A Graph-based Interaction Model for Knowledge Tracing](https://paperswithcode.com/paper/gikt-a-graph-based-interaction-model-for)
- [深度知识追踪（Deep Knowledge Tracing）论文学习](https://blog.csdn.net/sereasuesue/article/details/108686717)
- 知识追踪发展历程
  - `DKT`：只建模问题
  - `SKT`：只建模知识点
  - `DIKT`：同时建模问题、知识点

$$
\require{AMScd}
\begin{CD}
  DKT @>建模知识点>> SKT @>建模问题和知识点>> DIKT
\end{CD}
$$

# 知识追踪

## 什么是知识追踪

**Knowledge Tracing** 

> Def:  Knowledge tracing is the task of modelling student knowledge over time so that we can accurately predict how students will perform on future interactions. Usually by observing the correctness of doing exercises.

- **知识追踪**是基于学生行为序列进行建模，预测学生对知识的掌握程度。知识追踪是构建**自适应教育系统**的核心和关键。在自适应的教育系统中，无论是做精准推送，学生**学习路径规划**或**知识图谱构建**，第一步都是能够精准预测学生对知识的掌握程度。
- ![](https://img-blog.csdnimg.cn/20200919221855940.png)

知识追踪问题可以描述为： 
- 给定一学生的观测序列  $ x_0 ,……, x_t $ 预测下次表现 $x_(t+1)$ ，通常 $ x_t = { qt , at }$,  $x_t={q_t,a_t}$ ，其中
  - $q_t$代表回答的问题成分（如对应的知识点）
  - $a_t$ 代表对应的回答是否正确，通常 at={0,1} 。
  - 上图描述了一个学生在八年级数学中的知识追踪结果可视化展示。
- KT被制定为**监督序列**学习问题：给定学生过去的练习情况，预测学生正确回答新练习的概率。

知识追踪的任务是根据学生与智能教学系统之间的交互，自动跟踪学生的知识状态随时间的变化过程
- 知识追踪具有**自动化**和**个性化**的特点。

知识追踪简单的说就是“<span style="color:blue">边学边测</span>”问题，连续追踪学生在学习过程中的能力变化(即tracing)。
- 这个概念区别于专注于测试学生**能力水平**的模型，如`项目反应理论`(IRT)模型，测试场景的目标是快速、准确的测量出学生的水平。

### Q&A

概念对比
- 狭义的KT是专指**正确率预估模型**，本质是一个**二分类**深度学习模型，给出的结果是正确率：$ P(人,题）$。
- IRT是用来建模**题目**和**人**的能力的数学模型，简单的说：$ 正确率 = S曲线(人的能力 - 题目的难度) $，但大家常说的IRT和Bi-Factor是用**贝叶斯概率模型**来求解人的能力和题目的难度。
  - IRT是只考虑全局能力
  - Bi-Factor增加了人在知识点上的能力
- KLearning是一个推题策略，对标的是原有的“按照75%正确率推荐题目”的推题策略，Klearning想要对学生做题的提升度进行估计，按照单步提升度最大来推题。

KT在什么时候是可信的？什么时候不准？
- 按照目前的经验，一个题目被做了<span style="color:blue">5~10次<span>之后KT是准的。题目<5次的情况下，准确率会下降比较多。
- 做题次数过少的情况下，模型其实是按照<span style="color:blue">题目的泛化属性<span>，比如“同知识点”的题目来估计的。如果知识点也是新的，没有任何可以参考的信息，模型就只能参考所有人的全局准确率、该用户的全局准确率来估计。

KT能能估计考试吗？
- 题目维度的预估一定要有作答数据，否则效果跟使用学生知识点掌握度预估成绩类似。考题有其他学生的作答数据也可以。

英语/语文可以使用KT模型吗？
- 英语有很多公司是使用KT来预测的，这块公开的研究也比较多。但是其主要作用是提升了产品的留存率，即是在体验方面的提升。语文可能也是类似的，模型可能非常依赖做题数据来估计人的能力和题目的难度。


## 知识追踪发展

- 目前，教育领域通过引入人工智能的技术，使得在线的教学系统成为了**智能教学系统**（ITS），ITS不同与以往的MOOC形式的课程。ITS能够个性化的为学生制定有效的学习路径，通过根据学生的答题情况追踪学生当前的一个知识点掌握状况，从而可以做到因材施教。

三种模型对学生的知识点掌握状况进行一个追踪判断：
- **IRT**（Item response theory）  `项目反应理论`
  - 使用结构化的因子（人的能力、题的难度、题的区分度）。可以给出题目难度、区分度，学生能力值等数据。
- **BKT**（Bayesin knowledge tracing） 基于**贝叶斯网络**的学生知识点追踪模型
  - 早期的知识追踪模型都是依赖于一阶**马尔科夫模型**，例如**贝叶斯知识追踪**（Bayesian Knowledge Tracing）
  - 缺乏提取**未定义概念**和模拟复杂概念状态转换的能力；BKT不能捕捉不同概念之间的相关性，不能有效地表示复杂的概念状态转化。
  - 缺点：
    - 需要标记数据
    - 对每个知识点分别进行表达
- **DKT**(Deep konwledge traing)  基于**深度神经网络**的学生知识点追踪模型 
  - 利用LSTM来解决BKT的问题，DKT总结了学生在一个隐藏状态下所有概念的知识状态，这使其很难追踪学生掌握了某个概念的多少，而且很难指出学生擅长或不熟悉的概念。
  - 将深度学习的方法引入知识追踪最早出现于发表在NeurIPS 2015上的一篇论文《Deep Knowledge Tracing》，作者来自斯坦福大学。在这篇论文中，作者提出了使用**深度知识追踪**（Deep Knowledge Tracing）的概念，利用RNN对学生的学习情况进行建模，之后引出了一系列工作
  - 优点：
    - 比BKT模型有更好的预测能力，同时不需要专家对习题的知识点进行**标注**。
  - 缺点：
    - 表示能力受限：LSTM将所有的记忆存储在一个隐藏的向量中，很难准确地记住超过数百个时间步长的序列
- **MANN**：记忆增强神经网络—— 解决DKT问题
  - 2019年已经有使用Transformer代替RNN和LSTM并且达到了SOTA的论文。
- **DKVMN** （动态键值记忆网络）
  - DKVMN模型可以**自动**学习输入练习和基础概念之间的相关性，并为每个概念维护概念状态。在每个时间步，只有相关的状态会更新。
  - 优点
    - 借鉴了MANN的思想，同时又结合的BKT和DKT的优点，所以总体来说，它的预测性能是比较好的。与LSTM相比，它能避免过拟合、参数少，以及通过潜在概念自动发现相似练习。
  - 缺点
    - 计算知识增长的局限性
    - 过于依赖模型本身的遗忘机制
    - 预测过程中没有考虑遗忘机制
- **LPKT** （基于学习过程的知识追踪）
  - LPKT旨在通过模拟学生的学习和记忆过程来完成知识追踪。
  - LPKT过程：
    - 注意机制：计算一个问题涉及的知识点数和每个知识点所占的比例
    - 读过程：观察一段时间内学生在学习系统中的学习序列数据
    - 写过程：给定一个学生问答活动，代表学生的知识状态矩阵V由t-1时刻状态到t时刻状态
  - 在读过程中，模型根据当前知识状态计算知识遗忘量，再参考LSTM的遗忘机制，计算下一个时刻的知识状态。这个知识状态就比较符合学生的学习规律。
  - 而写过程则是根据MANN模型机制，在知识追踪的过程中跟新学生的动态知识状态。在更新状态时，会同时考虑遗忘机制，在DKVMN中被称作erase。遗忘过程中，不应该只考虑知识增量，同时还应该考虑学生学习持续时间。
  - LPKT相较于传统的BKT和DKT，都有较大的优势。同时它又结合了DKVMN的思想与优点，改进了遗忘机制上的不足，使得知识追踪的效率得到提高。

由于深度学习并不需要人类教会模型不同题目的难易、考核内容等特定的知识，避免了大量的手工标注特征工作量，而且在互联网在线教育行业兴起后，拥有了海量的学生答题记录，这些答题记录就能教会模型将题库中成千上万条题目encode为一个向量，并且能类似于word2vec那样找出题目之间的关联。

## BKT

BKT是最常用的一个模型，BKT是含有隐变量的**马尔可夫模型**（HMM）。因此可以采用**EM算法**或者bruteForce 算法求解参数。

学生对知识点的掌握有两个状态 {**掌握**, **未掌握**}，每经过一次学习动作（阅读、做题、学习课程），学生就有一定的概率从 未掌握 -> 掌握，对整个序列求解。

问题的难点在于：
1. 一些学习动作没有**反馈**（比如阅读材料）
2. 有反馈的动作（比如做题）也有很多**噪音**，P(做对) 不完全= P(掌握)，比如学生是猜对的，学生掌握了但不小做错了，学生“生搬硬套”做对了。

一个不恰当的比方：把学生学习的过程类比抽奖过程
- 学生面前有N个抽奖盒，每个盒子的中奖概率是不一样的，学生连续的去从每个盒子里面抽一次，最后离开了。我们可以观察到这个人抽奖完之后是否开心，越开心推测他已经中奖的概率越高。
- 观察到学生的表现: 没笑，笑了，没笑，大笑, ...
- 问题：学生最后有没有中奖？学生是在第几个盒子中的奖？

贝叶斯知识追踪模型在观测到一系列的行为和结果后，可以通过建模来指示学生在每一个环节上的能力值水平。能力水平的变化值可以给教学人员提供决策信息。

BKT是对学生知识点的一个变化进行追踪，可以知道学生知识点的一个掌握情况变化。
- 一般有个stop_policy准则，用于判断学生是否经过多轮的做题掌握了相应的知识点。      
  - Once that probability reaches 0.95, the student can be assumed to have learned the skill. The Cognitive Tutors use this threshold to determine when a student should no longer be asked to answer questions of a particular skill

- （1）首先我们来看一下BKT的模型是如何的：
- 如下图，是BKT的一个模型，以及对应的4个主要参数，L0，T，G，S。模型需要根据学生以往的历史答题系列情况学习出这4个对应的参数。
  - ![](https://images2015.cnblogs.com/blog/633472/201706/633472-20170630170929696-1687899647.png)
- BKT是对不同的的**知识点**进行建模的，理论上来说，训练数据有多少个知识点，就有多少组对应的（L0，T,G,S）参数。
  - L0：表示学生的未开始做这道题目时，或者为开始连续这项知识点的时候，他的一个掌握程度如何（即掌握这个知识点的概率是多少），这个一般我们可以从  - 训练数据里面求平均值获得，也可以使用经验，比如一般来说掌握的程度是对半概率，那么L0=0.5
  - T ：表示学生经过做题练习后，知识点从不会到学会的概率
  - G：表示学生没掌握这项知识点，但是还是蒙对的概率
  - S：表示学生实际上掌握了这项知识点，但是还是给做错了的概率
通过这4个参数，可以构造一个HMM的模型，剩下的事就是训练这个模型

- （2）有什么改进的吗？
  - 其实可以发现，这样构造模型，还是非常简单的，模型只是简单的针对知识点进行训练，所有的学生都是用的同一个模型。但是学生有好有坏，因此可以加个节点，不同的学生使用不同的L0。
  - 另外题目的难度也是可以应用到模型的，比如难度系数大的 G S参数就可以不一样。根据难度系数训练多组G S
 
- 参考论文：
  - From Predictive Models to Instructional Policies


## DKT

深度学习的好处（非深度学习方法也可以做，深度学习更灵活）：
1. **多目标**建模：可以对学生的正确率、做题用时同时建模，如果C端产品需要留存，也可以对中断进行建模
2. 行为数据建模：可以高效的使用各种行为数据，比如做题用时，看解答时间
3. 跨场景建模：可以对学习、练习、考试等场景进行综合建模
4. 多模态建模：可以利用行为数据、语音、图像等数据建模

DKT的内容：
- ![](https://pic1.zhimg.com/80/v2-f83067f9ddb315e9035e75b0feb8978c_1440w.jpg)
 
其中向量 ![[公式]](https://www.zhihu.com/equation?tex=x_%7Bt%7D) 表示的是用户答题记录的独热编码，由于独热编码太长，太稀疏，所以我们将其降维成小一些的向量 ![[公式]](https://www.zhihu.com/equation?tex=v_%7Bt%7D) ，之后将向量 ![[公式]](https://www.zhihu.com/equation?tex=v_%7Bt+%7D) 输入到循环神经网络中。其中循环神经网络中隐向量 ![[公式]](https://www.zhihu.com/equation?tex=h_%7Bt%7D) 表示的是用户的知识建模，循环神经网络输出向量 ![[公式]](https://www.zhihu.com/equation?tex=y_%7Bt%7D) 表示的是用户接下来做对题目的概率。
 
![](https://pic2.zhimg.com/80/v2-9057d82db0a9004dcee7386803dc9f65_1440w.png)
 
![](https://pic2.zhimg.com/80/v2-2cb602dff25c60356d6ab0b494349c99_1440w.png)
 
介绍完深度知识追踪模型之后，我们就要思考，如何将遗忘机制加入到DKT模型当中。首先要介绍的是与遗忘相关的信息。


### 改进

#### 遗忘机制

- [论文阅读笔记【13，参考遗忘的深度知识追踪模型】](https://zhuanlan.zhihu.com/p/112307768)
- WWW'19的一篇论文《Augmenting Knowledge Tracing by Considering Forgetting Behavior》。本论文其实是对原有知识追踪模型DKT（Deep Knowledge Tracing）的一种优化。DKT默认用户学到知识以后，是不会忘记的，但是实际上，学生学完知识以后如果很久都没有复习的话，依然是会产生遗忘的。

知识追踪要解决的问题有两个：
- （1）通过学生与学习系统内容的交互来对学生的知识进行建模
- （2）预测学生在未来做题中的表现。

#### 用户行为

- [论文阅读笔记【14，考虑用户行为的知识追踪】](https://zhuanlan.zhihu.com/p/112142513)
- 西北大学团队发表在TURC19的一篇文章《Muti-behavior Features based Knowledge Tracking using Decision Tree improved DKVMN》。
- 该论文所要解决的问题仍然是知识追踪问题，其目的有二，其一：追踪学生对于各个知识点的掌握情况；其二：根据学生当前对知识点的掌握情况，预测学生答对下一道题目的概率。
- 该论文是对于2017年论文《Dynamic Key-Value Memory Networks for Knowledge Tracing》的改进。其具体改进点在于：DKVMN模型没有在意用户在答题过程中的具体行为，仅仅在意用户最终是否答对习题。在e-learning环境下，这显然是有缺陷的。因为在线环境下，用户不仅仅可以在教学系统进行习题解答，还可以在教学系统查看答案，查看答案之后再对习题解答。试想，如果用户查看答案后，直接将答案复制下来，粘贴到作答区，这样学生知识水平或许完全没有变化，但是根据DKVMN模型，用户对于该知识点的理解一定会有提高，所以与事实不符合。
- 该论文正是关注到了用户行为对于答题情况，对于用户知识水平具有很大的影响，所以在这方面加以改进，提出了论文中所提到的模型Dynamic Key-Value Memory Networks with Decision Tree (DKVMN-DT)。

#### 知识点先验

- [论文阅读笔记【16，考虑知识点先验关系的知识追踪】](https://zhuanlan.zhihu.com/p/129898769)
- 北师大团队投稿在IEEE的论文。该论文同样是介绍知识追踪知识。论文的创新点在于，考虑了知识点之间的先验关系。
- 深度知识追踪DKT模型仅仅关注了学生的做题历史，将各个知识点视为是独立的毫无关联的个体，根据学生的做题历史去更新学生知识水平上的变化。但是现实生活中，知识点之间是存在先验关系得，比如java和spring就存在先验关系，没有学习过java语法得人，很难学会spring的知识。
 
![](https://pic3.zhimg.com/80/v2-71ff4b8181588712b99ac7de164c5762_1440w.jpg)
 
- 其中模型的输入有三个矩阵，最上面是学生的做题矩阵，描述的是每个学生的做题历史。中间的是试题-知识点矩阵，描述的是每道题目都包含了哪些知识点。最下面的是知识点之间的先验关系图，描述的是知识点之间的先验关系。
- 其实本文所使用的知识追踪方法和传统的DKT方法其实异曲同工，所选用的循环神经网络模型是GRU。
- 只是在描述知识点先验关系对知识追踪影响这个部分加入了一个先验条件。如果k1是k2的先验知识，那么如果学习者会k2，那么他学会k1的概率就会很大；相反如果学习者k1没有掌握，那么他学会k2的概率就会很低。举个例子就是，如果一个学生掌握了Spring，那么他很大概率就会掌握Java；相反如果一个学生没有掌握java，那么他很大程度没有掌握Spring。作者在原有DKT模型，加入了这个约束，从而可以根据知识点之间的先验关系去做知识追踪。

#### 题目相关性

- [论文阅读笔记【17，考虑问题之间关系得知识追踪】](https://zhuanlan.zhihu.com/p/138116440)
- 密歇根州立大学与TAL AI lab的一篇论文Deep Knowledge Tracing with Side Information，论文的目的依旧是知识追踪。该论文的创新点在于考虑了习题与习题之间的相关性。该论文基于传统模型DKT加以改进，提出了全新的模型DKTS，新模型考虑了问题之间的相关性。
- 众所周知，众多的习题并不是单独的个体，而是具有相关性的。不同的习题可能考察了相同的知识点，从而具有相关性。可能是考察相似的技能，从而具有相关性。但是传统模型DKT仅仅关注到学生对于习题的练习历史，但是并没有考虑到习题之间的相关性。
 
![](https://pic4.zhimg.com/80/v2-220e251b4a5b216b617bcee872f3a4fb_1440w.jpg)

## DKVMN模型

- 香港中文大学学者所写的《Dynamic Key-Value Memory Networks for Knowledge Tracing》，该论文发表在2017年的IW3C2上
- [知识追踪场景下的动态key-value记忆网络](https://zhuanlan.zhihu.com/p/55914739)
- KT的一个重要目的是个性化练习序列，以帮助学生有效地学习知识概念。KT被制定为监督序列学习问题：给定学生过去的练习情况，预测学生正确回答新练习的概率。
- 知识追踪（KT）的目标是根据学生过去的练习表现来追踪学生的知识状态。KT是在线学习平台的重要任务。 导师可以根据学生的个人优势和弱点，提供适当的提示并定制练习练习的顺序。学生可以了解他们的学习进度，并可以将更多精力投入到不太熟悉的概念上，以便更有效地学习。
- 贝叶斯知识追踪和深度知识追踪等现有方法要么单独为每个预定义概念建立知识状态，要么无法精确确定学生擅长或不熟悉的概念。
- 虽然贝叶斯知识追踪（BKT）可以输出学生对某些预定义概念的掌握程度，但它缺乏提取未定义概念和模拟复杂概念状态转换的能力。深度知识追踪（DKT）利用LSTM来解决BKT的问题，DKT总结了学生在一个隐藏状态下所有概念的知识状态，这使其很难追踪学生掌握了某个概念的多少，而且很难指出学生擅长或不熟悉的概念。
- 本文提出了DKVMN，具有利用概念之间的关系以及跟踪每个概念状态的能力。 我们的DKVMN模型可以自动学习输入练习和基础概念之间的相关性，并为每个概念维护概念状态。在每个时间步，只有相关的状态会更新。
- 为解决上述问题，本文提出了动态键值记忆网络（DKVMN），可以利用基础概念之间的关系，直接输出学生对每个概念的掌握程度。与利用单个记忆矩阵或多个静态记忆矩阵的记忆增强神经网络不同，我们的模型有一个静态矩阵（键）用来存储知识概念，还有一个动态矩阵（值）用来存储和更新对应概念的掌握程度。DKVMN模型可以自动发现通常由人类注释执行的练习的基本概念，并描绘学生不断变化的知识状态。

- ![](https://pic1.zhimg.com/80/v2-d696acc7f760c07340058ee05d7b74c0_720w.jpg)

## LPKT

[基于深度学习的知识追踪](https://segmentfault.com/a/1190000038939682)
- Knowledge Tracking Model Based on Learning Process一文中，介绍了一种知识追踪模型LPKT。这是一种基于现存深度学习的知识追踪模型的改进，该模型采用了记忆增强神经网络（MANN）的思想。

现存模型的缺陷
- 对于计算知识增长的局限性
- 模型遗忘机制不完善

# 神经认知诊断

- 认知诊断就是“诊断”被试内部的“认知加工过程”
- 以前只知道学生学习后的结果--**分数**，以此判定学生的水平、level、等级----**标准评价**；却不知道学生到底好在哪儿、差在哪儿（不是一般意义上知识好在哪儿差在哪儿）；学生在同一个水平时，为啥同样的教学方法下，学生的提高程度却不同。
- **认知诊断**可以把学生认知加工过程/心理过程展现给评价者。
  - 学生认知加工过程/心理过程是指学生学习时，到底学到了什么知识点，怎么学到的这个知识，会不会用，为啥能学会这个却学不会另一个知识点，学生为啥会用这个而不会用那个……同样的，不同学生为啥有人能学会有人学不会，有人知识点全记住了却答不对题，有人没记住书上原理却能解决题目……
  - 例子：十以内的加法。有的孩子是背下来的，毕竟十以内就这么几个数，靠记忆是完全可以的；有的学生是需要靠着实物帮助点数数出来 ；有的学生可以用接着数的方法算出来的；有的学生可能还会以5个一组来速算。表面上我们看到这些孩子是都会了十以内加法，是一样的，但其实他们的思考过程与方法都不一样。
- 以前只能靠老师和家长去发现孩子心理认知过程。有了认知诊断，就可以让评价者、教师更轻松了解学生内在心理的不同。当然，认知诊断理论需要有科学、有效的认知诊断模型、测量模型，才能达到精准“诊断”“认知加工过程”的目的。
- [知乎atticess](https://www.zhihu.com/question/383134450/answer/1444934329)

## 传统教育

考试这档子事，目前的问题在于反馈不准 & 反馈太慢：
- 反馈**不准**：一张卷子考了辣么多知识点，你丫就给我一个分数？我怎么知道哪些知识点掌握了，哪些还懵着？
- 反馈**太慢**：一个月，甚至一个学期才考一次。等到考的时候，都忘得差不多了。那难不成你要一天一考、一课一考？

认知诊断主要解决「反馈不准」的问题，至于改进反馈的即时性，可以用游戏化的手法解决

- [理解认知诊断](https://www.jianshu.com/p/032732d72a3a)

## 答题进阶

先看一张成绩单：

|学生|题1|题2|题3|题4|题5|<font color='green'>做对题数</font>|
|---|---|---|---|---|---|---|
|丁一|✓|✓|✓|✓|✓|5|
|陈二|✗|✓|✓|✓|✓|4|
|张三|✗|✗|✓|✓|✓|3|
|李四|✗|✗|✗|✓|✓|2|
|**王五**|✗|✗|✗|✗|✓|1|
|**赵六**|✓|✗|✗|✗|✗|1|
|<font color='red'>做错的人数</font>|4|4|3|2|1||

思考
- 王五和赵六都只得了 1 分，他俩学得一样好吗？
  - 赵六做出来的那道题，全班只有他和丁一做出来了
  - 而王五做出来的那题，全班除了赵六都能做出来。
- 每道题的难度是不一样的，是不是该区分一下啊？

于是，把「做错的人数」近似地看作「题目的难度」，重新给每道题赋分。
- 注：如果要细究「难度的定义」，应该从「涉及的知识点」去考虑。

|学生|题1|题2|题3|题4|题5|得分|
|---|---|---|---|---|---|---|
|丁一|4|4|3|2|1|14|
|陈二|0|4|3|2|1|10|
|张三|0|0|3|2|1|6|
|**李四**|0|0|0|2|1|3|
|王五|0|0|0|0|1|1|
|**赵六**|4|0|0|0|0|4|

这时，李四该跳起来了：
> 我做对了 2 道题，赵六才做对了 1 道，凭什么他的分比我还高？也许那一题是他蒙对的呢？

有道理啊，但我怎么知道他是不是蒙的呢？李四愤愤不平：
> 你看赵六那人就不是能做出题 1 的人，他其他题一道都没做出来，肯定是蒙的！

有点道理。那就用「总共做对了几道题」近似地去评估「一个人的**总体实力**」。实力越强，蒙的可能性越低；实力越弱，越可能是蒙的。

用「实力 - 难度」试试:

|学生|题1|题2|题3|题4|题5|得分|
|---|---|---|---|---|---|---|
|丁一|5-4|5-3|5-2|5-1|5-0|15|
|陈二|0|4-3|4-2|4-1|4-0|10|
|张三|0|0|3-2|3-1|3-0|6|
|李四|0|0|0|2-1|2-0|3|
|王五|0|0|0|0|1-0|1|
|赵六|1-4|0|0|0|0|-3|

「实力-难度」这个指标不光是一个算分的中间值，它还是一个用来衡量「某人做出这道题的可能性大小」的工具。比如，哪怕让丁一去做题 1 ，也会很费劲 5 - 4 = 1；但让他去做题 5 ，则很轻松 5 - 0 = 5 。

那如果这几道题，不是考题，而是**知识点**呢？能不能用这个工具去评估学生对各个知识点的掌握程度呢？我们只需要对它做一个 logistic 变换，就可以把它变成一个 0 到 1 之间的小数，能否用这个小数作为「某人做出某道题的概率」？某人做出某道题的概率P

$$  P = \frac{1}{1 + \exp^{-(实力-难度)}} $$

[吴文中公式在线LaTeX编辑器](https://latex.91maths.com/)

|学生|知识点1|知识点2|知识点3|知识点4|知识点5|
|---|---|---|---|---|---|
|丁一|0.73|0.88|0.95|0.98|0.99|
|陈二|0.50|0.73|0.88|0.95|0.98|
|张三|0.50|0.50|0.73|0.88|0.95|
|李四|0.50|0.50|0.50|0.73|0.88|
|王五|0.50|0.50|0.50|0.50|0.73|
|赵六|0.05|0.50|0.50|0.50|0.50|

奇怪，为什么好些个没拿分的题显示的是 0.5 呢？其实，0.5 在 logistic 的语境中，就是「不确定」的意思。概率很大，接近于 1 ，就是「掌握了」；概率很小，接近于 0 ，就是「没掌握」。

如果横向不是学生，而是一道道题呢？如果这不是一张成绩单，而是一张「知识点涵盖矩阵」呢？

|题号|知识点1|知识点2|知识点3|知识点4|知识点5|做对与否|
|---|---|---|---|---|---|---|
|一|✓|✓|✓|✓|✓|✗|
|二|✗|✓|✓|✓|✓|✗|
|三|✗|✗|✓|✓|✓|✗|
|四|✗|✗|✗|✔|✔|✓|
|五|✗|✗|✗|✗|✔|✓|
|六|✓|✗|✗|✗|✗|✗|
|<font color='green'>做对该知识点的数目</font>|0|0|0|1|2|
|<font color='red'>知识点的难度</font>|4|4|3|2|1|

题一涵盖了全部知识点，而题六只涵盖了知识点 1 。那不就能用这种方式做到「评估知识点的掌握情况」了？需要注意的，实力那的值就不是这道题涵盖的知识点的个数了，而是学生做对某个知识点上的个数。

假设学生甲只做对了题四、题五


|知识点|知识点1|知识点2|知识点3|知识点4|知识点5|
|---|---|---|---|---|---|
|掌握程度|	1 / (1 + exp(-(0 - 4)))	|1 / (1 + exp(-(0 - 4)))|	1 / (1 + exp(-(0 - 3)))	|1 / (1 + exp(-(1 - 2)))|	1 / (1 + exp(-(2 - 1)))|
|值|	2%|	2%|	5%| 27%	|73%|

可以看到，甲对知识点 5 掌握得最好。简单来说，思路其实相当相当简单：
- 做对该知识点越多，掌握得越好；
- 该知识点在整套题中出现得越罕见，难度越大，越不容易掌握；

但上面这套算法没有解决一个很关键的问题：知识点之间是存在**依赖关系**的。
- 比如：要想掌握分数的通分，至少得先学会整数的加减、求公分母……吧。但以上算法并没有考虑这个。

解决的思路其实也很简单：挨个考察这个知识点「所有的先修知识点」的掌握情况。

首先，我们得先细致地考察一番知识点的内在结构。我们用一个矩阵来做这事。其实这完全是为了数学上处理方便，用 if-else 同样解决问题。
![](https://upload-images.jianshu.io/upload_images/22586-e79d7288d0b809e9.jpg)
- 画反了！！！知识点内在结构：1 表示行号节点是列号节点的「直接」先修知识点；0 表示没有联系。

但我们正在想要的是，能够回答「节点 i 是不是节点 j 的先修知识点，直接或者间接都行」的矩阵。其实我们只要对上面这个矩阵加上一个单位矩阵，再反复自相乘直到收敛就行了。注意是布尔相乘哦。
![](https://upload-images.jianshu.io/upload_images/22586-1b579c19446c4d40.png)
画反了！！！直达矩阵

现在，你问「知识点 2 是不是知识点 5 的先修知识点？」，只要查第 2 行第 5 列是否为 1 就行了。我们先给个记号：q(5 → 2) = 1 。「q」就是 required 的意思啦。

好，搞定第一个工具。

下面要讲的，数学形式可能和上面那个「实力 - 难度」公式不同，但本质是一个意思。

下面我们构造一个矩阵，如果甲同学在题 i 中掌握了知识点 j 所需的所有知识点，记作 1；反之，为 0 ：

|题号|知识点1|知识点2|知识点3|知识点4|知识点5|做对与否|
|---|---|---|---|---|---|---|
|一|0|0|0|0|0|✗|
|二|0|0|0|0|0|✗|
|三|0|0|0|0|0|✗|
|四|0|0|0|1|1|✓|
|五|0|0|0|0|1|✓|
|六|0|0|0|0|0|✗|

[《认知诊断？基于一个案例的理解（改进版）》](http://www.sohu.com/a/208620978_763487)


## 介绍

- **认知诊断**在在线智能教育领域是一个非常经典的问题。根据学生的答题历史记录，分析学生对于各个知识点的掌握情况。如图1所示，总共有4道习题，学生对四道习题进行作答，认知诊断模型将<font color='blue'>根据学生的作答记录分析出学生对于题目中包含知识点的掌握情况</font>。
- ![](https://pic4.zhimg.com/80/v2-4657227c217b78a23e23c7f96a3cf3e7_1440w.jpg)

- **认知诊断**问题需要从以下三个方面去考虑：1，学生模型；2，试题模型；3，学生试题交互模型。
  - **学生**模型：将学生对于各个知识点的掌握程度向量![](https://www.zhihu.com/equation?tex=F%5E%7Bs%7D)作为学生建模结果。
  - **试题**建模：试题建模分为两个部分，其一是试题中包含哪些知识点，这些都是通过人工标注的Q矩阵得到的；其二就是试题本身的特征，比如试题难度，试题的区分度等等。
  - **学生-试题**交互建模：通过神经网络模拟学生与试题之间的交互建模。向网络中输入学生模型与试题模型，最终输出学生做出各个习题的概率。

## 传统方法

- 传统的认知诊断模型，比如`IRT`，`MIRT`，`DINA`都是基于概率模型，相比于神经网络模型，具有有限的拟合能力。同时传统的认知诊断模型往往需要较多的人工标注工作，因此会耗费大量的人力。

## 深度学习方法

- 迫切希望构造出可以**自动识别且具有较大拟合能力**的认知诊断模型。

### NeuralCDM模型

- 【2021-3-30】[论文阅读笔记【12，神经认知诊断】](https://zhuanlan.zhihu.com/p/110913207)，中科大陈恩红，刘淇团队发表在AAAI 2019 [Interpretable Cognitive Diagnosis with Neural Network for Intelligent Educational Systems](https://www.aminer.cn/pub/5d63adc33a55ac410be3288f/interpretable-cognitive-diagnosis-with-neural-network-for-intelligent-educational-systems)

示例
- ![](https://pic4.zhimg.com/80/v2-eb47e7cde66dd36cf31d8027e09d2f3b_1440w.jpg)
- 解释
  - Student One-hot向量是表示**学生向量**，是一个one-hot向量，将其与A矩阵相乘，得到的是反应**该学生知识水平**的向量。
  - Exersice One-hot向量是表示**练习向量**
    - 将其与Q矩阵相乘，得到的是表示**试题包含知识点**的向量 ![[公式]](https://www.zhihu.com/equation?tex=F%5E%7Bkn%7D) （与 ![[公式]](https://www.zhihu.com/equation?tex=F%5E%7Bs%7D) 维度相同）；
    - 将其与B矩阵相乘，得到的是表示**试题难度**的向量；
    - 将其与D向量相乘，得到的是表示**试题区分度**的标量。

通过计算式1，得到全连接层的输入x。
 
![](https://pic1.zhimg.com/80/v2-01fc57153758fe7b4046cda7f6e9203c_1440w.png)
 
将x输入到全连接层以后，得到的是认知诊断模型对于学生作对题目的预测。
 
![](https://pic1.zhimg.com/80/v2-3a21482cb3edd3facf74b82b88b3a86c_1440w.jpg)
 
我们通过学生答对题目的预测概率值与真实值的交叉熵损失函数，更新各个参数。从而进行模型的训练。
 
![](https://pic3.zhimg.com/80/v2-ca24d9b386df0833fd8789958429521a_1440w.png)
 
以上就是NeuralCDM模型的分析。作者发现之前的认知诊断模型都是考虑学生做题日志，很少有考虑到习题内容本身的，但是习题内容本身又是十分重要的因素，很多时候，通过阅读习题内容，便可以了解到习题考察了什么知识点。因此，作者通过CNN技术，对习题内容进行学习，通过习题的文本内容，对习题所包含哪些知识点进行分类。由于Q矩阵是由权威专家标注的，因此具有更高的权威性，因此，通过CNN网络学习的内容往往只是达到补强枪效果。
 
![](https://pic4.zhimg.com/80/v2-182187ecfc61a4ef0d5c418eaf49c6eb_1440w.jpg)
 
比如图三所示。Q矩阵显示该题目包含知识点3和知识点4。但是CNN模型显示包含知识点1和知识点3。这时，我们会综合考量Q矩阵和CNN，但是Q矩阵的权重更大，而CNN的权重较小。所以知识点1的考察度仅仅为0.3，知识点三由于既被Q矩阵标注又被CNN所识别，所以知识点3的权重最大。
 
下面我们介绍一下NeuralCDM和传统模型IRT以及MIRT的兼容性。
 
![](https://pic1.zhimg.com/80/v2-78d050b82ea2f58c19455b9329826ff0_1440w.jpg)
 
图4所示，NeuralCDM模型相较于IRT模型，可以考察更多的试题-学生交互历史，而IRT仅仅可以考虑一个交互历史；同时NeuralCDM具有多层神经网络，而IRT仅仅有单一算式，因此NeuralCDM相较于IRT具有更高的拟合性。
 
![](https://pic1.zhimg.com/80/v2-5ffbabc53df904db285e8a489b54fb1c_1440w.jpg)
 
图5所示，是NeuralCDM相较于MIRT的区别，两者都可以考察多交互历史，但是NeuralCDM相较于MIRT具有更高的拟合能力。


# 落地案例

## 在线教育

- 【2021-3-31】[宝宝巴士与HarmonyOS携手打造更具交互性的早教体验](https://mp.weixin.qq.com/s/vZgf-FDI9ju4A4cKGImSZw)，宝宝巴士开发团队与华为HarmonyOS合作，设法利用智能手机、平板、智能电视和音箱等现有智能设备，构建一个沉浸式、交互式的早教场景体验
- 【2020-12-30】[AI在扇贝的应用：基于TensorFlow的DKT(深度知识追踪)系统实现](https://zhuanlan.zhihu.com/p/51098581)
  - 深度知识追踪系统可以实时地预测用户对词表上每个词回答正确的概率。介绍扇贝是如何实现深度追踪模型并运用到英语学习者词汇水平评估中去。
  - 总序列数量已经累积到千万级别，这为使用深度学习模型提供了坚实的基础。模型方面，我们选用了斯坦福大学 Piech Chris 等人在 NIPS 2015 发表的 Deep Knowledge Tracing (DKT) 模型 [1]，该模型在 Khan Academy Data 上进行了验证，有着比传统 BKT 模型更好的效果。
  - ![](https://pic1.zhimg.com/80/v2-bda4f0eecc8fe662fa5c3a055589120c_720w.jpg)
  - ![](https://pic3.zhimg.com/80/v2-813552c1da97863a2662cf087938b2a6_720w.jpg)
- 【2018-11-22】[67岁AI教父跳槽中国，放弃千亿美金巨头加盟初创公司](https://mp.weixin.qq.com/s/3KsTzVscWi5rnR1WbYpvXg?share_token=12a6d5ef-ec1d-4785-b505-d454551ba7fb), 11月16日，全球机器学习教父、人工智能领域顶尖科学家Tom Mitchell教授，正式宣布加入了中国一家教育创业公司——松鼠AI，出任首席人工智能科学家，引起圈里一阵惊叹。Mitchell长期从事机器学习、认知神经学科等研究，全世界最经典应用最广的机器学习教材，就出自他之手。在全球机器学习领域，Mitchell教授是公认的行业“教父”，Machine Learning第一人。
  - “我对教育领域一直很感兴趣，我编写过教材，始终认为教育是我职业生涯中的重要一环，我最近开始深度关注AI对教育的应用，因为现在时机比较成熟了。”在最近一场关于AI+教育的主题大会上，Mitchell如是说。
  - AI在教育领域应用时机的成熟，很可能意味着这个自古以来的传统行业，也要真正进入到数字化的快车道了。
- 全球范围内，教育行业的核心痛点只有一个，没有之一：缺乏优质的教师资源。
- 据今年8月教育部发布《2017年全国教育事业发展统计公报》显示，全国共有义务教育阶段学校21.89万所，招生3313.78万人，在校生1.45亿人，专任教师949.36万人。而特级教师不到千分之一，这个巨大的差距，使得保证基本教学质量就已经成为一个艰巨的任务，更遑论能够让孩子学习效率得到最大提升的个性化问题了。
- 过去互联网和移动互联网，只是解决了教育行业的“太花钱”的问题，包括录刻式的教育或者是手机APP的教育。所谓录刻，只是把线下的教育搬移到了线上，降低了成本，但也暴露出新的问题：
  - 一是完课率非常低
  - 二是交互性差，学生学习过程中碰到问题没有人解决和帮助，对学生自主性要求非常高，学习时间无法保证，所以学习效能没有显著提高。
- 而之前流行的在线“一对一”教育的形式，虽然带来个性化学习，但是，这种模式对老师的依赖性非常强，好老师的资源始终有限，他们的精力也有限，当学生数量迅速增加时，优质的老师的比例就会被严重稀释，整体教学质量很难维持，而且也需要巨大的成本支出来维持、甚至争夺优质教师的资源。
- 而事实上，一个特级教师出来授课的课时费，是每小时4000元，收费每小时150到300元的无论线上线下一对一，是不可能找到最优质的师资的，这也是为什么几百万上千万的学区房仍旧被趋之若鹜。
- 正是存在着优质教师资源这个核心的限制条件，这也是为什么教育行业没有出现垄断性的巨头的原因，即使强大如新东方和好未来，发展近20年，市场占有率也仍然不高，无法体现出规模效应。而且，好的老师主要集中一、二线城市，下面的三、四、五线城市就难以找到一个好老师，扩张起来就更加困难。
- 以AI为基础的自适应教育，理论上能够从根本上解决这个问题
  - 智适应学习的概念，源于“自适应学习”（adaptive learning），诞生于人工智能时代，自上个世纪七十年代起流行。智适应学习模式，融合了计算机科学、人工智能、心理测量学、教育学、心理学和脑科学等专业领域。简单说来，它主要是使用计算机算法来调节与学习者的互动，并提供定制化的资源和学习活动，以满足每个学习者的独特需求。
- 近两年来，国内几乎所有具备实力的教育机构，已经有50多家都提出了“AI+”的发展目标。“AI+教育”到底可以做什么，场景也逐一清晰，目前已经被几亿家长们体验到的就包括——智能测评、拍照搜题、智能排课、表情识别、语音识别等等。
- 而上述这些方法在整个K12产业的落地还十分有限。来自艾瑞的数据显示，总规模达3万亿的中国教育市场，K12课外辅导总市场规模6000亿，新东方和好未来在其中只占到了2%的份额。如此来看，K12课外辅导行业空间巨大，急需新的、革命性的教学方法。
- 传统的非自适应方法学习模式中，由于学生的学习路径、认知过程、成绩反馈等数据无法得到大规模地追踪，存储和分析，难以实现量身定制个性化的学习模式。
- AI智适应系统也一改过去所有线上线下教育以老师为中心的教学模式，而成为根据学生的用户画像实施千人千面的因材施教，几千年来，学生第一次真正成为主角！
- “人类教师在教学过程中会制定许多决策。我们的研发任务就是模拟老师可能会制定的所有决策，并且通过计算机搜集的学生数据来最终制定决策。”Mitchell告诉钛媒体，教师经常需要选择最佳方式来提高教学质量，他需要快速地明白，不同水平的学生应该学习不同的知识，不同性格的学生目前最需要什么不同的帮助，以及下一步该采取什么行动。
- 智适应在学习中的应用之一：学生在学习过程中如何制定动态的学习目标？90分和60分的孩子的学习目标应该是完全不同的，同样都是60分的孩子，学习能力不同目标也不相同，所以学习路径就应该被不断调整达到精准有效。
- 概念
  - 知识地图的概念，这个概念是由ALEKS创造的，这也是个性化教育的一个重要基础。通过知识地图，可以用1/10的题目测出每个孩子哪个知识点会，哪个知识点不会。因为我们传统的中考高考只能测出孩子是八十分或者是六十分的孩子，但是5个80分的孩子，他们每个知识点会和不会的地方其实是完全不一样的。
  - 松鼠AI在知识地图的基础上，又提出了错因重构知识地图的理念，“错因”的概念是这样的：如果这个孩子某个知识点没掌握，不一定是知识点的问题，可能是其他的错因，比如说题干的语义理解有问题，也可能是单纯的马虎遗漏，他其实是掌握这个知识点的，所以，如果我们没有把所有的错因抓出来，或者只给孩子训练知识点，其实他已经掌握了，等于又浪费了时间，同时他自己真正错的原因还没有解决，以后遇到类似题目仍旧会做错。
  - 栗浩洋举例说，关于一元二次方程，ALEKS拆解为了13个知识点，而松鼠AI团队拆解为了107个；初中英语听力知识点拆分为了8000多个。

## 解题

【2022-8-8】[PNAS最新研究：81%解题率，神经网络 Codex 推开高等数学世界大门](https://mp.weixin.qq.com/s/1G_RgtqHmP0M4AhKLTtbsA)
- [论文](https://dataspace.princeton.edu/bitstream/88435/dsp01g445ch067/1/Sun_princeton_0181D_13173.pdf), [原文链接](https://www.pnas.org/doi/10.1073/pnas.2123433119): 研究团队证明了 OpenAI 的 Codex 模型可以进行程序合成从而解决大规模的数学问题，并通过小样本学习自动解决数据集中 81%的数学课程问题，并且 Codex 在这些任务的表现上达到了人类水平。

这项研究颠覆了人们普遍认为**神经网络无法解决高等数学问题**的共识。Codex 之所以能做到实现这样的能力，正是因为团队进行了一大创新，过去那些不成功的研究只使用了基于文本的预训练，而此次现身的 Codex 神经网络不仅要基于文本进行预训练，并且还对代码进行了微调。
- 问题数据集选用来自 MIT 的六门数学课程和哥伦比亚大学的一门数学课程，从七门课程中随机抽取 25 个问题：MIT的单变量微积分、多变量微积分、微分方程、概率与统计概论、线性代数和 计算机科学数学和哥伦比亚大学的 COMS3251 计算线性代数。
- 同时，研究团队使用了一个用于评估数学推理的最新高级数学问题基准 MATH，用 MATH 来检测OpenAI Codex 的能力，MATH 从6大数学板块：初级代数，代数，计数和概率，中级代数，数论，和初级微积分中各抽取15个问题。
- Codex 解决了问题数据集和 MATH 数据集中的 265 个问题，其中有 213 个是自动解决的

Transformer 发布后，基于 Transformer 的语言模型在各种自然语言处理 (NLP) 任务，包括在`零样本`和`少样本`语言任务中取得了巨大成功。但是因为 Transformer 仅在文本上进行了预训练，所以这些模型基本上不能解决数学问题，`GPT-3`就是一个典型例子

后来，通过`小样本学习`（few-shot learning）和`思维链` (Chain-of-thought， CoT) 提示，GPT-3 的数学推理能力得到了提高；然而，在没有代码的情况下，即便有小样本学习和 CoT 提示， GPT-3 在大学水平数学问题和 MATH 基准测试中仍然无能为力。

过去关于解数学题的研究，可能在相对简单的数学水平上有一定成绩。举个例子，基于协同训练输出来验证或预测表达式树的技术，比如 MAWPS 和 Math23k，能够以超过 81% 的准确率解决小学级别的数学问题，但是其不能解决高中、奥林匹克数学或大学难度的课程。`协同训练`与`图神经网络` (GNN) 相结合以预测算术表达式树，能够以高达 **95%** 的准确率解决机器学习中的大学水平问题。但是这项工作也仅限于数字答案，并且产生了过拟合，不能推广到其他课程。

而这项工作的最大创新点之一就是，不仅对Codex 这种Transformer 模型进行了文本上的预训练，还在代码上进行了微调，使得其可以生成大规模解决数学问题的程序。
- 仅对文本进行预训练的语言模型 (GPT-3 text-davinci-002) 仅自动解决了课程问题中的18%和 MATH基准测试问题中的25.5%。
- 使用`零样本学习`和对文本进行**预训练**并在代码上进行**微调**的神经网络（OpenAI Codex code-davinci-002）合成的程序可以自动解决课程问题中的 71%和 MATH 基准测试问题中的72.2%。
- 使用相同的神经网络 Codex 再加上少样本学习，便可自动解决课程中 81% 的问题和 MATH 基准测试中 81.1% 的问题。
- 而其余模型无法自动解决的 19% 的课程问题和 18.9% 的MATH基准问题，最后通过手动提示解决。

## 代码实现

【2022-8-30】paperwithcode 里的Deep Knowledge Tracing [sota榜单](https://paperswithcode.com/paper/deep-knowledge-tracing#code)
- [DeepKnowledgeTracing-DKT-Pytorch](https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch.git)
- [deepKT](https://github.com/jdxyw/deepKT)


# 结束


