---
layout: post
title:  提示学习 Prompt learning
date:   2021-11-10 19:58:00
categories: 深度学习 自然语言处理
tags: 自监督 prompt
excerpt: NLP新范式：Prompt（提示学习）
mathjax: true
permalink: /prompt
---

* content
{:toc}

# NLP新范式：Prompt

【2021-8-3】[Fine-tune之后的NLP新范式：Prompt越来越火，CMU华人博士后出了篇综述文章](https://blog.csdn.net/xixiaoyaoww/article/details/119363189)，CMU 博士后研究员刘鹏飞：近代自然语言处理技术发展的第四范式可能是预训练语言模型加持下的 Prompt Learning。
- 从 BERT 开始，**预训练+finetune** 已经成为了整个领域的常规范式。但是从 GPT-3 开始，一种新范式开始引起大家的关注并越来越流行：**prompting**。
- [论文地址](https://arxiv.org/pdf/2107.13586.pdf)，更多研究见：清华大学开源的论文列表 [thunlp/PromptPapers](https://github.com/thunlp/PromptPapers)
- ![img](https://img-blog.csdnimg.cn/img_convert/e538ffef7d05deaf84a5a66225c7f4bc.png)

prompt讲解
- [CMU](https://blender.cs.illinois.edu/course/fall22/lecture9.pdf)

<object type="application/pdf" data="https://blender.cs.illinois.edu/course/fall22/lecture9.pdf"
           id="review" style="width:100%;  height:800px; margin-top:0px;  margin-left:0px" >
</object>


## NLP 范式

全监督学习在 NLP 领域也非常重要。但是全监督的数据集对于学习高质量的模型来说是不充足的，<span style='color:red'>早期的 NLP 模型严重依赖特征工程</span>。
- 随着用于 NLP 任务的神经网络出现，使得特征学习与模型训练相结合，研究者将研究重点转向了**架构工程**，即通过设计一个网络架构能够学习数据特征。

各种模式的对比如下：

|模式paradigm|工程重心engineering|示例|任务关系task relation|
|---|---|---|---|
|①全监督（非神经网络）|特征|如单词，词性，句子长度等|分类、序列标注、语言模型（无监督）、生成|
|②全监督（神经网络）|结构|如卷积、循环、自注意力|同上|
|③pre-train与fine-tune|目标|掩码语言模型、NSP下一句预测|以语言模型为中心，含无监督训练|
|④pre-train、prompt与predict|提示|完形填空、前缀|语言模型为中心，含文本提示|


- ![img](https://img-blog.csdnimg.cn/img_convert/e7be4976c76f47cf54a95a7dcd2150b9.png)
- 传统的监督学习（不需要神经网络）
- 神经网络-监督学习：不同NLP任务需要单独训练
- pre-train + fine-tune：目前流行的范式，可以适应不同的场景任务
- pre-train + prompt + predict：模板prompt范式，可以适应不同的场景任务

【2023-2-12】[【NLP】Prompt Learning 超强入门教程](https://zhuanlan.zhihu.com/p/442486331), 刘鹏飞在[北京智源大会](https://event.baai.ac.cn/activities/172)上关于 Prompt 的分享


【2023-2-9】
- [【NLP】Prompt Learning 超强入门教程](https://zhuanlan.zhihu.com/p/442486331)
- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf)

很长一段时间内，NLP任务采用的都是 `Pretrain` + `Fine-tuning`（Model Tuning）的解决方案，需要对于每个任务都重新 fine-tune 一个新的模型，且**不能共用**。
- 但是对于一个预训练的大语言模型来说，这就仿佛对于每个任务都进行了**定制化**，十分不高效。
- 是否存在一种方式，可以将预训练语言模型作为**电源**，不同的任务当作**电器**，仅需要根据不同的电器（任务），选择不同的**插座**，对于模型来说，即插入不同的任务特定的参数，就可以使得模型适配该下游任务。
- `Prompt Learning` 就是这个**适配器**，它能高效得进行预训练语言模型的使用。

这种方式大大地提升了预训练模型的**使用效率**，如下图：
- ![](https://pic2.zhimg.com/80/v2-ffa9e652a07961216d1ed260dfdea95d_1440w.webp)
*   左边是传统的 `Model Tuning` 的范式：对于不同的任务，都需要将整个预训练语言模型进行**精调**，每个任务都有自己的一整套参数。
*   右边是`Prompt Tuning`，对于不同任务，仅需要插入不同的 prompt参数，每个任务都单独训练 Prompt 参数，不训练预训练语言模型，这样子可以大大缩短训练时间，也极大的提升了模型的使用率。



### NLP 范式发展历史

| 年份	| NLP模型范式变化 |
|---|---|
| 2017年以前 |	传统机器学习模型、神经网络 |
| 2017-2019	| 预训练 + 微调（pre-train + fine-tune） |
| 2019-至今	| ”预训练，prompt和预测“（pre-train，prompt and predict）范式 |

NLP发展历史上的三种范式（时间顺序）
*   很久以前发展起来的`全监督学习` Fully Supervised Learning
  - Fully Supervised Learning，即仅在目标任务的输入输出样本数据集上训练特定任务模型，长期以来在许多机器学习任务中发挥着核心作用，同样的，全监督学习在 NLP 领域也非常重要。
  - ![基于神经网络的监督学习](https://pic4.zhimg.com/80/v2-82767e969a98bc63c647374a049f6f17_1440w.webp)
  - 但是全监督数据集对于学习高质量的模型来说是不充足的，**早期的 NLP 模型严重依赖特征工程**。随着用于 NLP 任务的神经网络出现，使得特征学习与模型训练相结合，研究者将研究重点转向了架构工程，即通过设计一个网络架构能够学习数据特征。
  - ![基于神经网络的监督学习](https://pic4.zhimg.com/80/v2-82767e969a98bc63c647374a049f6f17_1440w.webp)
*   前三年火爆的`预训练+微调`  Pre-train, Fine-tune
  - 然而，从 2017-2019 年开始，NLP 模型发生了翻天覆地的变化，这种`全监督范式`发挥的作用越来越小。具体而言，研究重点开始转向预训练、Fine-tuning范式。一个具有固定架构的模型通过**预训练**作为`语言模型`（LM），用来预测观测到的文本数据的概率。
  - ![预训练+微调](https://pic1.zhimg.com/80/v2-9b02ff7acb3ac010d683c76dd53a4c14_1440w.webp)
*   最新的 `预训练+提示+预测 `  Pre-train, Prompt, Predict  
  - 当前正处于第二次巨变中，「预训练、Fine-tuning」过程被「预训练、prompt 和预测」过程所取代。
  - 在这种范式中，不是通过目标工程使预训练的语言模型（LM）适应下游任务，而是**重新形式化**（Reformulate）下游任务，使其看起来更像是在文本 prompt 的帮助下在原始 LM 训练期间解决的任务。
  - 通过这种方式，选择适当的 prompt，该方法可以操纵模型的行为，以便预训练的 LM 本身可以用于预测所需的输出，有时甚至无需任何额外的特定任务训练。
  - 优点是给定一组合适的 prompt，以**完全无监督**方式训练的单个 LM 就能够用于解决大量任务。
  - 然而该方法也存在一个问题 —— 这种方法引入了 **prompt 挖掘工程**的必要性，即需要找出最合适的 prompt 来让 LM 解决面临的问题

Prompt刚刚出现时，还没有被叫做Prompt，是研究者们为了下游任务设计出来的一种输入**形式**或**模板**，它能够帮助PLM“回忆”起自己在预训练时“学习”到的东西，因此后来慢慢地被叫做Prompt了。
- ![prompt](https://pic1.zhimg.com/80/v2-f152c022e31126bd8520e453899aaadc_1440w.webp)

不同于fine-tuning方法，prompt 范式需要给出一个定义好的模板，这个模板可以是离散的或者是连续的，来提醒模型在预训练的时候学习的知识。这是因为预训练的任务和下游任务往往差别较大，模型可能会存在特定性遗忘。

## prompt 介绍

什么是 `Prompt`, Prompt 就是 **提示**：  
- 有人忘记了某个事情，给予特定提示，他就可以想起来
- **白日依山尽**, 大家自然而然地会想起来下一句诗：**黄河入海流**。
- 搜索引擎，可以根据输入，进行输出提示：
  - ![](https://pic3.zhimg.com/80/v2-81d4c4b774e7910935d97fcde34b3842_1440w.webp)
 
文本情感分类：
- “I missed the bus today.” 句子后紧跟着给出这样一个prompt：“I felt so _____”
- “English: I missed the bus today. French: ______”

PLM将自动补充单词sad，或使用法语来进行填空。

### 什么是 prompt？

NLP中 `Prompt` 代表的是什么呢？
*   prompt 就是给 预训练语言模型 的一个**线索**/**提示**，更好的理解 人类的问题。

下图的 BERT/BART/ERNIE 均为预训练语言模型，对于人类提出的问题以及线索，预训练语言模型可以给出正确的答案。
- ![](https://pic4.zhimg.com/80/v2-f09af919f520b65363e38d8340ac4e4f_1440w.webp)
*   根据提示，BERT能回答，JDK 是 _Oracle_ 研发的
*   根据 `TL;DR:` 的提示，BART知道人类想要问的是文章的摘要
*   根据提示，ERNIE 知道人类想要问鸟类的能力--飞行

Prompt 更严谨的定义如下：
> - Prompt is the technique of making better use of the knowledge from the pre-trained model by adding additional texts to the input.  
> - Prompt 是一种为了更好的使用预训练语言模型的知识，采用在输入段添加**额外文本**的技术。
 
*   目的：更好挖掘预训练语言模型的能力
*   手段：在输入端添加文本，即重新定义任务（task reformulation）



### Prompt 概要

该综述研究试图通过提供 prompting 方法的概述和形式化定义，以及使用这些 prompt 的预训练语言模型的概述，来梳理这一迅速发展领域的当前知识状态。然后该论文对 prompt 方法进行了深入的讨论，包括 **prompt工程**、**answer工程**等基础和**多prompt学习**方法、**prompt相关的训练方法**等更高级的概念。

然后，该研究列出了已有的基于 prompt 学习方法的多种应用，并探讨了不同应用场景中如何选择合适的训练方法。最后，该研究尝试在研究生态系统中定位 prompt 方法的当前状态，并与其他研究领域建立联系。此外，该研究提出一些可能适合进一步研究的挑战性问题，并针对当前研究趋势进行了分析。

基于 Prompt 的学习方法试图通过**学习LM**来规避这一问题，该 LM 对文本 x 本身的概率 P(x;θ) 进行建模并使用该概率来预测 y，从而减少或消除了训练模型对大型监督数据集的需求。

最基本的 Prompt 形式的数学描述，包含许多有关 Prompt 的工作，并且可以扩展到其他内容。

基础 Prompt 分三步预测得分最高的 ^y，即：**prompt 添加**、**answer 搜索**和 **answer 映射**。prompting 方法的术语和符号。
- ![img](https://img-blog.csdnimg.cn/img_convert/c441c670a31e4b2669da835842b9f171.png)
不同任务的输入、模板和 answer 示例：
- ![img](https://img-blog.csdnimg.cn/img_convert/90e84a4ad6cf465e3e306fc376581bcf.png)

### Prompt设计思路

Prompting 设计考虑：
- 预训练模型选择：有许多预训练 LM 可以用来计算 P(x; θ)。在第 3 章中，研究者对预训练 LM 进行了初步的介绍；
- **Prompt 工程**：如果 prompt 指定了任务，那么选择正确的 prompt 不仅对准确率影响很大，而且对模型首先执行的任务也有很大影响。在第 4 章中，研究者讨论了应该选择哪个 prompt 作为 f_prompt(x) 方法；
- **Answer 工程**：根据任务的不同，会有不同的方式设计 Z (Answer)，可能会和映射函数一起使用。在第 5 章中，详细介绍了不同的设计方式；
- **扩展范式**：如上所述， 上面的公式仅仅代表了各种底层框架中最简单的一种，这些框架已经被提议用于执行各种 prompting。在 第 6 章中，研究者讨论了扩展这种基本范式以进一步提高结果或适用性的方法；
- 基于 Prompt 的**训练策略**：在第 7 章中，研究者总结了不同的训练策略并详细说明它们的相对优势
- ![img](https://img-blog.csdnimg.cn/img_convert/eae05d97522535d2a976353daae592c2.png)

## Prompt 工作流

Prompt 的工作流包含以下4部分：
1.  Prompt **模版**（Template）构造*   
2.  Prompt **答案空间映射**（Verbalizer）的构造    
3.  文本代入template，并且使用预训练语言模型进行**预测**    
4.  将预测结果**映射回**label。
 
具体的步骤如下图，拆解分析。
-  ![workflow](https://pic4.zhimg.com/80/v2-65b25d4895d4d7b81d747282cdb4c7f3_1440w.webp)
 
### Step 1: prompt construction【Template】

首先构建一个模版Template，作用是将输入和输出进行**重新构造**，变成一个新的带有mask slots的文本，具体如下：
*   定义一个模版，包含了2处代填入的slots：\[x\] 和 \[z\]
*   将\[x\] 用输入文本代入

例如：
*   输入：<span style='color:green'>x = 我喜欢这个电影</span>。
*   模版：<span style='color:blue'>\[x\]总而言之，它是一个\[z\]电影</span>。
*   代入（prompting）：<span style='color:green'>我喜欢这个电影。总而言之，它是一个\[z\]电影</span>。
- ![](https://pic2.zhimg.com/80/v2-e6c4edefdb2498229dfa37f9fc883f15_1440w.webp)
 
### Step 2: answer construction【Verbalizer】
 
对于构造的prompt，要知道预测词和label 之间的关系，并且不可能运行z(任意词)，就需要一个`映射函数`（mapping function）将输出的词与label进行映射。
- 输出的label 有两个，一个是 😄，一个是 😭，可以限定，如果预测词是`fantastic` 则对应 😄，如果是 `boring` 则对应 😭.
- ![](https://pic3.zhimg.com/80/v2-6c3ab4435a08d559c69d2b46b18a5d1e_1440w.webp)
- ![](https://pic4.zhimg.com/80/v2-4708199326266b548a6b3e0361b1bb47_1440w.webp)
 
### Step 3: answer prediction【Prediction】
 
只需要选择[合适的预训练语言模型](https://huggingface.co/docs/transformers/model_summary)，然后进行 mask slots \[z\] 的预测。例如下图，得到了结果 `fantastic`, 将其代入\[z\] 中。
- ![](https://pic2.zhimg.com/80/v2-c12486224648f205c3c8199101a06b75_1440w.webp)

### Step 4: answer-label mapping【Mapping】
 
第四步骤，对于得到的 `answer`，用 `Verbalizer` 将其映射回原本的label。
- 例如：fantastic 映射回 label：
- ![](https://pic2.zhimg.com/80/v2-b9a60cb83f1c6772490053801d13885d_1440w.webp)
 
### 总结

- ![](https://pic1.zhimg.com/80/v2-45666504e1714ef274be6ed35a86d388_1440w.webp)
 
## Prompt-based 方法的工程选择问题

在知乎中有个提问：
> 现代的deep learning 就是为了规避 feature engineering，可是prompt 这边选择了 template 和 answer 不还是 feature engineering吗？

确实, 如果使用 BERT 的 fine-tuning 范式（下图左），不需要使用任何的人工特征构造，而使用 prompt-based 的方法的话，需要人工参与的部分包含了以下部分：
*   template 构造
*   answer 构造
*   预训练模型选择
*   prompt 的组合问题选择
*   以及训练策略的选择等
- ![](https://pic3.zhimg.com/80/v2-011fccce5f1d7367c243def5d3da4e32_1440w.webp)
 
会先进行每个需要人工engineering 的部分进行详细讲解，然后再分析为什么我们还需要prompt 这种范式。
 
### Prompt Template Engineering（Prompt模版工程）
 
如何构造合适的Prompt 模版？对于同一个任务，不同的人可能构造不同的Template。
- ![](https://pic3.zhimg.com/80/v2-6b1eef9478acd01687934bcaa07a3d0a_1440w.webp)

且每个模版都具有合理性。Tempalte的选择，对于Prompt任务起到了很重大的作用，就算一个word的区别，也坑导致10几个点的效果差别，论文[GPT Understands, Too](https://arxiv.org/abs/2103.10385) 给出了如下的结果：
- ![](https://pic1.zhimg.com/80/v2-b98e6f18abfad252f96b04a549cc9898_1440w.webp)
 
对于不同的template，可以从以下两种角度进行区分：
1.  根据**slot 的形状/位置**区分
  *   1.1 `完形填空`（Cloze）的模式，即未知的slot在template的中间等不定的位置
  *   1.2 `前缀模式`（Prefix），未知的slot在template的开头
1.  根据是否**由人指定**的来区分
  *   2.1 `人工指定` template
  *   2.2 `自动搜索` template
  *   2.3 `Discrete` 离散Template，即搜索的空间是离散的，为预训练语言模型的字典里的字符。
  *   2.4 `Continuous` 连续Template，即搜索的空间是连续的，因为所有新增的这些prompt的参数主要是为了让机器更好地服务于任务，所以其参数的取值空间不需要限定在特定的取值范围内，可以是连续的空间。

具体的思维导图如下：
- ![](https://pic3.zhimg.com/80/v2-c96d89a06ca2ec58e31a7cd2b4f30e7e_1440w.webp)
 
### Answer Engineering（答案工程）
 
在给定一个任务或者Prompt，如何对 label 空间 和 answer 空间进行映射？
- ![](https://pic2.zhimg.com/80/v2-3df9747e3a96385804fce424e5c7b619_1440w.webp)
 
在上图，label 空间 Y 是: Positive, Negative, 答案空间 Z 可以是表示positive或者negative 的词，例如: Interesting/Fantastic/Happy/Boring/1-Star/Bad，具体的答案空间 Z 的选择范围可以由我们指定。可以指定一个 y 对应1-N个字符/词。
- ![](https://pic4.zhimg.com/80/v2-acf52745920aae345e6c5ac9ee20e92b_1440w.webp)
 
具体的答案空间的选择可以有以下三个分类标注：
1.  根据**形状**
  *   1.1 Token 类型
  *   1.2 Span 类型
  *   1.3 Sentence 类型
1.  是否**有界**
  *   2.1 有界
  *   2.2 无界
1.  是否**人工选择**
  *   3.1 人工选择
  *   3.2 自动搜素
  *   3.2.1 离散空间
  *   3.2.2 连续空间

具体的思维导图如下：
- ![](https://pic4.zhimg.com/80/v2-9e58677317b0576537d58fa669c6fc5b_1440w.webp)
 
### Pre-trained Model Choice（预训练模型选择）

在定义完模版以及答案空间后，选择合适的预训练语言模型对 prompt 进行预测，如何选择一个合适的预训练语言模型需要人工经验判别的。

具体的预训练语言模型可以分为如下5类，具体参考：[Huggingface Summary of the models](https://huggingface.co/docs/transformers/model_summary)
*   autoregressive-models: `自回归模型`，主要代表有 `GPT`，主要用于生成任务
*   autoencoding-models: `自编码模型`，主要代表有 `BERT`，主要用于NLU任务
*   seq-to-seq-models：`序列到序列任务`，包含了an encoder 和 a decoder，主要代表有 `BART`，主要用于基于条件的生成任务，例如翻译，summary等
*   multimodal-models：`多模态模型`
*   retrieval-based-models：`基于召回的模型`，主要用于开放域问答

基于此，例如下图想要做summary 任务，我们可以选择更合适的 BART 模型。
- ![](https://pic3.zhimg.com/80/v2-f7cf71aaa125547394fc53faadc0e7e6_1440w.webp)
 
其他分类标准也可参考：
- ![](https://pic3.zhimg.com/80/v2-654bc36f0f684b17b97f1966fe5904aa_1440w.webp)
- ![](https://pic2.zhimg.com/80/v2-f8e5c095bf30cd97176098cd725974e1_1440w.webp)
 
### Expanding the Paradigm（范式拓展）

如何对已有的 Prompt 进行任务增强以及拓展，具体可以从以下几个方面进行探讨：
*   Prompt Ensemble：Prompt 集成，采用多种方式询问同一个问题
  - ![](https://pic2.zhimg.com/80/v2-0143f03d078e4c78231b987dd041752d_1440w.webp)
*   Prompt Augmentation：Prompt 增强，采用类似的 prompt 提示进行增强
  - ![](https://pic1.zhimg.com/80/v2-04b7abb8bac6d642808f95c3eaeef088_1440w.webp)
*   Prompt Composition：Prompt 组合，例如将一个任务，拆成多个任务的组合，比如判别两个实体之间是否是父子关系，首先对于每个实体，先用Prompt 判别是人物，再进行实体关系的预测。
  - ![](https://pic3.zhimg.com/80/v2-f3fd7d887bcec01d18e410efe74c36aa_1440w.webp)
*   Prompt Decomposition：  
  - 将一个prompt 拆分成多个prompt
  - ![](https://pic1.zhimg.com/80/v2-a13127a5cd6927bcbff1f278b6c32c28_1440w.webp)
 
具体的思维导图如下：
- ![](https://pic1.zhimg.com/80/v2-62bb4b0d499ab4ba4eb57fc27304ec00_1440w.webp)
 
## Prompt-based Training Strategies（训练策略选择）

Prompt-based 模型在训练中，有多种训练策略，可以选择哪些模型部分训练，哪些不训练。
 
可以根据训练数据的多少分为：
*   `Zero-shot`: 对于下游任务，没有任何训练数据
*   `Few-shot`: 对于下游任务只有很少的训练数据，例如100条
*   `Full-data`: 有很多的训练数据，例如1万多条数据
 
也可以根据不同的参数更新的部分，对于prompt-based 的模型，主要分为两大块  
- 一个是预训练模型，一个是 Prompts 参数。  

这两个部分，都可以独立选择参数训练选择。  

对于
*   预训练语言模型，可以选择精调，或者不训练
*   对于prompts：
*   可以是没有prompts
*   固定的离散字符 prompts。（无参数）
*   使用训练好的 prompts参数，不再训练。
*   继续训练 prompts参数
- ![](https://pic3.zhimg.com/80/v2-edcf6508177774d990a83a9867bc96de_1440w.webp)
 
这些训练策略均可以两两组合，下面举例说明：
 
### 策略分类

*   **Promptless** Fine-tuning
  - 如果只有预训练语言模型，没有prompts，然后fine-tuning，即是bert 的常规使用。
  - ![](https://pic3.zhimg.com/80/v2-eb301f6533d25e15a4b980581d4c736e_1440w.webp)
*   **Fixed-Prompt** Tuning  
  - 如果使用精调预训练语言模型+离散的固定prompts，就是 BERT + Discrete Prompt for text classification
  - ![](https://pic1.zhimg.com/80/v2-f9deac3450d2f4af12cb96fc42784fc8_1440w.webp)
  - 如果使用精调预训练语言模型+连续训练好的固定prompts，就是 BERT + Transferred Continuous Prompt for text classification
-  ![](https://pic1.zhimg.com/80/v2-ae562fd4a0b05f4a3d87247f64b68e88_1440w.webp)
*   **Prompt+LM** Fine-tuning
  - 如果使用精调预训练语言模型+可训练的prompts，就是 BERT + Continuous Prompt for text classification
  - ![](https://pic3.zhimg.com/80/v2-0e47867fb32772bbe94974f4b2a37ff6_1440w.webp)
*   **Adapter** Tuning
  - 如果使用固定预训练语言模型无prompt，只是插入task-specific模块到预训练语言模型中，就是BERT + Adapter for text classification
  - ![](https://pic2.zhimg.com/80/v2-bf82c965a4d2abf020356ff70401ee85_1440w.webp)
*   **Tuning-free** Prompting
  - 如果使用固定预训练语言模型和离散固定的prompt，就是GPT3 + Discrete Prompts for Machine Translation
  - ![](https://pic4.zhimg.com/80/v2-c72a6a803262e3ed3e4ec442a4382ebf_1440w.webp)
  - 如果使用固定预训练语言模型和连续固定的prompt，就是 GPT3 + Continuous Prompts for Machine Translation
  - ![](https://pic1.zhimg.com/80/v2-5bfc03ab8699075d28f0f64ca60142cc_1440w.webp)
*   **Fixed-LM** Prompt Tuning
  - 如果使用固定预训练语言模型和可训练的prompt，就是 BART + Continuous Prompts for Machine Translation
  - ![](https://pic2.zhimg.com/80/v2-d19c5a6e03987aea08bfd7896fc24c51_1440w.webp)
 
### 策略选择
 
对于不同的策略，需要进行不同的选择，我们往往需要考虑以下两点：
*   我们的数据量级是多少
*   我们的是否有个超大的 Left-to-right 的语言模型  

通常如果只有很少的数据的时候，希望不要去 fine-tune 预训练语言模型，而是使用LM的超强能力，只是去调prompt 参数。而让数据量足够多的时候，我们可以精调语言模型。

而只有像GPT-3 这种超大的语言模型的时候，我们才能直接使用，不需要任何的fine-tuning.
- ![](https://pic4.zhimg.com/80/v2-6a96f5cf3c0524bce4f9328746c6bff7_1440w.webp)
 
## Prompt 的优势是什么
 
Prompt Learning 的优势有哪些呢？从四个角度进行分析。
*   Level 1. Prompt Learning 角度
*   Level 2. Prompt Learning 和 Fine-tuning 的区别
*   Level 3. 现代 NLP 历史
*   Level 4. 超越NLP
- ![](https://pic2.zhimg.com/80/v2-b9363e52298acdc1997182b72b16bfe9_1440w.webp)
 
### Level 1. Prompt Learning 使得所有的NLP任务成为一个语言模型的问题

*   Prompt Learning 可以将所有的任务归一化预训练语言模型的任务
*   避免了预训练和fine-tuning 之间的gap，几乎所有 NLP 任务都可以直接使用，不需要训练数据。
*   在少样本的数据集上，能取得超过fine-tuning的效果。
*   使得所有的任务在方法上变得一致
- ![](https://pic2.zhimg.com/80/v2-e344a7b5f4364cb2ab6aa3e38681ebbd_1440w.webp)
 
### Level 2. Prompt Learning 和 Fine-tuning 的范式区别
 
*   Fine-tuning 是使得预训练语言模型适配下游任务
*   Prompting 是将下游任务进行任务重定义，使得其利用预训练语言模型的能力，即适配语言模型
- ![](https://pic3.zhimg.com/80/v2-e89d427849c1270e7caffc4990d5d5e6_1440w.webp)
 
### Level 3. 现代 NLP 第四范式
 
Prompting 方法是现在NLP的第四范式。其中现在NLP的发展史包含
1.  Feature Engineering：即使用文本特征，例如词性，长度等，在使用机器学习的方法进行模型训练。（无预训练语言模型）
2.  Architecture Engineering：在W2V基础上，利用深度模型，加上固定的embedding。（有固定预训练embedding，但与下游任务无直接关系）
3.  Objective Engineering：在bert 的基础上，使用动态的embedding，在加上fine-tuning。（有预训练语言模型，但与下游任务有gap）
4.  Prompt Engineering：直接利用与训练语言模型辅以特定的prompt。（有预训练语言模型，但与下游任务无gap）

在四个范式中，预训练语言模型，和下游任务之间的距离，变得越来越近，直到最后Prompt Learning是直接完全利用LM的能力。
- ![](https://pic4.zhimg.com/80/v2-041acfa2e38bb9c616e9ba1835f17b1f_1440w.webp)
 
### Level 4. 超越NLP的角度
 
Prompt 可以作为连接多模态的一个契机，例如 CLIP 模型，连接了文本和图片。相信在未来，可以连接声音和视频，这是一个广大的待探索的领域。
- ![](https://pic3.zhimg.com/80/v2-9fa54eb5b1b4b5ebc88843a6647c6c42_1440w.webp)

## 提升效果

提升 prompting 效果的方法
- prompt ensembling
  - 把多个prompt通过某种加权方法组合到一起
- prompt augmentation
  - 启发式学习
- prompt composition
  - 将复合的prompt句子，拆解成多个小段prompt，最后再组合在一起训练
- prompt decomposition
  - 由于一些任务的mask工作使用句子数量有限（比如词性标注任务），于是就只能通过decomposition将一个句子拆分成多个部分后，再对每个部分做prompt单独训练

## prompt 应用

prompt的应用
- 知识探索（事实探索和语言学探索）
- 分类任务（文本分类和自然语言推理）
- 信息提取（关系提取、语义分析和命名实体识别）
- NLP 中的推理（常识推理和数学推理）
- 问答
- 文本生成
- 文本生成的自动评估
- 多模态学习
- 元应用（域自适应、除偏和数据集创建）

![img](https://pic3.zhimg.com/80/v2-934ee6d5289bcf81b6a32f3e85c88712_1440w.webp)

# 结束