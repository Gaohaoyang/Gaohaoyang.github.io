---
layout: post
title:  "Python技能"
date:   2019-06-29 19:17:00
categories: 技术工具
tags: Python Numpy Pandas pyecharts virtualenv
author : 鹤啸九天
excerpt: Web开发相关技术知识点
mathjax: true
---

* content
{:toc}

# Python

- aadict包：在dict的基础上封装了一层，使其能够像操作属性一样使用字典。使得后续操作更加简便且易读，还可以预防不必要的异常出现。
- 代码示例

```python
from addict import Dict

configs = Dict()

configs.platform.status = "on"
configs.platform.web.task.name = "测试-1204"
configs.platform.web.periods.start = "2020-10-01"
configs.platform.web.periods.end = "2020-10-31"
# 获取不存在的key时会返回一个空字典，不用担心报KeyError，对返回值做判空处理即可
app_configs = configs.platform.app
assert app_configs == {}
```

## 安装

### 自动编译安装python

- 【2020-7-3】脚本如下：

```shell

#-----自定义区------
# 下载python3
src_file='https://www.python.org/ftp/python/3.8.3/Python-3.8.3.tgz'
file_name="${src_file##*/}"
install_dir=~/bin
#-------------------
 
[ -e ${file_name} ]||{
        wget ${src_file}
        echo "下载完毕..."
}&& echo "文件已存在, $file_name"
# 解压
tar zxvf ${file_name}
echo "安装目录: $install_dir"
# 安装
new_dir=${file_name%.*}
cd $new_dir
./configure --prefix=${install_dir}/python38
# 如果不设置安装目录prefix, 就会提示sudo权限
make && make install
echo "安装完毕，请设置环境变量"
 
# 设置环境变量
#vim ~/.bash_profile
echo "
alias python3='${install_dir}/python38/bin/python3.8'
alias pip3='${install_dir}/python38/bin/pip3'
" >> ~/.bash_profile
 
echo '生效'
source ~/.bash_profile


echo '修改pip源'
mkdir ~/.pip
echo "
[global]
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
[install]
trusted-host=mirrors.aliyun.com
" > ~/.pip/pip.conf

# 或者一行命令设置
#pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

```

### virtualenv

- 【2018-1-3】[Python--Virtualenv简明教程](http://python.jobbole.com/85398/)，[virtualenv官方文档](http://virtualenv.readthedocs.org/en/latest/virtualenv.html)
- python沙盒环境，virtualenv创建一个拥有自己安装目录的环境, 这个环境不与其他虚拟环境共享库, 能够方便的管理python版本和管理python库
- （1）安装：

```shell
pip install virtualenv
#或者由于权限问题使用sudo临时提升权限
sudo pip install virtualenv
virtualenv -h #获得帮助
```
- （2）创建：
    - 用virtualenv管理python环境
    - virtualenv ENV  # 创建一个名为ENV的目录, 并且安装了ENV/bin/python
    - 生成ENV目录，包含bin（解释器）、include和lib（python库）文件夹
    - 运行 virtualenv --system-site-packages ENV, 会继承/usr/lib/python2.7/site-packages下的所有库, 最新版本virtualenv把把访问全局site-packages作为默认行为
- （3）激活虚拟环境：

```shell
cd ENV
source ./bin/activate  #激活当前virtualenv
(ENV)➜  ENV git:(master) ✗ #注意终端发生了变化
```

【2020-5-14】注意：windows下没有bin目录，参考，执行方法：.\scripts\activate.bat

- （4）关闭
    - deactivate
- （5）指定python版本
    - 可以使用-p PYTHON_EXE选项在创建虚拟环境的时候指定python版本

```shell
#创建python2.7虚拟环境
➜  Test git:(master) ✗ virtualenv -p /usr/bin/python2.7 ENV2.7
virtualenv -p "C:\Program Files (x86)\Python\Python27" py2
```
- 生成requirements.txt文件

```shell
pip freeze  #显示所有依赖
pip freeze > requirement.txt  #生成requirement.txt文件
pip install -r requirement.txt  #根据requirement.txt生成相同的环境
```

## 单元测试

- [2020-11-6] 经验总结, 提交代码前，执行单测，确保代码功能无误
- 主目录下执行命令: [pytest使用笔记（一）](https://www.pianshen.com/article/4986199865/)
   - pytest # 整体报告
   - pytest -q # 运行简单模式测试报告
   - pytest -x # 在第一个测试用例发生错误时就停止运行
   - pytest --maxfail=2 # 在第2个测试用例发生错误时就停止运行
   - pytest test_mod.py # 执行具体文件
   - pytest test # 运行单个文件的用例
   - pytest -k "TestClass" # 运行某些包含关键字的用例，如包含TestClass的用例
   - pytest test_class.py::TestClass # 运行某一文件内特定模块的用例
   - pytest -m slow # 运行用@ pytest.mark.slow装饰器修饰的用例


# python技能


## uuid生成

- [python生成并处理uuid的方法](https://blog.csdn.net/yl416306434/article/details/80569688)

- uuid是128位的全局唯一标识符（univeral unique identifier），通常用32位的一个字符串的形式来表现。有时也称guid(global unique identifier)。python中自带了uuid模块来进行uuid的生成和管理工作。（具体从哪个版本开始有的不清楚。。）
- python中的uuid模块基于信息如MAC地址、时间戳、命名空间、随机数、伪随机数来uuid。具体方法有如下几个：　　
   - uuid.uuid1()　　基于MAC地址，时间戳，随机数来生成唯一的uuid，可以保证全球范围内的唯一性。
   - uuid.uuid2()　　算法与uuid1相同，不同的是把时间戳的前4位置换为POSIX的UID。不过需要注意的是python中没有基于DCE的算法，所以python的uuid模块中没有uuid2这个方法。
   - uuid.uuid3(namespace,name)　　通过计算一个命名空间和名字的md5散列值来给出一个uuid，所以可以保证命名空间中的不同名字具有不同的uuid，但是相同的名字就是相同的uuid了。【感谢评论区大佬指出】namespace并不是一个自己手动指定的字符串或其他量，而是在uuid模块中本身给出的一些值。比如uuid.NAMESPACE_DNS，uuid.NAMESPACE_OID，uuid.NAMESPACE_OID这些值。这些值本身也是UUID对象，根据一定的规则计算得出。
   - uuid.uuid4()　　通过伪随机数得到uuid，是有一定概率重复的
   - uuid.uuid5(namespace,name)　　和uuid3基本相同，只不过采用的散列算法是sha1

一般而言，在对uuid的需求不是很复杂的时候，uuid1方法就已经够用了

```python
import uuid

name = 'test_name'
# namespace = 'test_namespace'
namespace = uuid.NAMESPACE_URL

print uuid.uuid1()
print uuid.uuid3(namespace,name)
print uuid.uuid4()
print uuid.uuid5(namespace,name)
```

## 性能优化

- 【2020-9-10】[Python语言优化](https://www.cnblogs.com/pypypy/p/11995237.html)
- 原生的python通常都是由cpython实现，而cpython的运行效率，确实让人不敢恭维，比较好的解决方案有cython、numba、pypy等等

### cython

![](https://yqfile.alicdn.com/d0a10d313a638bc6a18eb6ef4b1632920a2b133a.png)


### numba

![](https://yqfile.alicdn.com/94af3cf79a6a076262e647cf491247928939ff79.jpeg)

### pypy

![](https://yqfile.alicdn.com/ae64deb6d0ce804914e023290429be7812e62a16.jpeg)




# Python生态系统


## Numpy

- 【2020-12-28】[NumPy初学教程，可视化指南](https://www.toutiao.com/i6911204024628806148/)
  - ![](https://p3-tt.byteimg.com/origin/pgc-image/21a2426ec0304256950e4f80596b2b4a?from=pc)
  - ![](https://p3-tt.byteimg.com/origin/pgc-image/cc4fbb6975bf4799b413cb5ec9c694f3?from=pc)

- Numpy知识点汇总

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170415-1.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170415-2.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170415-3.png)

Reference
> 《Python for data analysis》 <br>
[NumPy Reference — NumPy v1.12 Manual](https://docs.scipy.org/doc/numpy/reference/?v=20170515184114)

## Pandas

- Pandas 提供了数据结构——DataFrame，可以高效的处理一些数据分析任务。我们日常分析的数据，大多是存储在类似 excel 的数据表中，Pandas 可以灵活的按列或行处理数据，几乎是最常用的工具了。

- [Pandas按行按列遍历Dataframe的几种方式](https://blog.csdn.net/sinat_29675423/article/details/87972498)
    - ![](https://img-blog.csdnimg.cn/20190227142817847.png)
    - 简单对上面三种方法进行说明：
        - iterrows(): 按行遍历，将DataFrame的每一行迭代为(index, Series)对，可以通过row[name]对元素进行访问。
        - itertuples(): 按行遍历，将DataFrame的每一行迭代为元祖，可以通过row[name]对元素进行访问，比iterrows()效率高。
        - iteritems():按列遍历，将DataFrame的每一列迭代为(列名, Series)对，可以通过row[index]对元素进行访问。

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-1.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-2.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-3.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-4.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-5.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-6.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170422-7.png)


### pandas操作命令

- [pandas-数据的合并与拼接](https://www.cnblogs.com/keye/p/10791705.html)
- Pandas包的merge、join、concat方法可以完成数据的合并和拼接
    - **merge**方法主要基于两个dataframe的共同列进行合并
    - **join**方法主要基于两个dataframe的索引进行合并
    - **concat**方法是对series或dataframe进行行拼接或列拼接。

- (1) pandas的merge方法是基于共同列，将两个dataframe连接起来。
- merge方法的主要参数：
    - left/right：左/右位置的dataframe。
    - how：数据合并的方式。
        - left：基于左dataframe列的数据合并；
        - right：基于右dataframe列的数据合并；
        - outer：基于列的数据外合并（取并集）；
        - inner：基于列的数据内合并（取交集）；默认为'inner'。
    - on：用来合并的列名，这个参数需要保证两个dataframe有相同的列名。
    - left_on/right_on：左/右dataframe合并的列名，也可为索引，数组和列表。
    - left_index/right_index：是否以index作为数据合并的列名，True表示是。
    - sort：根据dataframe合并的keys排序，默认是。
    - suffixes：若有相同列且该列没有作为合并的列，可通过suffixes设置该列的后缀名，一般为元组和列表类型。
- 示例：
    - 内连接：
        - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170030512-309759819.png)
    - 外链接
        - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170055862-1927816021.png)
    - index和column的内连接方法
        - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170503579-1916082061.png)



```python
# 单列的内连接
# 定义df1
import pandas as pd
import numpy as np

df1 = pd.DataFrame({'alpha':['A','B','B','C','D','E'],'feature1':[1,1,2,3,3,1],
            'feature2':['low','medium','medium','high','low','high']})
# 定义df2
df2 = pd.DataFrame({'alpha':['A','A','B','F'],'pazham':['apple','orange','pine','pear'],
            'kilo':['high','low','high','medium'],'price':np.array([5,6,5,7])})
# print(df1)
# print(df2)
# 基于共同列alpha的内连接
df3 = pd.merge(df1,df2,how='inner',on='alpha')
# 基于共同列alpha的内连接,若两个dataframe间除了on设置的连接列外并无相同列，则该列的值置为NaN。
df4 = pd.merge(df1,df2,how='outer',on='alpha')
# 基于共同列alpha的左连接
df5 = pd.merge(df1,df2,how='left',on='alpha')
# 基于共同列alpha的右连接
df6 = pd.merge(df1,df2,how='right',on='alpha')
# 基于共同列alpha和beta的内连接
df7 = pd.merge(df1,df2,on=['alpha','beta'],how='inner')
# 基于共同列alpha和beta的右连接
df8 = pd.merge(df1,df2,on=['alpha','beta'],how='right')
# 基于df1的beta列和df2的index连接
df9 = pd.merge(df1,df2,how='inner',left_on='beta',right_index=True)
# 基于df1的alpha列和df2的index内连接(修改相同列的后缀名)
df9 = pd.merge(df1,df2,how='inner',left_on='beta',right_index=True,suffixes=('_df1','_df2'))
df3
```

- (2) join方法
    - join方法是基于index连接dataframe，merge方法是基于column连接，连接方法有内连接，外连接，左连接和右连接，与merge一致。 
    - join和merge的连接方法类似，这里就不展开join方法了，建议用merge方法。
- 示例
    - ![](https://img2018.cnblogs.com/blog/1235684/201904/1235684-20190429170956399-607825585.png)

```python
caller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})
other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],'B': ['B0', 'B1', 'B2']})
print(caller)
print(other)# lsuffix和rsuffix设置连接的后缀名
# 基于index连接
caller.join(other,lsuffix='_caller', rsuffix='_other',how='inner')
# 基于key列进行连接
caller.set_index('key').join(other.set_index('key'),how='inner')
```

- (3) concat方法
    - concat方法是拼接函数，有行拼接和列拼接，默认是行拼接，拼接方法默认是外拼接（并集），拼接的对象是pandas数据类型。 
- 示例

```python
df1 = pd.Series([1.1,2.2,3.3],index=['i1','i2','i3'])
df2 = pd.Series([4.4,5.5,6.6],index=['i2','i3','i4'])
print(df1)
print(df2)

# 行拼接
pd.concat([df1,df2])
# 对行拼接分组,行拼接若有相同的索引，为了区分索引，我们在最外层定义了索引的分组情况。
pd.concat([df1,df2],keys=['fea1','fea2'])
# 列拼接,默认是并集
pd.concat([df1,df2],axis=1)
# 列拼接的内连接（交）
pd.concat([df1,df2],axis=1,join='inner')
# 列拼接的内连接（交）
pd.concat([df1,df2],axis=1,join='inner',keys=['fea1','fea2'])
# 指定索引[i1,i2,i3]的列拼接
pd.concat([df1,df2],axis=1,join_axes=[['i1','i2','i3']])

df1 = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})
df2 = pd.DataFrame({'key': ['K0', 'K1', 'K2'],'B': ['B0', 'B1', 'B2']})
print(df1)
print(df2)

# 行拼接
pd.concat([df1,df2])
# 列拼接
pd.concat([df1,df2],axis=1)
# 判断是否有重复的列名，若有则报错
pd.concat([df1,df2],axis=1,verify_integrity = True)

```



Reference
> 《Python for data analysis》<br>
[pandas: powerful Python data analysis toolkit — pandas 0.20.1 documentation](http://pandas.pydata.org/pandas-docs/stable/?v=20170515184114)

### 遍历

- 【2020-12-25】遍历dataframe

```python
df = pd.DataFrame({'a': range(0, 10000), 'b': range(10000, 20000)})
import time
list1 = []
start = time.time()
for i,r in df.iterrows():
    list1.append((r['a'], r['b']))
print("iterrows耗时  :",time.time()-start)

list1 = []
start = time.time()
for ir in df.itertuples():
    list1.append((ir[1], ir[2]))    
print("itertuples耗时:",time.time()-start)

list1 = []
start = time.time()
for r in zip(df['a'], df['b']):
    list1.append((r[0], r[1]))
print("zip耗时       :",time.time()-start)
```

- 结果：
    - iterrows耗时  : 0.7355637550354004
    - itertuples耗时: 0.008462905883789062
    - zip耗时       : 0.003980875015258789

### 多表合并

- 【2020-12-31】一次合并多张表

```python
import pandas as pd
from functools import reduce
 
data_dir = '/home/work/data/北链讲盘培训价值分析'
#data_file = '/home/work/data/北链讲盘过关用户业绩样例.csv'
bu = ['京北', '京东南']
group = ['未参加', '低分', '高分']
df_dict = {}
for b in bu:
    df_dict[b] = {}
    for g in group:
        data_file = '{}/{}-{}.csv'.format(data_dir, b, g)
        print('开始读数据：{}'.format(data_file))
        df_dict[b][g] = pd.read_csv(data_file, encoding='gbk')
        df_dict[b][g] = df_dict[b][g].rename(columns={'stat_date':'日期', 'avg(assign_amt)':'培训{}的经纪人日均业绩'.format(g)})
        df_final.loc[:,'alpha'].apply(lambda x:'{}-hh'.format(x))
        df_dict[b][g]['日期'] = df_dict[b][g]['日期'].apply(lambda x: '{}-{}-{}'.format(str(x)[:4],str(x)[4:6],str(x)[6:8]))
        # .dt.dayofweek
        df_dict[b][g]['星期几'] = pd.to_datetime(df_dict[b][g]['日期']).dt.dayofweek
    #df_dict[b]['合并'] = df.merge(df_dict[b]['未参加'], df_dict[b]['低分'], df_dict[b]['高分'], how='inner', on='日期')
    merge_list = [df_dict[b]['未参加'], df_dict[b]['低分'], df_dict[b]['高分']]
    df_dict[b]['合并'] = reduce(lambda left,right: pd.merge(left,right,on='日期',how='outer'), merge_list).fillna(0)
    df_dict[b]['合并'].to_excel('{}/{}_合并后.xlsx'.format(data_dir, b))
 
#df = pd.read_csv(data_file, encoding='gbk')
#!head $data_file
#df3 = pd.merge(df1,df2,how='inner',on='alpha')
df_dict['京北']['合并']
```

### 日期转换

- [pandas字符串转日期处理方式](https://blog.csdn.net/weixin_41685388/article/details/103860881)
- 代码

```python

#提取年月日时分秒：方法1
df = pd.read_csv(r"spider.csv",header=None,names=['datetime','url','name','x','y'],encoding='utf-8')
df['datetime'] = pd.to_datetime(df['datetime'],errors='coerce')   #先转化为datetime类型,默认format='%Y-%m-%d %H:%M:%S'
df['date'] = df['datetime'].dt.date   #转化提取年-月-日
df['year'] =df['datetime'].dt.year.fillna(0).astype("int")   #转化提取年 ,
#如果有NaN元素则默认转化float64型，要转换数据类型则需要先填充空值,在做数据类型转换
df['month'] = df['datetime'].dt.month.fillna(0).astype("int")  #转化提取月
df['%Y_%m'] = df['year'].map(str) + '-' + df['month'].map(str) #转化获取年-月
df['day'] = df['datetime'].dt.day.fillna(0).astype("int")      #转化提取天
df['hour'] = df['datetime'].dt.hour.fillna(0).astype("int")    #转化提取小时
df['minute'] = df['datetime'].dt.minute.fillna(0).astype("int") #转化提取分钟
df['second'] = df['datetime'].dt.second.fillna(0).astype("int") #转化提取秒
df['dayofyear'] = df['datetime'].dt.dayofyear.fillna(0).astype("int") #一年中的第n天
df['weekofyear'] = df['datetime'].dt.weekofyear.fillna(0).astype("int") #一年中的第n周
df['weekday'] = df['datetime'].dt.weekday.fillna(0).astype("int") #周几，一周里的第几天，Monday=0, Sunday=6
df['quarter'] = df['datetime'].dt.quarter.fillna(0).astype("int")  #季度
display(df.head())
```


## Matplotlib

- Python 有非常丰富的第三方绘图库，matplotlib 使用起来也许并不是很便捷，因为图上每个元素都需要自己来定制。但仔细体会 matplotlib 背后的设计思想是很有趣的事情。seaborn 之类的绘图库是基于 matplotlib 封装的，因而后期需要自己灵活定制图形时就大大受用了。本文的两幅思维导图是基于两种不同的思路绘制的，偶有内容交叉，日常使用可以选择自己熟悉的方式（网上的教程大多是基于过程的函数式编程，即 pyplot 方法）。**建议配合最后附上出的参考资料学习**。

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170427-1.png)

![](https://raw.githubusercontent.com/woaielf/woaielf.github.io/master/_posts/Pic/1704/170427-2.png)

Reference
> 《Python for data analysis》<br>
[Matplotlib: Python plotting — Matplotlib 2.0.2 documentation](http://matplotlib.org/index.html) <br>
[绘图: matplotlib核心剖析](http://www.cnblogs.com/vamei/archive/2013/01/30/2879700.html#commentform) <br>
[【数据可视化】 之 Matplotlib](https://zhuanlan.zhihu.com/p/21443208?utm_medium=social&utm_source=qq?utm_medium=social&utm_source=qq) <br>
[Python--matplotlib绘图可视化知识点整理](http://python.jobbole.com/85106/) <br>
[一份非常好的Matplotlib 教程](http://blog.csdn.net/u011497262/article/details/52325705)


## pyecharts

- 【2020-11-27】多轮转化图

```python
import random
import pyecharts as pe
# 为了避免显示空白，加入以下代码执行后，重新刷新当前jupyter页面即可
pe.configure(
    jshost="https://pyecharts.github.io/assets/js",
    echarts_template_dir=None,
    force_js_embed=None,
    output_image=None,
    global_theme=None
)
# 代码参考：http://pyecharts.org/#/zh-cn/charts_base?id=heatmap%EF%BC%88%E7%83%AD%E5%8A%9B%E5%9B%BE%EF%BC%89
# x_axis = ["12a", "1a", "2a", "3a", "4a", "5a", "6a", "7a", "8a", "9a", "10a", "11a",
#     "12p", "1p", "2p", "3p", "4p", "5p", "6p", "7p", "8p", "9p", "10p", "11p"]
# y_axis = ["Saturday", "Friday", "Thursday", "Wednesday", "Tuesday", "Monday", "Sunday"]
# data = [[i, j, random.randint(0, 50)] for i in range(24) for j in range(7)]
page = pe.Page('多轮对话场景分析')
title = '投诉进度查询状态转化'
# (1) 节点状态转化图
x_axis = y_axis = attr_list
item_len = len(x_axis)
data = [[x_axis[i], y_axis[j], val_list[i][j]] for i in range(item_len) for j in range(item_len)]
heatmap = pe.HeatMap()
heatmap.add(
    '%s（x -> y）'%(title),
    x_axis,
    y_axis,
    data,
    is_visualmap=True,
    visual_range=[dh.get_values().min(), dh.get_values().max()],
    visual_text_color="#000",
    visual_orient="horizontal",
)
#heatmap.render()
page.add(heatmap)

# (2) Graph图谱
from pyecharts import Graph

nodes = [{"name": "结点1", "symbolSize": 10},
         {"name": "结点2", "symbolSize": 20},
         {"name": "结点3", "symbolSize": 30},
         {"name": "结点4", "symbolSize": 40},
         {"name": "结点5", "symbolSize": 50},
         {"name": "结点6", "symbolSize": 40},
         {"name": "结点7", "symbolSize": 30},
         {"name": "结点8", "symbolSize": 20}]
links = []
for i in nodes:
    for j in nodes:
        links.append({"source": i.get('name'), "target": j.get('name')})
nodes = json.loads(json.dumps(nodes))
graph = Graph("%s-状态图"%(title))
graph.add("", nodes, links, repulsion=80000, symbol='roundRect', layout='force',edgeSymbolSize= [0, 20],edgeSymbol =['circle', 'arrow'])
#graph.render()
page.add(graph)
# 集中渲染到html文件
page.render('muti_turn_vis.html')
page
```


# 结束
















