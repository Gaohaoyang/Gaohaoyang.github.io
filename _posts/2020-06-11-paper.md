---
layout: post
title:  "论文阅读-Paper-Club"
date:   2020-06-11 10:48:00
categories: 论文
tags: 深度学习 自然语言处理 sota 元学习 BLEU
excerpt: 最新技术咨询梳理，sota(the state of the art), 论文资料汇总
author: 鹤啸九天
mathjax: true
---

* content
{:toc}

# 最新技术



## 论文检索

- [AIMner学术头条](https://www.aminer.cn/)
- [PaperWeekly](https://www.paperweekly.site/home)（论文分享社区）
- 【2020-6-11】阿里员工开发的[论文知识图谱](https://www.connectedpapers.com/)
  - ![](http://p1.pstatp.com/large/pgc-image/37054b2db9b64394a73feecfa9ad024d)
- ak47开发的[arxiv最新文章跟进工具](http://www.arxiv-sanity.com/)
- [ResearchGate](https://www.researchgate.net/)（论文引用高效关联）
- 【2020-9-5】[What-I-Have-Read](https://github.com/xcfcode/What-I-Have-Read)，NLP论文解读集合

## Sota

- 【2021-3-7】[机器之心SOTA专栏](https://www.jiqizhixin.com/sota)
- [StateOfTheArt.ai](http://StateOfTheArt.ai)
- [Paperwithcode](https://paperswithcode.com)，[Browse State-of-the-Art](https://paperswithcode.com/sota)
- 【2020-7-5】快速找到最新AI技术的模型/代码/API】“[CatalyzeX: machine intelligence to catalyze your projects](https://www.catalyzex.com/)”


## NLP论文

- [NLP Progress](http://nlpprogress.com/english/dialogue.html)
- [nlp最新论文及代码](https://paperswithcode.com/search?q_meta=&q=generation+text)
- [100 Must-Read NLP Papers](http://masatohagiwara.net/100-nlp-papers/)
- 【按主题分类的自然语言处理文献大列表】[NLP Paper - natural language processing paper list](http://t.cn/A6Aia1D0)
- 清华NLP组文本生成方向：[Text Generation Reading List](https://github.com/THUNLP-MT/TG-Reading-List)
- [文本生成框架](https://tobiaslee.top/2019/08/31/TG-framework-notes/)：AllenNLP、FairSeq、OpenNMT、Texar、HuggingFace
- [中文公开聊天语料库](https://github.com/codemayq/chinese_chatbot_corpus)
- [Chatbot and Related Research Paper Notes with Images](https://github.com/ricsinaruto/Seq2seqChatbots/wiki/Chatbot-and-Related-Research-Paper-Notes-with-Images)

### NLP各方向论文综述

- 最新版见[NLP学习指南](https://github.com/leerumor/nlp_tutorial/blob/main/README.md)
- [2020 A Survey on Text Classification: From Shallow to Deep Learning](https://arxiv.org/pdf/2008.00364v2.pdf)
- [2020 A Survey on Recent Advances in Sequence Labeling from Deep Learning Models](https://arxiv.org/pdf/2011.06727)
- [2020 Evolution of Semantic Similarity - A Survey](https://arxiv.org/pdf/2004.13820)
- [2017 Neural text generation: A practical guide](https://arxiv.org/abs/1711.09534)
- [2018 Neural Text Generation: Past, Present and Beyond](https://arxiv.org/pdf/1803.07133.pdf)
- [2019 The survey: Text generation models in deep learning](https://www.sciencedirect.com/science/article/pii/S1319157820303360)
- [2020 Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732)

### NLP论文经验

【2020-9-30】[ACL 2020趋势总结](https://www.yanxishe.com/TextTranslation/2634)
- 交稿量最多的方向：通过机器学习处理自然语言，对话和交互系统，机器翻译，信息提取和自然语言处理的应用及生成。
  - ![](https://static.leiphone.com/uploads/new/sns/article/202007/1594719617791903.png)
  - 近10年来的[研究热点变化趋势图](https://public.flourish.studio/visualisation/2431551/)
  - 论文有从基础任务到高级任务发展的趋势，例如从通过单词级，句子级语义和语篇的句法，过渡到对话。机器学习方向研究也正稳步增加，越来越多的文章提出具有普遍性目标的模型，而这些模型都基于多个任务来衡量。

<div class="flourish-embed flourish-bar-chart-race" data-src="visualisation/2431551" data-url="https://flo.uri.sh/visualisation/2431551/embed" aria-label=""><script src="https://public.flourish.studio/resources/embed.js"></script></div>

- 模式：
  - <font color='blue'>基于某任务X调整了BERT模型，然后在评价标准Y下表现更好</font>
  - I fine-tuned BERT on task X and it improved the performance on benchmark Y
- 在自然语言处理研究有个反复出现的模式
   1. 介绍一个新模型；
   2. 通过改进模型，或者将其应用于多任务实现一些容易的目标然后发表；
   3. 发表文章分析其不足之处或缺陷；
   4. 发表新的数据集。
- 尽管某些步骤可能同时进行，现在就处于2和3之间。小标题的结论是基于我选择的论文得出的，过滤掉了这类文章。

- ACL 2020 文章摘要
  - （1）少了**套路**。
  - （2）不再依赖大型已标注数据集
    - 聚焦于更少监督的训练模型：
      - 无监督
        - [Yadav等人](https://www.aclweb.org/anthology/2020.acl-main.414.pdf)，基于检索的问答方法，可以迭代地将询问提炼到1KB
        - 常识类多选任务上，通过计算每个选项的合理性得分（利用Masked LM）,[Tamborrino等人](https://www.aclweb.org/anthology/2020.acl-main.357.pdf)取得了令人欣喜的成果。
      - 数据增强
        - [Fabbri等人](https://www.aclweb.org/anthology/2020.acl-main.413.pdf)提出了一种可以自动生成上下文的方法，问题和回答三合一的形式来训练问答模型。他们首先检索和原始数据相似的上下文，生成回答：是或否，并且以问句形式向上下文提问（what, when, who之类开头的问句）然后基于这三件套训练模型。
        - [Jacob Andreas](https://www.aclweb.org/anthology/2020.acl-main.676.pdf)提出将不常见的短语替换为在相似语境下更常用的短语从而改进神经网络中的组合泛化能力。
        - [Asai和Hajishirzi](https://www.aclweb.org/anthology/2020.acl-main.499.pdf)用人工例子增加问答训练数据，这些例子都是从原始训练数据中按逻辑衍生出来用以加强系统性和传递一致性。
      - 元学习
        - [Yu等人](https://www.aclweb.org/anthology/2020.acl-main.336.pdf)利用元学习去迁移知识用以从高源语言(high-resource language)到低源语言(low-resource language)的上义关系检测。
      - 主动学习
        - [Li等人](https://www.aclweb.org/anthology/2020.acl-main.738.pdf)搭建了一个高效的标注框架，通过主动学习选取最有价值的样本进行批注进行共指关系解析。
  - （3）语言模型不是全部，检索又回来了
    - 语言模型的不足： [Kassner and Schütze](https://www.aclweb.org/anthology/2020.acl-main.698.pdf)和 [Allyson Ettinger](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00298)的论文表明某些语言模型对否定不敏感，并且容易被错误的探针或相关但不正确的答案混淆。
    - 解法
      - ① 检索：在Repl4NLP研讨会上的两次受邀演讲中，有两次提到了检索增强的LMs。 Kristina Toutanova谈到了谷歌的[智能领域](https://arxiv.org/abs/2002.08909)，以及如何用实体知识来增强LMs(例如，[这里](https://arxiv.org/abs/2004.12006)和[这里](https://arxiv.org/abs/2004.07202))。 Mike Lewis谈到了改进事实知识预测的[最近邻LM模型](https://openreview.net/forum?id=HklBjCEKvH)，以及Facebook的将生成器与检索组件相结合的[RAG模型](https://arxiv.org/abs/2005.11401)。
      - ② 使用外部知识库：这已经普遍使用好几年了。[Guan等人](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00302)利用常识知识库中的知识来增强用于常识任务的GPT-2模型。[Wu等人](https://www.aclweb.org/anthology/2020.acl-main.515.pdf)使用这样的知识库生成对话。  
      - ③ 用新的能力增强 LMs：[Zhou 等人](https://www.aclweb.org/anthology/2020.acl-main.678.pdf)训练了一个 LM，通过使用带有模式和 SRL 的训练实例来获取时间知识(例如事件的频率和事件的持续时间) ，这些训练实例是通过使用带有模式和 SRL 的信息抽取来获得的。[Geva 和 Gupta](https://www.aclweb.org/anthology/2020.acl-main.89.pdf)通过对使用模板和需要对数字进行推理的文本数据生成的数值数据进行微调，将数值技能注入 BERT 中。 
    - 可解释 NLP
      - 检查注意力权重今年看起来已经不流行了，取而代之的关注重点是**生成文本依据**，尤其是那些能够反映判别模型决策的依据。[Kumar 和 Talukdar](https://www.aclweb.org/anthology/2020.acl-main.771.pdf) 提出了一种为自然语言推断（NLI）预测忠实解释的方法，其方法是为每个标签预测候选解释，然后使用它们来预测标签。[Jain 等人](https://www.aclweb.org/anthology/2020.acl-main.409.pdf) 开发了一种忠实的解释模型，其依赖于事后归因（post-hoc）的解释方法（这并不一定忠实）和启发式方法来生成训练数据。为了评估解释模型，[Hase 和 Bansa](https://www.aclweb.org/anthology/2020.acl-main.491.pdf) 提出通过测量用户的能力，在有或没有给定解释的前提下来预测模型的行为。
  - （4）反思NLP的当前成就，局限性以及对未来的思考
    - 求解的是数据集，而不是任务。在大量数据上训练模型，可能无法从可用的数据量中学到任何东西，而且这些模型在人类可能认为不相关的数据中找到统计模式。 建议应该标准化中等规模的预训练语料库，使用专家创建的评估集，并奖励成功的一次性学习。排行榜并不总是对推动这一领域有所帮助。 基准通常会占据分布的顶端，而我们需要关注分布的尾部。 此外，很难使用通用模型（例如LM）来分析特定任务的进步。
    - 当前模型和数据存在固有的局限性。 邦妮还说，神经网络能够解决不需要深入理解的任务，但是更具挑战性的目标是识别隐含的含义和世界知识。
    - 远离分类任务。 近年来，我们已经看到了许多证据，证明分类和多项选择任务很容易进行，并且模型可以通过学习浅层的数据特定模式来达到较高的准确性。 另一方面，生成任务很难评估，人类评估目前是唯一的信息量度，但是却很昂贵。将NLI任务从三向分类转换为较软的概率任务，旨在回答以下问题：“在假设前提下，假设成立的可能性有多大？”
    - 学习处理歧义和不确定性。 Ellie Pavlick在Repl4NLP上的演讲讨论了在明确定义语义研究目标方面的挑战。 将语言理论天真地转换为NLI样式的任务注定会失败，因为语言是在更广泛的上下文中定位和扎根的。 盖·艾默生（Guy Emerson）定义了分布语义的期望属性，其中之一是捕获不确定性。 冯等。 设计的对话框响应任务和模型，其中包括“以上皆非”响应。 最后，Trott等 指出，尽管语义任务关注的是识别两种话语具有相同的含义，但识别措辞上的差异如何影响含义也很重要。   
  - （5）有关道德伦理的讨论（很复杂）
    - 强烈推荐观看 Rachael Tatman 在 [WiNLP](http://www.winlp.org/) 研讨会上洞见深入的主题演讲「[What I Won’t Build](https://slideslive.com/38929585/what-i-wont-build)（我不会构建的东西）」。Rachael 说明了她个人不会参与构建的那几类系统，包括监控系统、欺骗与其交互的用户的系统、社会类别监测系统。她提供了一个问题列表，研究者可用来决定是否应该构建某个系统：
      - 该系统将让哪些人获益？
      - 该系统对哪些人有害？
      - 用户可以选择退出吗？
      - 该系统会强化还是弱化系统的不公平性？
      - 该系统总体上会让世界变得更好吗？


# 顶会信息

## 资讯

- [AI Conference Deadlines顶会截止时间](https://aideadlin.es/?sub=ML,NLP,RO,SP,DM)
- [Conference Ranks](http://www.conferenceranks.com/#)


## 录用论文

- 【2020-7-18】[2020 IJCAI](https://www.ijcai.org/Proceedings/2020/)，[ICML 2020](https://proceedings.icml.cc/book/2020)
- 【2021-2-5】[2021年AAAI论文录取](https://aaai.org/Conferences/AAAI-21/)

# 研究

- 【2020-8-28】【Eric的博士生生存指南】《[Syllabus for Eric's PhD students - Google Docs](https://docs.google.com/document/d/11D3kHElzS2HQxTwPqcaTnU5HCJ8WGE5brTXI4KLf4dM/preview?pru=AAABdEw6n2A*Q0YVpfw_ms0fZOf3P5-_hw)》by Eric Gilbert


## 研究思路

### [好的想法从哪里来](https://www.aminer.cn/research_report/5de5cd5caf66005a44823119)

- 做过一些研究的同学会有感受，仅阅读自己研究方向的文献，新想法还是不会特别多。这是因为读到的都是该研究问题已经完成时的想法，它们本身无法启发新的想法。
- 如何产生新的想法呢？有三种可行的基本途径：
  - `实践法`。即在研究任务上实现已有最好的算法，通过分析实验结果，例如发现这些算法计算复杂度特别高、训练收敛特别慢，或者发现该算法的错误样例呈现明显的规律，都可以启发你改进已有算法的思路。现在很多自然语言处理任务的Leaderboard上的最新算法，就是通过分析错误样例来有针对性改进算法的 [1]。
  - `类比法`（迁移）。即将研究问题与其他任务建立类比联系，调研其他相似任务上最新的有效思想、算法或工具，通过合理的转换迁移，运用到当前的研究问题上来。例如，当初注意力机制在神经网络机器翻译中大获成功，当时主要是在词级别建立注意力，后来我们课题组的林衍凯和沈世奇提出建立句子级别的注意力解决关系抽取的远程监督训练数据的标注噪音问题 [2]，这就是一种类比的做法。
  - `组合法`。即将新的研究问题分解为若干已被较好解决的子问题，通过有机地组合这些子问题上的最好做法，建立对新的研究问题的解决方案。例如，我们提出的融合知识图谱的预训练语言模型，就是将BERT和TransE等已有算法融合起来建立的新模型 [3]。

- 与阅读论文、撰写论文、设计实验等环节相比，如何产生好的研究想法，是一个不太有章可循的环节，很难总结出固定的范式可供遵循。像小马过河，需要通过大量训练实践，来积累自己的研究经验。不过，对于初学者而言，仍然有几个简单可行的原则可以参考。
  - （1）一篇论文的可发表价值，取决于它**与已有最直接相关工作间的Delta**。我们大部分研究工作都是站在前人工作的基础上推进的。牛顿说：**如果说我看得比别人更远些，那是因为我站在巨人的肩膀上**。在我看来，评判一篇论文研究想法的价值，就是看它站在了哪个或哪些巨人的肩膀上，以及在此基础上又向上走了多远。反过来，在准备开始一项研究工作之前，在形成研究想法的时候，也许要首先明确准备站在哪个巨人的肩膀上，以及计划通过什么方式走得更远。与已有最直接相关工作之间的Delta，决定了这个研究想法的价值有多大。
  - （2）**兼顾摘果子和啃骨头**。人们一般把比较容易想到的研究想法，叫做Low Hanging Fruit（**低垂果实**）。低垂果实容易摘，但同时摘的人也多，选择摘果子就容易受到想法撞车的困扰。例如，2018年以BERT为首的预训练语言模型取得重大突破，2019年中就出现大量改进工作，其中以跨模态预训练模型为例，短短几个月里 [arxiv](http://arxiv.org)上挂出了超过六个来自不同团队的图像与文本融合的预训练模型。设身处地去想，进行跨模态预训练模型研究，就是一个比较容易想到的方向，你一定需要有预判能力，知道世界上肯定会有很多团队也同时开展这方面研究，这时你如果选择入场，就一定要做得更深入更有特色，有自己独特的贡献才行。相对而言，那些困难的问题，愿意碰的人就少，潜下心来啃硬骨头，也是不错的选择，当然同时就会面临做不出来的风险，或者做出来也得不到太多关注的风险。同学需要根据自身特点、经验和需求，兼顾摘果子和啃骨头两种类型的研究想法。
  - （3）注意多项研究工作的**主题连贯性**。同学的研究训练往往持续数年，需要注意前后多项研究工作的主题连贯性，保证内在逻辑统一。需要考虑，在个人简历上，在出国申请Personal Statement中，或者在各类评奖展示中，能够将这些研究成果汇总在一起，讲出自己开展这些研究工作的总目标、总设想。客观上讲，人工智能领域研究节奏很快，技术更新换代快，所以成果发表也倾向于小型化、短平快。我有商学院、社科的朋友，他们一项研究工作往往需要持续一年甚至数年以上；高性能计算、计算机网络方向的研究周期也相对较长。人工智能这种小步快跑的特点，决定了很多同学即使本科毕业时，也会有多篇论文发表，更不用说硕士生、博士生。在这种情况下，就格外需要在研究选题时，注意前后工作的连贯性和照应关系。几项研究工作放在一起，到底是互相割裂说不上话，还是在为一个统一的大目标而努力，格外反映研究的大局意识和布局能力。例如，下图是我们课题组涂存超博士2018年毕业时博士论文《面向社会计算的网络表示学习》的章节设置，整体来看就比《社会计算的若干重要问题研究》等没有内在关联的写法要更让人信服一些。当然，对于初学者而言，一开始就想清楚五年的研究计划，根本不可能。但想，还是不去想，结果还是不同的。
  - （4）注意**总结和把握研究动态和趋势，因时而动**。
    - 2019年在知乎上有这样一个问题：“<font color='blue'>2019年在NLP领域，资源有限的个人/团队能做哪些有价值有希望的工作？</font>” 
    - 我当时的回答如下：
      - 我感觉，产业界开始集团化搞的问题，说明其中主要的开放性难题已经被解决得差不多了，如语言识别、人脸识别等，在过去20年里面都陆续被广泛商业应用。看最近的BERT、GPT-2，我理解更多的是将深度学习对大规模数据拟合的能力发挥到极致，在深度学习技术路线基本成熟的前提下，大公司有强大计算能力支持，自然可以数据用得更多，模型做得更大，效果拟合更好。
      - 成熟高新技术进入商用竞争，就大致会符合摩尔定律的发展规律。现在BERT等训练看似遥不可及，但随着计算能力等因素的发展普及，说不定再过几年，人人都能轻易训练BERT和GPT-2，大家又会在同一个起跑线上，把目光转移到下一个挑战性难题上。
      - 所以不如提前考虑，**哪些问题是纯数据驱动技术无法解决的**。NLP和AI中的困难任务，如<font color='green'>常识和知识推理，复杂语境和跨模态理解，可解释智能</font>，都还没有可行的解决方案，我个人也不看好数据驱动方法能够彻底解决。更高层次的联想、创造、顿悟等认知能力，更是连边还没碰到。这些正是有远见的研究者们应该开始关注的方向。
  - 需要看到，不同时期的研究动态和趋势不同。把握这些动态和趋势，就能够做出研究社区感兴趣的成果。不然的话，即使研究成果没有变化，只是简单早几年或晚几年投稿，结果也会大不相同。例如，2013年word2vec发表，在2014-2016年之间开展词表示学习研究，就相对比较容易得到ACL、EMNLP等会议的录用；但到了2017-2018年，ACL等会议上的词表示学习的相关工作就比较少见了。

- 周志华：[做研究与写论文](https://zhuanlan.zhihu.com/p/98747105)

## 写作

- 【2020-7-4】【论文写作相关资源大列表】’Paper Writing' by wangdongdut [GitHub](https://github.com/wangdongdut/PaperWriting)

- 【2021-1-1】如何让文章写的更好？源自：[哥大读博五年总结](https://zhuanlan.zhihu.com/p/338191470)
- 总体思路：
  - **先给一个Talk**。写paper最难的是<font color='red'>构思storyline</font>，最好的方法就是做一个slides，给周围的人present一遍。这个过程中，梳理好自己的思路，画好文中的figure，准备好实验结果的table，周围的人给你提意见，帮助你完善，等这个talk给完了，后面写paper就会顺畅自然了。其实准备投一个paper，当做了一段时间后，就会按照最终presentation的思路，准备slides，用在每周给老板们report时。开头先快速review一下做的task和提出的方法，remind一下context，然后重点focus在那周做的新东西上，所以每周汇报的slides可能80%都是跟上一周一样的，然后新的方法和实验结果的那几页slides是新的，有比较多的细节。
  - **用Google doc做语法检查**。刚写好的paper有typo和语法错误是很难避免的，但常常会被reviewer揪着不放。大家写paper如今大都在overleaf上，但overleaf的查错还是不够好，建议可以写完paper后，贴到Google doc里面。几年前开始，估计是由于deep learning对Google NLP的改进很大，感觉Google自动改的质量已经非常高了。
  - **Rationale很重要**。不光是要讲清楚怎么做的，更要justify为什么这么做；不光要讲结果比baseline好，更要解释为什么好；读者看到的不应是一个“使用手册”。有时候花了很多篇幅写了实现细节，更重要的是解释“为什么”，这个背后的逻辑和insights。
- 大部分paper都是**提出一个新的方法**，这类paper都可以套这个框架：
  - Introduction：可以分为以下几个部分：
    - Problem definition
    - Previous methods and their limits
    - 简单描述你是提出了什么技术来overcome上面的limits
    - 一个图，非常high-level的解释前人工作的limits和你的工作怎么解决了这些limits，最好让人30秒内完全看懂
    - 最后一段如今大都是，In summary, this paper makes three contributions:
      - First work to解决什么limits
      - 提出了什么novel的技术
      - outperform了state-of-the-art多少
  - Related Work：一般三五个subsection，分别review下相关的topics，同样不光讲previous work做了啥，更要讲自己的方法跟前人工作有啥不同
  - Method
    - 这是文章的主体，按照你觉得最容易让别人看懂的方式来讲
    - 可以第一个subsection是overview，formulate一下你的problem给出notation，配一个整体framework的图，图里面的字体不能太大或者太小看不清，   - 要有些细节，让人光看图就能明白你的方法是怎么回事，但不要过于复杂，让人在不超过2分钟的时间看完这张图
    - 然后几个subsection具体介绍你的方法或者模型；如果testing跟training不太一样，最后一个subsection介绍inference时候的不同，通常是一些post-processing操作
  - Experiment
    - Datasets
    - Implementation details such as pre-processing process, training recipe
    - Evaluation metrics
    - Comparisons with state-of-the-art
    - Detailed analysis
      - Alternative design choice exploration
      - Ablation studies
      - Visualization examples
  - Conclusion (and Future Work)
  - Abstract：是全文的精简版，建议在paper写完第一稿差不多成型了，有定下来的成熟的storyline了，再去写abstract；大概就是用一两句话分别概括paper里面每个section，然后串起来
- presentation的技巧：
  - 如果可能的话，事先了解听众背景，是做同一个topic的，还是同一个大领域但不同topic的，还是完全其他专业背景的。需要根据听众背景，定制和调整：比如，需不需要多介绍些背景？需不需要更深入技术细节？等等
  - 一页slide尽可能focus在一个点上，不要信息量过大，否则听众很容易lost
  - 尽可能多用图片表达，不要大段大段的列文字，A picture is worth a thousand words
  - 上面这两点，其实principle都是尽量让要讲的内容简单明了，因为很多时候我们在听talk，这样被动接受的时候，接受新知识的能力是比主动接受时候（比如看paper）低的。
  - 当听众问问题的时候，If you don’t know the answer, just say don’t know.
  - 如果是跟mentor日常讨论的slides，因为会讨论到很细节的东西，有些图PPT画起来，很花时间，而且通常这样细节的图还挺多，所以可以就ipad上面手画一画，截个图放到PPT里就好了；如果是正式一点的presentation，写slides跟写paper的principle有点像，不要太focus在细节上，更重要的是讲清楚motivation，为什么这样设计，细枝末节的不关键的内容，放在backup slides里面。

## 小样本学习

- 【2021-1-1】[小样本学习方法(FSL)演变过程](https://zhuanlan.zhihu.com/p/149983811)
- 小样本学习方法(FSL)演变过程以及MAML和度量学习的区别所在
- 小样本学习一般会简化为N-way K-shot问题，[如图](https://pic2.zhimg.com/80/v2-f620ca7321227e502aeb087ca22f38ed_720w.jpg)。其中N代表类别数量，K代表每一类中(支持集)的样本量；
  - ![](https://pic2.zhimg.com/80/v2-f620ca7321227e502aeb087ca22f38ed_720w.jpg)
- 解决分类问题，人们最先想到的是采用传统监督学习的方式，直接在训练集上进行训练，在测试集上进行测试，如图，但神经网络需要优化的参数量是巨大的，在少样本条件下，几乎都会发生过拟合；
  - ![](https://pic2.zhimg.com/80/v2-c90efb24dbe41cfd580630df1034f10d_720w.jpg)
- 首先想到的是通过使用迁移学习+Fine-tune的方式，利用Base-classes中的大量数据进行网络训练，得到的Pre-trained模型迁移到Novel-classes进行Fine-tune，如图。虽然是Pre-trained网络+Fine-tune微调可以避免部分情况的过拟合问题，但是当数据量很少的时候，仍然存在较大过拟合的风险。
  - ![](https://pic1.zhimg.com/80/v2-68f3e6f197585df5798fdb99855ad5cc_720w.jpg)
- 小样本学习中极具分量的Meta-learning方法，现阶段绝大部分的小样本学习都使用的是Meta-learning方法。Meta-learning，即learn to learn，翻译成中文是元学习。Meta-learning共分为Training和Testing两个阶段
  - (1) Training阶段的思路如图[4]。
    - ![](https://pic4.zhimg.com/80/v2-bb502fe159dbfdda83e308d8546a6103_720w.jpg)
    - 简单描述下流程：
      - 1：将训练集采样成Support set和Query set两部分；
      - 2：基于Support set生成一个分类模型；
      - 3：利用模型对Query set进行分类预测生成predict labels；
      - 4：通过query labels和predict labels进行Loss(e.g., cross entropy loss )计算，从而对分类模型 中的参数θ进行优化。
  - (2) Testing阶段的思路如图，利用Training阶段学来的分类模型在Novel class的Support set上进行进一步学习，学到的模型对Novel class的Query set进行预测。
    - ![](https://pic4.zhimg.com/80/v2-3ad39b2b18f6def704d82c5fa1d0eb73_720w.jpg)
  - 元学习整体流程
    - ![](https://pic3.zhimg.com/80/v2-de7542790f48107f6d67a83b1e9e9e8e_720w.jpg)
  - Meta-learning核心点之一是如何通过少量样本来学习这个分类模型，即图中的key部分。
  - 在这里引出了Meta-learning的两个主要方法：
    - 度量学习(Matrix-based Meta-learning)和MAML(Optimization-based Meta-learning)


## 元学习

- 【2020-9-19】[什么是元学习（meta-learning）?](https://www.toutiao.com/i6873363794463195655/)
- **元学习**（Meta Learning）或者叫做“学会学习”（Learning to learn），它是要“学会如何学习”，即利用以往的知识经验来指导新任务的学习，具有学会学习的能力。
  - 瑞士Dalle Molle人工智能研究所的联合主任Jürgen Schmidhuber（LSTM发明人）在1987年毕业论文《Evolutionary principles in selfreferential learning. (On learning how to learn: The meta-meta-... hook.)》中最早提出了元学习的概念。在 1992 和 1993 两年里又借助循环神经网络进一步发展元学习方法。
- 由于元学习可帮助模型在少量样本下快速学习，从元学习的使用角度看，人们也称之为**少次学习**（Few-Shot Learning）。
  - 如果训练样本数为 1，则称为**一次学习**（One-Shot Learning）；
  - 训练样本数为 K，称为 **K次学习**；
  - 更极端地，训练样本数为 0，称为**零次学习**（Zero-Shot Learning）。
- 另外，**多任务学习**（Multitask Learning）和**迁移学习**（Transfer Learning）在理论层面上都能归结到元学习的大家庭中。
- 当前的深度学习大部分情况下只能从头开始训练。使用Finetune来学习新任务，效果往往不好，而Meta Learning 就是研究如何让神经元两个很好的利用以往的知识，使得能根据新任务的调整自己。

- 元学习可以简单地定义为获取知识多样性 (knowledge versatility) 的能力。
- 元学习要解决的就是这样的问题 : 设计出拥有获取知识多样性能力的机器学习模型，它可以在基于过去的经验与知识下，通过少量的训练样本快速学会新概念和技能。
  - 例如完成在非猫图像上训练的分类器可以在看到一些猫图片之后判断给定图像是否包含猫
  - 帮游戏机器人能够快速掌握新游戏,使迷你机器人在测试期间在上坡路面上完成所需的任务，即使它仅在平坦的表面环境中训练



### 元学习与多任务学习以及迁移学习的对比

- 元学习虽然从适应新任务的角度看，像是多任务学习；从利用过去信息的角度看，又像迁移学习。不过相对比二者还是有自己的特殊性
  - 相较于迁移学习，元学习模型的泛化不依赖于数据量。迁移学习微调阶段还是需要大量的数据去喂模型的，不然会很影响最终效果。而元学习的逻辑是在新的任务上只用很少量的样本就可以完成学习，看一眼就可以学会。从这个角度看，迁移学习可以理解为元学习的一种效率较低的实现方式。
  - 对比多任务学习，元学习实现了无限制任务级别的泛化。因为元学习基于大量的同类任务 ( 如图像分类任务 ) 去学习到一个模型，这个模型可以有效泛化到所有图像分类任务上。而多任务学习是基于多个不同的任务同时进行损失函数优化，它的学习范围只限定在这几个不同的任务里，并不具学习的特性。
- 【2021-1-1】知乎总结 [aluea](https://www.zhihu.com/question/299020462/answer/846980686)
  - 迁移学习和元学习共同点就是泛化到没训过的任务上，或者是特定数据一些没见过的类。
  - 两者一个是字面上的迁移学习，一个是**学会学习**。迁移学习简单来说就是，以前训练了一个模型，现在有个新任务，仍想用上那个模型。元学习完全不拘泥于模型，以前学过一些东西，现在新任务得用上它们。从定义上来看，使用迁移学习来实现元学习是一个天然直观的想法，这就是两者的关系。
- [anders](https://www.zhihu.com/question/299020462/answer/1062703759)：元学习经常与另一个话题更相关，多任务学习，两者之间经常是形影不离。
  - 多任务学习属于parallel transfer learning，而一般意义的迁移学习是sequential transfer learning。
  - 多任务学习中的知识迁移，是并行进行的，多个任务的学习没有先后关系。而一般情况的迁移学习中的知识迁移，是串行进行的，即多个任务的学习过程存在先后关系。
  - 需要说的是，不少的多任务学习模型背后都有着元学习的影子，但这些多任务学习的研究往往不会从元学习的角度去解释和思考问题。实际上，元学习也启发了不少多任务学习模型，可以从元学习的角度去解释多任务学习的有效性。



### 元学习与有监督学习、强化学习的对比

- 分类
  - 有监督学习和强化学习称为**从经验中学习**（Learning from Experiences) , 下面简称`LFE`； 
  - 而把元学习称为**学会学习**（Learning to Learn) , 下面简称`LTL`。
- 二者区别
  - ① 训练集不同
    - LFE的训练集面向一个任务，由大量的训练经验构成，每条训练经验即为有监督学习的（样本，标签）对，或者强化学习的回合（episode) 
    - 而LTL的训练集是一个任务集合，其中的每个任务都各自带有自己的训练经验。
  - ② 预测函数不同
    - ![](https://p3-tt.byteimg.com/origin/pgc-image/b185dc4f49154d6a878f449f1880ddd1?from=pc)
  - ③ 损失函数不同
    - ![](https://p3-tt.byteimg.com/origin/pgc-image/7273df5187dc43588deb5431e0ebc749?from=pc)
  - ④ 评价指标不同
    - ![](https://p1-tt.byteimg.com/origin/pgc-image/dcd3b3d8b4ce47acbfb2da50703f5fb1?from=pc)
  - ⑤ 学习内涵不同
    - LFE是基层面的学习，学习的是样本特征（或数据点）与标签之间呈现的相关关系，最终转化为学习一个带参函数的形式；
    - 而LTL是在基层面之上，元层面的学习，学习的是多个相似任务之间存在的共性。不同任务都有一个与自己适配的最优函数，因此LTL是在整个函数空间上做学习，要学习出这些最优函数遵循的共同属性。
  - ⑥ 泛化目标不同
    - LFE的泛化目标是从训练样本或已知样本出发，推广到测试样本或新样本；
    - 而LTL的泛化目标是从多个不同但相关的任务入手，推广到一个个新任务。LTL的泛化可以指导LFE的泛化，提升LFE在面对小样本任务时的泛化效率。
  - ⑦ 与其他任务的关系不同
    - LFE只关注当前给定的任务，与其他任务没关系；
    - 而LTL的表现不仅与当前任务的训练样本相关，还同时受到其他相关任务数据的影响，原则上提升其他任务的相关性与数据量可以提升模型在当前任务上的表现。



# 技术无止境

> 注意：
> - 始终记住我们是做算法的，多想想自己的工作泛化能力有多强，技术亮点在哪儿，模板映射谁都能想到，没有什么技术难度，做起来容易，说起来却难以开口，到时候别埋怨自己的工作内容没技术含量了
> - 工作中不缺乏技术点，缺乏发现的眼睛。技术点无处不在。
> - 别被产品、运营的思路限制，做什么，怎么做，做得怎么样，我们都是可以控制的

宗旨：
- 从业务中来（0→1）：提炼、归纳可以泛化的平台能力，一次开发，多次使用，业务弱相关，人力解绑，多花些心思打磨核心竞争力（技术+思维方式）
- 到业务中去（1→n）：通用能力快速应用到具体业务，可以小幅定制，尽量避免过多一次性工作，项目做了一堆，却感觉不到成长

- 技术转化路线
   - 技术点 → 专利（10篇）、项目、公众号、论文

## 说明

- 跟进NLP、对话方向最新技术
- [ACL 2020趋势总结](https://wqw547243068.github.io/2020/06/11/paper/?query=paper#nlp%E8%AE%BA%E6%96%87%E7%BB%8F%E9%AA%8C)

## 论文

- [NLP Progress](http://nlpprogress.com/english/dialogue.html)
- [nlp最新论文及代码](https://paperswithcode.com/search?q_meta=&q=generation+text)
- [100 Must-Read NLP Papers](http://masatohagiwara.net/100-nlp-papers/)
- 【按主题分类的自然语言处理文献大列表】[NLP Paper - natural language processing paper list](http://t.cn/A6Aia1D0)
- 清华NLP组文本生成方向：[Text Generation Reading List](https://github.com/THUNLP-MT/TG-Reading-List)
- [文本生成框架](https://tobiaslee.top/2019/08/31/TG-framework-notes/)：AllenNLP、FairSeq、OpenNMT、Texar、HuggingFace
- [中文公开聊天语料库](https://github.com/codemayq/chinese_chatbot_corpus)
- [Chatbot and Related Research Paper Notes with Images](https://github.com/ricsinaruto/Seq2seqChatbots/wiki/Chatbot-and-Related-Research-Paper-Notes-with-Images)

## 技术点

- 培训机器人的技术点
  1. 知识追踪在培训中应用：出题式培训按照知识追踪提前预估
  1. Data2text：题目自动生成，业务方只需要准备关键词
  1. 问答模型：IR-QA/KB-QA/MRC-QA
  1. 多轮改写：解决单轮问答里的信息缺失问题，指代消解和信息补全
  1. 小贝客户模拟器
  1. 小贝主动发问策略：RL里的DQN/BBQ等
  1. 闲聊：基于模板的文本生成
  1. 基于画像的文本风格话
  1. 元学习在培训中应用：小样本学习，业务方不太可能按照监督学习模式提供大规模标注语料，他们能准备的只有100-200的少样本，因此需要探索小样本学习、语义匹配模式实现NLU功能
  1. 多模态会话评价：除了文本，还要结合行为（页面点击）、情绪、声音特征
  1. 因果推理
    - 基于模型的评价结果无法定位到哪个因素导致结果分数低
    - 基于规则的评价方法可控，但是泛化能力弱
    - 因果推理可以根因到具体哪个特征影响了分数，反事实干预
  1. 可解释性
    - 机器学习可解释性探索


### 对话评估

- 尤其是无监督领域 @chaiying002 @zhengkaiyu001 @huzhuo002 
- 论文：
   - 一篇解决对话无监督评估的论文：[How NOT To Evaluate Your Dialogue System: An Empirical Study of
Unsupervised Evaluation Metrics for Dialogue Response Generation](https://arxiv.org/pdf/1603.08023.pdf)
   - 该论文[引用图谱](https://www.connectedpapers.com/main/129cbad01be98ee88a930e31898cb76be79c41c1/How-NOT-To-Evaluate-Your-Dialogue-System-An-Empirical-Study-of-Unsupervised-Evaluation-Metrics-for-Dialogue-Response-Generation/graph)

![image](/uploads/ae9d9c77bebfd2b154eed46460646206/image.png)
![image](/uploads/05c8be077322c3106ecb3f471b22150d/image.png)

|方法|全称|应用场景|核心思想|特点|缺点|改进|备注|
|---|---|---|---|---|---|---|---|
|BLEU|Machine Translation|比较候选译文和参考译文里的 n-gram 的重合程度|n-gram共现统计;基于精确率|只看重精确率，不看重召回率；存在常用词干扰（可以用截断的方法解决）；短句得分较高。即使引入了brevity penalty，也还是不够。|截断：改进常用词干扰；brevity penalty：改进短句得分较高的问题||
|NIST|National Institute of standards and Technology|BLEU改进|引入了每个n-gram的信息量(information)，对于一些出现少的重点的词权重就给的大了 |||||
|METEOR|Metric for Evaluation of Translation with Explicit ORdering，显式排序的翻译评估指标|Machine Translation、Image Caption|解决一些 BLEU 标准中固有的缺陷|unigram共现统计；基于F值；考虑同义词、词干|只有java实现；参数较多，4个自己设置；需要外部知识源，比如：WordNet|||
|ROUGE|Recall-Oriented Understudy for Gisting Evaluation，面向召回率的摘要评估辅助工具|Text Summarization|BLEU 的改进版，专注于召回率而非精度。多少个参考译句中的 n 元词组出现在了输出之中。大致分为四种：ROUGE-N，ROUGE-L，ROUGE-W，ROUGE-S|n-gram共现统计、最长公共子序列；基于召回率(ROUGE-N)和F值(ROUGE-L)|基于字的对应而非基于语义，可以通过增加参考摘要数量来缓解|ROUGE-S：统计skip n-gram而非n-gram；ROUGE-W：考虑加权的最长公共子序列||
|Perplexity|困惑度|Machine Translation、Language Model|根据句子长度对语言模型得分进行Normalize|基于语言模型（我感觉其实也是n-gram）；困惑度越低，翻译质量越好|数据集越大，困惑度下降得越快；数据中的标点会对模型的PPL产生很大影响；常用词干扰|||
|CIDEr|Consensus-based Image Description Evaluation，基于共识的图像描述评估|Image Caption|TF-IDF向量的夹角余弦度量相似度|TF-IDF；余弦相似度|与ROUGE一样，也只是基于字词的对应而非语义的对应|||
|SPICE|Semantic Propositional Image Caption Evaluation，语义命题图像标题评估|Image Caption|||主要考察名词的相似度，不适合机器翻译|||
|||||||||

详见[地址](https://wqw547243068.github.io/2020/04/28/text-generation/?query=%E8%AF%84%E4%BB%B7#%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95)

### DM对话管理器

#### DST

- 最新的论文，基于BERT的DST，[A Simple But Effective Bert Model for Dialog State Tracking on Resource-Limited Systems](https://ieeexplore.ieee.org/document/9053975)
- 参考对话系统领域[sota论文](http://nlpprogress.com/english/dialogue.html)


### 口语书面化

- 【2020-10-26】用文本匹配方法做文本摘要，[ACL 2020论文代码](https://github.com/maszhongming/MatchSum)
- 文本摘要方向sota论文及代码[集合](https://paperswithcode.com/task/text-summarization)
![image](/uploads/1a4801d5e50d8c557e9c29288c348f1a/image.png)
   - 用这个，bertsum，排名第一，pytorch代码，含模型文件，https://github.com/nlpyang/PreSumm
   - [Text Summarization on WikiHow](https://paperswithcode.com/sota/text-summarization-on-wikihow)，第一名[代码](https://github.com/nlpyang/PreSumm)
   - ![image](/uploads/e0788806f37348d362afb4378f25dab8/image.png)

### 文本生成

- 综述，截止2019年12月
![image](/uploads/f8ccaab435a3519e0d5815a960e37b95/image.png)
- 【2020-10-22】训练场文案生成，华山论剑上分享的[文本生成综述](https://share.weiyun.com/6Fauw23u)
- [大众点评信息流基于文本生成的创意优化实践](https://tech.meituan.com/2019/03/14/information-flow-creative-optimization-practices.html)：文本生成的三种主流方法各自的优劣势：
  - **规划式**：根据结构化的信息，通过语法规则、树形规则等方式规划生成进文本中，可以抽象为三个阶段。宏观规划解决“说什么内容”，微观规划解决“怎么说”，包括语法句子粒度的规划，以及最后的表层优化对结果进行微调。其优势是控制力极强、准确率较高，特别适合新闻播报等模版化场景。而劣势是很难做到端到端的优化，损失信息上限也不高。
  - **抽取式**：顾名思义，在原文信息中抽取一部分作为输出。可以通过编码端的表征在解码端转化为多种不同的分类任务，来实现端到端的优化。其优势在于：能降低复杂度，较好控制与原文的相关性。而劣势在于：容易受原文的束缚，泛化能力不强。
  - **生成式**：通过编码端的表征，在解码端完成序列生成的任务，可以实现完全的端到端优化，可以完成多模态的任务。其在泛化能力上具有压倒性优势，但劣势是控制难度极大，建模复杂度也很高。
![image](/uploads/6e2268286de04392521426ff66724ed0/image.png)

- 【2021-1-4】题目自动生成[data2text](https://zhuanlan.zhihu.com/p/82054729)
  - 应用点是业务方设计题目时，不用再费劲编写题目，只需设置知识点，系统根据知识点+问题类型生成候选题目，业务方验证通过即可
- 【2021-3-29】文本风格迁移综述，[一文超详细讲解文本风格迁移](https://zhuanlan.zhihu.com/p/159039652)
  - ![](https://pic2.zhimg.com/80/v2-da58494400a380027e47ff97af6b97fd_1440w.jpg)

### 多轮改写

- 【2020-11-25】腾讯微信AI Labs发表的多轮改写
   - [Improving Multi-turn Dialogue Modelling with Utterance ReWriter](https://www.aclweb.org/anthology/P19-1003.pdf)，通过query改写提升对话效果，开源代码基于lstm，有人改造成transformer[版本](https://github.com/liu-nlper/dialogue-utterance-rewriter)
![image](/uploads/769d3cd23fba0061a6fcca8d1d6dd976/image.png)

### 文本匹配

- 文本匹配

### 文本聚类

- 聚类算法

### 知识追踪

- 【2020-11-20】[Knowledge Tracing](https://paperswithcode.com/task/knowledge-tracing)
- VR培训场景中，知识点可以按照两个维度划分：①具体：对楼盘、小区、房源掌握程度②抽象：逻辑能力、需求挖掘能力、突发应对能力等，这样EE和AE都好做了，解释性也很好

## 新技术

- 因果推理，[代码实践](https://github.com/microsoft/dowhy/blob/master/docs/source/example_notebooks/tutorial-causalinference-machinelearning-using-dowhy-econml.ipynb)

- 【2021-2-4】佐治亚理工调解机器人, [An Intervening Ethical Governor for a Robot Mediator in Patient-Caregiver Relationships](https://www.cc.gatech.edu/ai/robot-lab/online-publications/ICRE15_shim_arkin.pdf)



# 结束


