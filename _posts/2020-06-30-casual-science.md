---
layout: post
title:  "因果科学-Casual-Science"
date:   2020-06-30 16:03:00
categories: 自然语言处理 深度学习
tags: 深度学习 NLP KG 知识图谱 表示学习 因果科学 集智俱乐部 广告预估
excerpt: 如何让AI系统具备真正的推理能力？图灵奖得主、贝叶斯网络之父 Judea Pearl 的解法——因果科学
author: 鹤啸九天
mathjax: true
---

* content
{:toc}


# 总结

- 【2020-9-2】[Bengio讲授因果表示学习，Mila博士因果推理导论开课了](https://www.toutiao.com/i6867722568795685387)，从机器学习的角度编写的《Introduction to Causal Inference》秋季[课程](https://www.bradyneal.com/causal-inference-course#course-textbook)，[教材地址](https://www.bradyneal.com/Introduction_to_Causal_Inference-Aug27_2020-Neal.pdf)，[YouTube地址](https://www.youtube.com/watch?v=CfzO4IEMVUk&list=PLoazKTcS0Rzb6bb9L508cyJ1z-U9iWkA0&index=1)，由 Yoshua Bengio 高徒 Brady Neal 主讲，主要讲述因果推理相关知识。此外，该课程整合了来自许多不同领域的见解，如流行病学、经济学、政治学和机器学习等，这些领域都利用到了因果推理。
  - ![](https://p3-tt.byteimg.com/origin/pgc-image/50a7c51c7b664c4d97c6ffce404790e2?from=pc)
  - 内容：
    - 图模型、后门调整和因果模型结构；
    - 随机化实验、前门调整、do-calculus 和通用识别；
    - 估值和条件平均处理效应（Conditional Average Treatment Effects）；
    - 未观察到的的混淆、边界以及敏感性分析；
    - 工具变量、断点回归、双重差分和合成控制法；
    - 有实验的因果关系发现；
    - 无实验的因果关系发现；
    - 可移植性和迁移学习；
    - 反事实推理以及中介和特定路径效应（Mediation and Path-Specific Effects）。
- **乌鸦智能** ＞ **鹦鹉智能**
  - [因果观念新革命？万字长文，解读复杂系统背后的暗因果](https://swarma.org/?p=19906)，[集智俱乐部因果科学专题Github](https://github.com/CausalAI/clubjizhi)，[因果科学与 Causal AI 系列读书会](https://www.sohu.com/a/415039730_741733)
  - 【2020-10-22】[如何在观测数据下进行因果效应评估](https://www.sohu.com/a/426630014_741733)：
    - 相关性相比因果，更缺乏 **可解释性**（Explainability）、**稳定性**（Stability）（漂移）
    - 可行动性（Actionability）：这些虚假相关是由混淆变量产生的混杂偏倚（Confounding Bias），这种决策问题实际上是反事实问题，而不是预测问题。
    - 公平性（Fairness）：通过因果评估的框架，可以用Do-演算（Do-Calculus）等工具，干预收入的多少，来计算肤色与犯罪率之间真正的因果效应大小。
    - 相关性有三种来源：**因果**、**混淆**和**样本选择**。
      - ① 因果关联例子就是天下雨地面会湿，这种关系是能够被人类所理解的、是可解释的、稳定的（无论在任何国家或城市，天下雨地都会湿）。
      - ② 混淆关联是由混淆偏差（Confounding Bias）造成的。比如图中X是T和Y的共同原因，但如果不对X进行观察，就会发现T和Y是具有相关性的，但T和Y之间是没有直接因果效应的，这就是产生了虚假相关。
      - ③ 样本选择偏差（Selection Bias）也会产生相关性，比如之前的例子中，如果数据集中的狗都出现在沙滩上，而没有狗的图片都是草地，那么训练处的模型就会发现草地与狗之间是负相关的，这也产生了虚假相关。
    - 虚假相关与因果关联相比，缺乏可解释性，且容易随着环境变化。在工业界和学术界中，我们都希望能判断两个变量之间的相关究竟是因果关联还是虚假相关。如果是虚假相关的话，可能会给实际的系统带来风险。
    - 所以恢复因果可以提高可解释性，帮助决策，并在未来的数据集中做出稳定而鲁棒的预测，防止算法产生的偏差。无论数据集中有什么样的偏差，我们都希望能挖掘出没有偏差的因果关系，来指导算法。
  - ![](https://swarma.org/wp-content/uploads/2020/05/wxsync-2020-05-381c31fa5614d7d4df7ae1b27e0d393c.png)

- 【2020-9-23】[Introduction to Causal Inference](https://www.bradyneal.com/causal-inference-course)
  - [A Brief Introduction to Causal Inference](https://www.bradyneal.com/slides/1%20-%20A%20Brief%20Introduction%20to%20Causal%20Inference.pdf)
  - [The Flow of Association and Causation in Graphs](https://www.bradyneal.com/slides/3%20-%20The%20Flow%20of%20Association%20and%20Causation%20in%20Graphs.pdf)
- 【2021-1-1】文库资料：
- [因果推理](https://wenku.baidu.com/view/60e4478ccd1755270722192e453610661ed95af5.html)
  - 因果推理的分类：
    - 由因推果：没有复习，所以考不好
    - 由果推因：心情不好，所以一定发生了不好的事情
    - 因果分析：一果多因、一因多果、同因异果、异因同果、互为因果
  - 因果分析的关键：
    - （1）分清主因和次因
    - （2）结果形成的因果链
    - （3）同因异果、异因同果、互为因果
      - 异因同果表面上互不干涉，但用联系的眼光看问题，深入分析下去，背后有共同之处，排除表象的迷惑，接近本质
      - 同因异果也是常见的相互关联，同样的原因在不同条件下可能产生不同的结果
  - 因果推理的误区
    - **因果倒置**谬误
    - **强加因果**谬误：仅仅把时间上有先后顺序或伴随发生的事看成有因果关系
    - **单一因果**谬误：用一个简单、单一的原因解释事件的发生，这个事件可能只是促进作用的原因之一，不是根本原因
    - **滑坡**谬误：使用连串的因果推论，却夸大了每个环节的因果强度，即不合理的使用连串的因果关系，将“可能性”转化为“必然性”，而得到不合理的结论，以实现某种意图
    - **臆测原因**谬误：针对某个现象（而不是调查分析）得出结论，根据主观臆断推断原因，造成归因偏差
    - **诉诸公众**谬误：以多数人相信的命题为事实依据来证明该命题一定是真的
  - 因果推理的运用
    - 补充中间环节：挖掘背后的因果链，找到关键因素
    - 积极归因：
    - 因果推理的目的：清楚某一现象背后的真正原因，包含主因、次因；如果是好现象，引导人们去做，如果是坏现象，告诫人们不该做
- [因果关系的推断](http://www.doc88.com/p-1052907204605.html) 研究疾病里的因果
  - 因果关联的几种方式：
    - （1）单因单果 x → y
    - （2）单因多果 x → y1,y2,y3
    - （3）多因单果 x1,x2,x3 → y
    - （4）多因多果 x1,x2,x3 → y1,y2,y3
    - （5）直接/间接病因 x1 → x2  。。。 → xn → y
  - 统计学关联的本质：原因、偏倚（系统误差）和机遇（随机误差）
  - 统计学关联中，排除虚假关联、间接关联后，是直接关联，再剔除偏倚才是可能的因果关联
  - 因果推断的标准
    - 关联的时间顺序：从因到果，是必要和前提条件
    - 关联的强度：与因果关联可能性成正比
    - 关联的特异性：因果一一对应关系
    - 关联的分布一致性
    - 关联的一致性：多个研究结果的一致性/可重复性增强了因果关联的可能性
- [观察性研究中的因果推断方法(三)30分钟.ppt](https://max.book118.com/html/2017/0930/135243899.shtm)， [百度文库](https://wenku.baidu.com/view/f945a4e8370cba1aa8114431b90d6c85ec3a8823.html)
- [因果作用评价与因果网络学习及其结合](https://mp.weixin.qq.com/s/eQbKE3hMVx6B-sQ3oF0F_w?notreplace=true)
  - 该报告介绍Pearl提出的因果推断的三个层级，综述因果推断的两个主要模型：潜在结果模型、因果网络。探讨因果作用和因果关系的可识别性，因果作用的可传递性，因果网络结构的学习算法，以及因果作用与因果网络结合的因果推断方法。
  - 【2021-1-6】May 10, 2017, MIT Machine learning expert Jonas Peters of the University of Copenhagen presents “Four Lectures on Causality”.
  - 从因果图模型开始，更广阔的定义了结构化的因果模型，以及如何从数据中识别因果关系。课程介绍了该领域当前（2017）比较前沿的研究，包括用传统机器学习方法进行因果推断的几篇论文。
  - MIT 因果推断 [Mini Lectures on Causality by Jonas Peters 2017](https://www.bilibili.com/video/av90067629/) (无字幕)
    - [ppt地址](https://stat.mit.edu/news/four-lectures-causality/)

  <iframe src="//player.bilibili.com/player.html?aid=90067629&bvid=BV1o7411L7dp&cid=153821743&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="350px" height="266px" > </iframe>

- 【2021-1-28】[将因果关系引入计算机视觉的"小学生"](https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&mid=2247575503&idx=1&sn=1a3a0c3f99f2bee229e983ca5e4564be&chksm=9095ae5ca7e2274a817ca681ea37267e33c139c54c406f73a5f964b3c11691edb48595a7077f&mpshare=1&scene=23&srcid=0128c6xVJSEVLXRvMK6obR48&sharer_sharetime=1611811625919&sharer_shareid=b8d409494a5439418f4a89712efcd92a%23rd)
  - AI 仍是一个比人类更低维的生物，与人类之间存在很大差距，对事物的因果推理能力便是其中之一
  - 张含望创立并带领的机器推理与学习实验室（Machine Reasoning and Learning Lab，简称“MReal”）是全球第一个将因果关系推理引入计算机视觉研究中的团队。

- 【因果推断】 [A Brief Introduction to Causal Inference by Brady Neal](https://www.bilibili.com/video/BV1CK4y1L7uA/?spm_id_from=333.788.videocard.5)
- 【2021-3-29】[统计之都-因果推断专题](https://cosx.org/tags/%E5%9B%A0%E6%9E%9C%E6%8E%A8%E6%96%AD/)
  - [因果推断简介之一：从 Yule-Simpson’s Paradox 讲起](https://cosx.org/2012/03/causality1-simpson-paradox/)
  - [因果推断简介之二：Rubin Causal Model (RCM) 和随机化试验](https://cosx.org/2012/03/causality2-rcm/)
  - [因果推断简介之三：R. A. Fisher 和 J. Neyman 的分歧](https://cosx.org/2012/03/causality3-fisher-and-neyman/)
  - [因果推断简介之五：因果图 (Causal Diagram)](https://cosx.org/2012/10/causality5-causal-diagram/)
  
- [Causal inference course written from a machine learning perspective](https://www.bradyneal.com/causal-inference-course)，包含课程ppt列表

<iframe src="//player.bilibili.com/player.html?aid=885688534&bvid=BV1CK4y1L7uA&cid=267895326&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="350px" height="266px" > </iframe>


# 因果推理书籍


## （1）The book of why
- 【2020-12-04】因果推理书籍索引，[Which causal inference book you should read](https://www.bradyneal.com/which-causal-inference-book)
- ![](https://www.bradyneal.com/img/books_flowchart.svg)
- 书籍：
  - ![](http://5b0988e595225.cdn.sohucs.com/images/20190716/935359c273384228b196eac31077b762.jpeg)
- 《The book of Why》，豆瓣高达9.5分。其中文版《为什么：关于因果关系的新科学》由中信出版社推出
- 因果推理和贝叶斯网络的创始人，图灵奖得主`Judea Peral`（朱迪亚·珀尔，贝叶斯网络之父）和科普作家 Mackenzie, Dana合作写的一本因果推理的入门书。
  - 朱迪亚•珀尓（Judea Pearl），加州大学洛杉矶分校计算机科学教授，“贝叶斯网络”之父。2011年，珀尔因“通过发展概率和因果推理对人工智能的奠基性贡献”获得了计算机科学的最高荣誉图灵奖；他的孩子，一名记者在巴以冲突的死亡，他为了纪念他的孩子还设立了一个基金。[初读Judea Pearl的书，有什么感觉？](https://www.zhihu.com/question/67715905)
  - ![](http://5b0988e595225.cdn.sohucs.com/images/20190716/7cee9f86eaea4b12af02c573bac064ed.jpeg)
- 目录
  - 导言：思维胜于数据
  - 第一章：**因果关系**之梯
  - 第二章：从海盗到豚鼠：因果推断的起源
  - 第三章：从证据到因：当贝叶斯牧师遇见福尔摩斯先生
  - 第四章：**混杂**和去混杂：或者，消灭潜伏变量
    - [因果学习初探（2）——混杂和去混杂](https://zhuanlan.zhihu.com/p/360525040)：随机试验是可以对付自然精灵的黄金法则。随机化带来的两个实际好处：
      - （1）消除了混杂偏移；
      - （2）能够量化不确定性（引出do算子）。
    - 随机试验可以切断混杂因子，即使是那些我们不知道的，而非随机的试验很难做到，或者说不能做到。很多时候，因为一些伦理性的问题等，干预在事实上是不可行的。幸运的是，do算子为我们提供了一种科学的方法，让我们能够在非试验性研究中确定因果关系。借助do算子定义混杂: ![](https://www.zhihu.com/equation?tex=P%28Y%7CX%29%5Cne+P%28Y%7Cdo%28X%29%29)
    - do算子和后门标准可以定义混杂、识别混杂，甚至是解决混杂因子带来的问题。除了三种结构外，我们引入另一条规则，控制一个变量的后代节点（替代物），如同部分的控制变量本身。为了去除X和Y之间的混杂，我们只需要阻断它们之间的非因果路径，而不去阻断或者干扰所有的因果路径就可以了。我们将后门路径定义为所有X和Y之间以指向X的箭头为开始的路径。我们要做的是对后门路径进行阻断，这些路径中有些需要进行约束，而有些不需要进行约束，来达到去混杂的目的。
  - 第五章：烟雾缭绕的争论：消除迷雾，澄清事实
  - 第六章：大量的**悖论**！
    - 谁能直面矛盾，谁就能触摸现实。**蒙提-霍尔**悖论，**伯克森**悖论，**辛普森**悖论
  - 第七章：超越调整：征服**干预**之峰
  - 第八章：**反事实**：挖掘关于假如的世界
  - 第九章：**中介**：寻找隐藏的作用机制
  - 第十章：大数据，人工智能和大问题
- 【2021-3-29】[《为什么：关于因果关系的新科学》思维导图](https://zhuanlan.zhihu.com/p/144562779)
- 1、 文章结构
  - 人类创造出了我们今天所享有的科技文明。所有这一切都源于我们的祖先提出了这样一个简单的问题：为什么？因果推断正是关于这个问题的严肃思考。因果革命背后有数学工具上的发展作为支撑，这种数学工具最恰当的名称应该是“因果关系演算法”。其一为因果图（causal diagrams），用以表达我们已知的事物，其二为类似代数的符号语言，用以表达我们想知道的事物。
![](https://pic4.zhimg.com/80/v2-8bb7cbdd487fbd5c93d7a3f184f2def7_1440w.jpg)
- 2、 **因果关系之梯**
  - 如果第一层级对应的是观察到的世界，第二层级对应的是一个可被观察的美好新世界，那么第三层级对应的就是一个无法被观察的世界（因为它与我们观察到的世界截然相反）。为了弥合第三层级与前两个层级之间的差距，我们需要掌握一种理解力，建立一种理论，据此我们就可以预测在尚未经历甚至未曾设想过的情况下会发生什么——这显然是所有科学分支的圣杯。
![](https://pic3.zhimg.com/80/v2-d198dbac52e3e19e756ba4b5944a64c6_1440w.jpg)
- 3、 **因果推断的起源**
  - 因果推断是用数学语言表达看似合理的因果知识，将其与经验数据相结合，回答具有实际价值的因果问题。将相关关系的知识与因果关系的知识相结合以获得某些结果的做法。而路径图在因果论和概率论之间建立的第一座桥梁，其跨越了因果关系之梯第二层级和第一层级之间的障碍。在建造了这座桥梁之后，就可以进行反向的实践，从根据数据测算出的相关性（第一层级）中发现隐藏在背后的因果量。
 
![](https://pic3.zhimg.com/80/v2-07a7bfe5722105fa283c20018babce6a_1440w.jpg)
- 4、 **混杂和对撞因子**
  - 我们在实际生活中似乎就是遵循着共因原则行事的，无论何时，只要观察到某种模式，我们就会去寻找一个因果解释。事实上，我们本能地渴望根据数据之外的某个稳定机制对观察结果做出解释。其中最令人满意的解释是直接因果关系：X导致Y。
 
![](https://pic4.zhimg.com/80/v2-f6d7aab9b26261f5c3b5f3f61e264337_1440w.jpg)
- 5、 **征服干预之峰**
  - 混杂因子是导致我们混淆“观察”与“干预”的主要障碍。在用“路径阻断”工具和后门标准消除这一障碍后，我们就能精确而系统地绘制出登上干预之峰的路线图。最安全的路线是后门调整和由此衍生的诸多同源路线，它们有些可以归于“前门调整”名下，有些则可以归于“工具变量”名下。一种通用的绘图工具，我们称之为“do演算”（do–calculus），它允许研究者探索并绘制出通往干预之峰的所有可能的路线，无论这些路线有多曲折。
 
![](https://pic4.zhimg.com/80/v2-76999a49fea61767d4e794e957a60dbf_1440w.jpg)
- 6、 **反事实**
  - “A导致B”解释为“假如没有A，则B就不会发生”。我们根本不需要争论这样的世界是否以物理或者形而上学的实体形式存在。如果我们的目的是解释人们所说的“A导致B”的含义，那么我们只需要假设人们有能力在头脑中想象出可能的世界，并能判断出哪个世界“更接近”我们的真实世界即可；最重要的是我们的想象和判断要前后一致，这有助于我们在群体中达成共识。
 
![](https://pic4.zhimg.com/80/v2-0edbbc63e8f6f20a1cb40e7059fa2ec7_1440w.jpg)


## （2）因果关系：模型、论证与推断

- 2011 年图灵奖得主 Judea Pearl 的 《[Causality : Models, Reasoning and Inference](http://bayes.cs.ucla.edu/BOOK-2K/)》（第二版）
- 作者：Judea Pearl
- 目录
  - 1 概率、图表和因果模型简介
  - 2 推论因果关系理论
  - 3 **因果图**和**因果效应**的识别
  - 4 行动、计划和直接影响
  - 5 社会科学和经济学中的因果关系和结构模型
  - 6 辛普森悖论、混乱与崩溃
  - 7 基于结构的**反事实**逻辑
  - 8 个不完善实验：边界效应与反事实
  - 9 因果关系的可能性：解释与识别
  - 10 实际原因
  - 11 与读者的思考、阐述和讨论

- Judea Pearl的《Causality》
  - ![](https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=2426721436,1889448037&fm=15&gp=0.jpg)
- 主要内容：
  - 第一章——前言：用通俗的语言介绍「什么是因果关系？」这一问题的讨论背景，并概括若干个传统的哲学观点，以及和下文的统计因果模型相比，这些传统定义存在的缺陷。
  - 第二章——事件性因果
    - 2.1. 随机对照试验
    - 2.2. **介入主义**的因果观
    - 2.3. **虚拟事实模型**（RCM）
    - 2.4. 贝叶斯网络
    - 2.5. **结构方程**（SEM）+ **结构因果模型**（SCM）
    - 2.6. SCM的**反事实**推理
  - 第三章——过程性因果：**因果环路图**（CLD）与微分方程
  - 第四章——后记
- 除前言外，本文其他部分默认读者已经理解基础概率论（概率、条件概率、贝叶斯定理、随机变量、期望值、相互独立事件）、基础图论（节点、边、有向无环图）、概率图模型初步（贝叶斯网络、d分隔）、统计学基础（随机对照试验）等知识。
- 【2021-3-29】源自书籍总结：[【综述长文】因果关系是什么？结构因果模型入门](https://zhuanlan.zhihu.com/p/33860572)，高二学生的杰作！



## 为什么要读

- 年度必读书，原因有二：
  - 提出了一套全新的科学方法论——因果关系模型，其应用范围涉及众多领域。借助因果关系的视角，作者重新阐述了人类认知和科学文明的发展史。
  - 因果推理将对人工智能产生革命性的跃迁，引领人工智能的未来发展，并赋予人工智能以真正的人类智慧甚至道德意识，让人工智能与人类能在彼此合作的基础上打造一个更好的未来世界。


## 当前的AI方法论错了！

- 自从AlphaGo一鸣惊人后，人工智能似乎一下子遍地开了花。智能音箱、智能导航、智能医疗——恍惚间，我们似乎已昂首阔步、意气风发走进了AI新时代。
- 然而有个人却说：
  - ![](http://5b0988e595225.cdn.sohucs.com/images/20190716/28bb22de858749fa92db4d67ed55bcaf.jpeg)
  - <font color='red'>你们的方向都错了，现在的人工智能连“智能”的门还没摸到。</font>
  - <font color='blue'>所有深度学习的成果，都只是曲线拟合。复杂而平庸。</font>
- 目前的大数据和人工智能都只是停留在相关性的层面，其算法的核心都是基于过往的数据，来预测/产生新的东西

- 尤瓦尔·赫拉利在《人类简史》中说，**想象**和**虚构**的能力，让智人走上了食物链的顶端。同样，机器要想真的“智能”，也必须能想象和虚构。
  - ![](http://5b0988e595225.cdn.sohucs.com/images/20190716/314be42d51e74f28bccf2c37c26316bb.jpeg)
  - 也就是朱迪亚·珀尔强调的，真正的人工智能，光知道“相关”远远不够，而要懂得“因果”。


# 机器学习理论的缺陷

- [图灵奖得主Judea Pearl：机器学习的理论局限性与因果推理的七大特性](https://cloud.tencent.com/developer/article/1119926)

- 【2018-5-10】近日，有越来越多的学者正在探讨机器学习（和深度学习）的局限性，并试图为人工智能的未来探路
  - [纽约大学教授 Gary Marcus 就对深度学习展开了系统性的批判](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650735630&idx=1&sn=5840c3e9bed487da3a9080d482fcc58e&chksm=871ac070b06d496638d47dbdaac75fdec06c5e81a3afaee1e1ce2ea37e86d92ba61de8b2b7c9&scene=21#wechat_redirect)
  - 图灵奖获得者，UCLA 教授 Judea Pearl 题为《[Theoretical Impediments to Machine Learning with Seven Sparks from the Causal Revolution](http://ftp.cs.ucla.edu/pub/stat_ser/r475.pdf)》的论文中，作者就已探讨了当前机器学习存在的理论局限性，并给出了面向解决这些问题，来自因果推理的七个启发。
  - 当前的机器学习几乎完全是统计学或**黑箱**的形式，从而为其性能带来了严重的理论局限性。这样的系统不能推断干预和反思，因此不能作为强人工智能的基础。为了达到人类级别的智能，学习机器需要现实模型（类似于因果推理的模型）的引导。为了展示此类模型的关键性，我将总结展示 7 种当前机器学习系统无法完成的任务，并使用因果推理的工具完成它们。

## 解决缺陷

- 【2021-3-30】[ICLR 2020 反事实因果理论如何帮助深度学习？](https://zhuanlan.zhihu.com/p/136937643)
- 一个巨大的问题是深度神经网络的**黑箱**问题和**不稳定性**问题。其中的一个根本原因，基于**相关性**的统计模型容易学习到数据中的“**伪关系**(spurious relation)”，而非因果关系，从而降低了泛化能力和对抗攻击的能力。
  - 一个潜在的方向，就是采用从90年代以来以Judea Pearl为代表的研究者们提出的**因果推断理论**来改进现有的表示学习技术。
  - 然而<font color='blue'>因果分析框架和表示学习并非天生相容</font>。
    - **因果分析**通常是基于抽象的、高层次的统计特征来构建结构**因果图**；
    - 而**表示学习**则基于海量数据提取具体的、低层次的表示特征来辅助下游任务。
  - 为了结合这两者，MILA的Yoshua Bengio提出了System 2框架，Max Planck Institute的Bernhard Schölkopf提出的因果表示学习框架。这两者实际上的思考是一致的。ICLR 2020上因果表示学习的2项有代表性的工作：如何利用因果理论中的**反事实**（counterfactual）框架来提高算法的**稳定性**和**可解释性**。
  - [Learning the Difference That Makes A Difference with Counterfactually-Augmented Data](https://www.aminer.cn/pub/5e5e18a393d709897ce222b4/learning-the-difference-that-makes-a-difference-with-counterfactually-augmented-data)
    - 深度学习容易学到语言数据集上**伪关系**（spurious relation）的问题一直没有得到解决。因果推断理论告诉我们，这是由于**混杂因子**（confounding）造成的。
    - 然而，将因果推断方法应用到自然语言处理面临着巨大的困难：什么是自然语言当中的随机变量？如何从表示中找出混杂因子？如何让学习结果更加稳定，避免受训练集中的伪关系影响？其中最大的困难，在于如何定义自然语言中的因果关系。
    - 作者设计了一种巧妙的方法，绕开了随机变量的定义问题，转而采用因果理论中的另一个重要概念——**反事实**——来进行**human in the loop**的数据增强以避免伪关系的干扰。
    - ![](https://pic2.zhimg.com/80/v2-4e65ed79cfe3785eb17a8a23c40bb711_1440w.jpg)
    - 在情感分析的一个3分类数据集上，利用Amazon’s Mechanical Turk众包平台，要求人类对句子做轻微的修改。这些修改包括：
      * 将**事实变为希望**：比如加入supposed to be表示虚拟语气
      * **反讽**语气：如加入引号修饰、改为反问句表示反讽
      * 插入/替换**修饰词**：将interesting替换为boring
      * 插入**短语**，修改**评分**等
    - 使评论的情感分类发生变化（如从正面变为负面）来进行数据增强。实验证明，对于支持向量机，朴素贝叶斯，随机森林，Bi-LSTM和BERT：
      - a) 在原有数据集上训练后，相比原测试集，**反事实**数据集上的测试结果要差许多。反之亦然。
      - b) 在结合了反事实增强过的训练集上训练，模型性能相比原来有着巨大的提升。
      - c) BERT不但在通常情况下表现最好，而且在反事实干扰的数据集上表现也降低得最少
        - [台湾国立成功大学一篇论文把 BERT 拉下神坛！NLP 神话缺了数据集还不如随机](https://zhuanlan.zhihu.com/p/74652696)，曾经狂扫 11 项记录的谷歌 NLP 模型BERT在一些基准测试中的成功仅仅是因为利用了数据集中的**虚假统计线索**(Spurious Statistical Cues)，如若不然，还没有随机的结果好。
        - 鉴于 R∧A→¬C，通过否定 claim 并反转每个数据点的标签来产生对抗性示例，将对抗性示例与原始数据进行组合，构建对抗测试集
          - ![](https://pic2.zhimg.com/80/v2-75a3014d062de4707616e048a820568d_1440w.jpg)
        - 实验表明：BERT准确率就从77%降到53%，几乎等同于随机猜。BERT 并不能做出正确 “理解”，只能利用**虚假统计线索**(Spurious Statistical Cues)
  - [Counterfactuals Uncover the Modular Structure of Deep Generative Models](https://www.aminer.cn/pub/5c2c7a9217c44a4e7cf314de/counterfactuals-uncover-the-modular-structure-of-deep-generative-models)
    - 有监督的视觉模型很容易会被伪关系干扰从而学出带有偏见的结果。比如，一个典型的例子是有监督CNN模型在识别狼和狗的图片时，实际上使用的统计特征是狼一般在雪中而狗在草地上。也就是说，模型认为“背景（草或雪）”与“目标（狗和狼）”之间存在某种关系。而实际上，这两种特征是解耦合的。我们希望能找到某些能学会解耦合的特征表示的模型。
    - 检验模型能否推理反事实情况（比如狗在雪中，狼崽草上）。这样的反事实推理能力也是人类智能的一个重要标志，即推理未发生事件的结果的能力，属于因果学习的一个重要分支。反事实理论在计量经济学和公共卫生领域得到了广泛的应用，然而对于机器学习，这套理论的应用方法仍然是一片空白。将因果学习应用在表示学习上的一个重要改进的方向，就是来自Max Planck Institute的Scho ̈lkopf和MILA的Bengio目前倡议的causal representation learning. 本文即是Scho ̈lkopf在ICLR2020上的一篇尝试性的工作：通过验证模型推断反事实的能力，来验证生成式模型（BigGAN）可以学习到解耦合的模块化结构。提出了**因果生成模型**（Causal Generative Model）的分析框架来解耦合生成式模型的模块化结构



## 因果推理模型的 7 种特性

- 【2021-1-9】和家人一起去一个未知的目的地度假。假期前后，你都在纠结一些与事实相悖的问题:
  - 假期里我们应该做什么？
  - 我们会开心吗？
  - 我们为什么会觉得开心？
  - 之后我们会有什么感觉？

![](http://imgcdn.atyun.com/2019/06/2-8.png)


- 考虑以下 5 个问题：
  - 给定的疗法在治疗某种疾病上的有效性？
  - 是新的税收优惠导致了销量上升吗？
  - 每年的医疗费用上升是由于肥胖症人数的增多吗？
  - 招聘记录可以证明雇主的性别歧视罪吗？
  - 我应该放弃我的工作吗？
- 这些问题的一般特征是它们关心的都是原因和效应的关系，可以通过诸如「治疗」、「导致」、「由于」、「证明」和「我应该」等词识别出这类关系。这些词在日常语言中很常见，并且我们的社会一直都需要这些问题的答案。然而，直到最近也没有足够好的科学方法对这些问题进行表达，更不用说回答这些问题了。和几何学、机械学、光学或概率论的规律不同，原因和效应的规律曾被认为不适合应用数学方法进行分析。
- 这种误解有多严重呢？实际上仅几十年前科学家还不能为明显的事实「mud does not cause rain」写下一个数学方程。即使是今天，也只有顶尖的科学社区能写出这样的方程并形式地区分「mud causes rain」和「rain causes mud」。
- 过去三十年事情已发生巨大变化。一种强大而透明的数学语言已被开发用于处理因果关系，伴随着一套把因果分析转化为数学博弈的工具。这些工具允许我们表达因果问题，用图和代数形式正式编纂我们现有的知识，然后利用我们的数据来估计答案。进而，这警告我们当现有知识或可获得的数据不足以回答我们的问题时，暗示额外的知识或数据源以使问题变的可回答。
- 我把这种转化称为「**因果革命**」（Pearl and Mackenzie, 2018, forthcoming），而导致因果革命的数理框架我称之为「结构性因果模型」（SCM）。
- SCM 由三部分构成：
  - 图模型
  - 结构化方程
  - 反事实和介入式逻辑
- 图模型作为表征知识的语言，反事实逻辑帮助表达问题，结构化方程以清晰的语义将前两者关联起来。

接下来介绍 SCM 框架的 7 项最重要的特性，并讨论每项特性对自动化推理做出的独特贡献。
1. **编码因果假设**—透明性和可试性
  - 图模型可以用紧凑的格式编码因果假设，同时保留透明性和可试性。其透明性使我们可以了解编码的假设是否可信（科学意义上），以及是否有必要添加其它假设。可试性使我们（作为人类或机器）决定编码的假设是否与可用的数据相容，如果不相容，分辨出需要修改的假设。利用 d-分离（d-separate）的图形标准有助于以上过程的执行，d-分离构成了原因和概率之间的关联。通过 d-分离可以知道，对模型中任意给定的路径模式，哪些依赖关系的模式才是数据中应该存在的（Pearl，1988）。
2. **do-calculus** 和混杂控制
  - 混杂是从数据中提取因果推理的主要障碍，通过利用一种称为「back-door」的图形标准可以完全地「解混杂」。特别地，为混杂控制选择一个合适的协变量集合的任务已被简化为一种简单的「roadblocks」问题，并可用简单的算法求解。（Pearl，1993）
  - 为了应对「back-door」标准不适用的情况，人们开发了一种符号引擎，称为 do-calculus，只要条件适宜，它可以预测策略干预的效应。每当预测不能由具体的假设确定的时候，会以失败退出（Pearl, 1995; Tian and Pearl, 2002; Shpitser and Pearl, 2008）。
3. **反事实**算法
  - 反事实分析处理的是特定个体的行为，以确定清晰的特征集合。例如，假定 Joe 的薪水为 Y=y，他上过 X=x 年的大学，那么 Joe 接受多一年教育的话，他的薪水将会是多少？
  - 在图形表示中使用反事实推理是将因果推理应用于编码科学知识的非常有代表性的研究。每一个结构化方程都决定了每一个反事实语句的真值。因此，我们可以解析地确定关于语句真实性的概率是不是可以从实验或观察研究（或实验加观察）中进行估计（Balke and Pearl, 1994; Pearl, 2000, Chapter 7）。
  - 人们在因果论述中特别感兴趣的是关注「效应的原因」的反事实问题（和「原因的效应」相对）。（Pearl，2015）
4. 调解分析和直接、间接效应的评估
  - 调解分析关心的是将变化从原因传递到效应的机制。对中间机制的检测是生成解释的基础，且必须应用反事实逻辑帮助进行检测。反事实的图形表征使我们能定义直接和间接效应，并确定这些效应可从数据或实验中评估的条件（Robins and Greenland, 1992; Pearl, 2001; VanderWeele, 2015）
5. 外部效度和样本选择偏差
  - 每项实验研究的有效性都需要考虑实验和现实设置的差异。不能期待在某个环境中训练的模型可以在环境改变的时候保持高性能，除非变化是局域的、可识别的。上面讨论的 do-calculus 提供了完整的方法论用于克服这种偏差来源。它可以用于重新调整学习策略、规避环境变化，以及控制由非代表性样本带来的偏差（Bareinboim and Pearl, 2016）。
6. 数据丢失
  - 数据丢失的问题困扰着实验科学的所有领域。回答者不会在调查问卷上填写所有的条目，传感器无法捕捉环境中的所有变化，以及病人经常不知为何从临床研究中突然退出。对于这个问题，大量的文献致力于统计分析的黑箱模型范式。使用缺失过程的因果模型，我们可以形式化从不完整数据中恢复因果和概率的关系的条件，并且只要条件被满足，就可以生成对所需关系的一致性估计（Mohan and Pearl, 2017）。
7. 挖掘因果关系
  - 上述的 d-分离标准使我们能检测和列举给定因果模型的可测试推断。这为利用不精确的假设、和数据相容的模型集合进行推理提供了可能，并可以对模型集合进行紧凑的表征。人们已在特定的情景中做过系统化的研究，可以显著地精简紧凑模型的集合，从而可以直接从该集合中评估因果问询。

- NIPS 2017 研讨会 Q&A
  - 我在一个关于机器学习与因果性的研讨会（长滩 NIPS 2017 会议之后）上发表了讲话。随后我就现场若干个问题作了回应。我希望从中你可以发现与博客主题相关的问题和回答。
- 一些人也想拷贝我的 PPT，下面的链接即是，并附上[论文](http://ftp.cs.ucla.edu/pub/stat_ser/r475.pdf)：
  - NIPS 17 – What If? Workshop Slides [PDF](http://causality.cs.ucla.edu/blog/wp-content/uploads/2017/12/nips-dec2017-bw.pdf)


- 问题 1：「因果革命」是什么意思？
  - 回答：「革命」是诗意用法，以总结 Gary King 的奇迹般的发现：「在过去几十年里，对于因果推断的了解比以前所有历史记载的总和还要多」（参见 Morgan 和 Winship 合著的书的封面，2015）。三十年之前，我们还无法为「Mud does not cause Rain」编写一个公式；现在，我们可以公式化和评估每一个因果或反事实陈述。
- 问题 2：由图模型产生的评估与由潜在结果的方法产生的评估相同吗？
  - 回答：是的，假设两种方法开始于相同的假设。图方法（graphical approach）中的假设在图中被展示，而潜在结果方法（potential outcome approach）中的假设则通过使用反事实词汇被审查者单独表达。
- 问题 3：把潜在的结果归因于表格个体单元的方法似乎完全不同于图方法中所使用的方法。它们的区别是什么？
  - 回答：只在有可条件忽略的特定假设成立的情况下，归因才有效。表格本身并未向我们展示假设是什么，其意义是什么？为了搞明白其意义，我们需要一个图，因为没有人可在头脑中处理这些假设。流程上的明显差异反映了对假设可见的坚持（在图框架中），而不是使其隐藏。
- 问题 4：有人说经济学家并不使用图，因为其问题不同，并且也没能力建模整个经济。你同意这种解释吗？
  - 回答：不同意！从数学上讲，经济问题与流行病学家（或其他科学家）面临的问题并无不同，对于后者来讲，图模型已经成为了第二语言。此外，流行病学家从未抱怨图迫使其建模整个人体解剖结构。（一些）经济学家中的图规避（graph-avoidance）是一种文化现象，让人联想到 17 世纪意大利教会天文学家避开望远镜。底线：流行病学家可以判断他们的假设的合理性——规避掉图的经济学家做不到（我提供给他们很多公开证明的机会，并且我不责怪他们保持沉默；没有外援，这个问题无法被处理）。
- 问题 5：深度学习不仅仅是盛赞曲线拟合？毕竟，曲线拟合的目标是最大化拟合，同时深度学习中很多努力也在最小化过拟合。
  - 回答：在你的学习策略中不管你使用何种技巧来最小化过拟合或其他问题，你依然在优化已观察数据的一些属性，同时不涉及数据之外的世界。这使你立即回到因果关系阶梯的第一阶段，其中包含了第一阶段要求的所有限制。


# 引言

- 2020年6月21日，图灵奖得主、贝叶斯网络之父 Judea Pearl 在第二届[北京智源大会](https://2020.baai.ac.cn/)上做了《新因果科学与数据科学、人工智能的思考》的报告。
- ![](http://p6-tt.byteimg.com/large/pgc-image/S2ZVTI7E7MNFQ7)
- Pearl说：
  - 我们现在正处在第二次数学科学革命，这一革命是以科学为中心的因果革命，相对于第一次以数据为中心的革命，第二次显得有些沉默，但威力同样巨大。
- Pearl解释了因果科学为什么需要新的逻辑和新的推理机制，以及因果科学中新引擎的结构是什么。也对称之为“double-helix”两个因果推理的基本定理进行了交代；最后也给大家讲了基于因果智能的七种工具，以及这七种工具是如何给科学带来革命性变化。

# 什么是因果科学

- ![](http://p1-tt.byteimg.com/large/pgc-image/S2ZVTIc6kEyATB)

- **因果科学**就是回答因果问题的逻辑和工具，如上图一些因果问题的典型例子：
  - 1、某项治疗对预防疾病的效果如何；
  - 2、新的税收优惠政策和营销活动哪个是导致销售额上升的原因；
  - 3、肥胖症每年造成的保健费用是多少；
  - 4、雇用记录能否证明雇主有性别歧视行为；
  - 5、我如果辞职了，会不会后悔？
- 上面这五个问题，显然无法用现在标准的科学语言（如数学公式）进行回答。为什么呢？因为这些问题都包含着不对称信息。毕竟“代数学科”从伽利略时代开始，就是专注于等式（完全对称的因果关系），即y=ax此类的表达式。
- 而现实中，大多数问题，如上标黄的单词，预防、导致、归因、歧视、后悔等等都是含有不对称属性的。相对于“等号=”表示对称信息，那么我们也可用箭头→表示非对称信息。在过去30年中，我和我的同事做了非常多的工作，就是为了找到非对称的表达工具，在后面我也会介绍一些工具。

- **因果推断**
  - 因果推断区分了人们可能想要估计的两种条件分布。机器学习中，通常只会估计一种分布，但在某些情况下，可能也需要估计第二种。
  - 因果推断用的最多的模型是 Rubin Causal Model (RCM; Rubin 1978) 和 Causal Diagram (Pearl 1995)。Pearl (2000) 中介绍了这两个模型的等价性，但是就应用来看，RCM 更加精确，而 Causal Diagram 更加直观，后者深受计算机专家们的推崇。
- 观察给定一个x后，变量y会发生什么变化。这就引申出两种表述： 
  - （1）**观察**p(y\|x)：如果观察变量X取值于x，Y的相应分布是什么？这是我们常在监督学习中遇到问题，它是一个条件分布，可以从p(x,y,z,…)中计算出它的两个边缘概率：p(y\|x) = p(x,y)/p(x)。相信所有人都不会对这个公式感到陌生，也都会计算。 
  - （2）**介入**p(y\|do(x))：如果设X的值为x，那Y的相应分布是什么？这其实就是通过人为把X的值设为x来干预数据生成过程，但其余变量还是用原先的生成方式，以此观察Y的变化（请注意，数据生成过程与联合分布p(x,y,z,…)不同）。
- p(y\|x)和p(y\|do(x))不一样，p(y\|do(x))实际上和x无关
- p(y\|do(x))实际上就是一个普通的条件分布，但它不是基于 p(x,z,y,…)的，而是pdo(X=x)(x,z,y,…)。这里的pdo(X=x)是如果实际进行干预的话会观察到的数据的联合分布。所以p(y\|do(x))是从随机对照试验或A/B测试收集到的数据中学习的条件分布，其中x由实验者控制。
- 即便不能从随机实验中直接估计p(y\|do(x))，这个分布也是实际存在的。所以因果推断和do-calculus的主要观点是：
  - 如果我不能在随机对照实验中直接测量p(y\|do(x))，那我是否可以根据我在受控实验之外观察到的数据来估计它？
  - ![](https://www.inference.vc/content/images/2018/05/Causality_-building-a-bridge--1-.png)
  - ![](https://www.inference.vc/content/images/2018/05/Causality_-do-calculus-estimand--1-.png)
- 参考作者：[骑驴看热闹](https://www.zhihu.com/question/283897078/answer/756671333)，英文原文：[ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus](https://www.inference.vc/untitled/)

## 推理引擎的结构

- 因果关系的学习者必须熟练掌握至少三种不同层级的认知能力：
  - `观察`能力（Seeing）、`行动`能力（Doing）和`想象`能力（Imagining）。”
  - 第一层级“`关联`”表示`观察`能力，指发现环境中规律的能力
    - 一只猫头鹰观察到一只老鼠在活动，便开始推测老鼠下一刻可能出现的位置，这只猫头鹰所做的就是通过观察寻找规律；
  - 第二层级“`干预`”表示`行动`能力，指预测对环境刻意改变后的结果，并根据预测结果选择行为方案
    - 如果我做X这件事情，那么y会发生什么变化，一个具体的例子是如果我把香烟戒掉，那么得癌症的状况会发生什么变化；
  - 第三层级“`反事实`”表示`想象`能力，指想象并不存在的世界，并推测观察到的现象原因为何
    - 为什么是x导致了y，如果当时x没有发生，那么状况会是怎么样的，如果当时采取了其他措施，会发生什么？具体的例子是：我吃了阿司匹林能治好了我的头痛吗？假如奥斯沃德没有刺杀肯尼迪，肯尼迪会活着吗？假如在过去的两年里我没有吸烟会怎样？

  ![](http://p1-tt.byteimg.com/large/pgc-image/S2ZVU0v7v01jZj)

|层级|能力提现|数学表达|说明|
|---|---|---|---|
|**反事实**|想象|P(y_x\|x', y')|因果推断的最高层|
|**干预**|行动|P(y\|do(x), z)|执行某动作会带来的结果|
|**关联**|观察|P(y\|x)|发现规律→机器学习|



`Judea Pearl` 曾在他的书里《`为什么`》中提到：
- 第一层级“关联”和第二层级“干预”主要针对当前的弱人工智能，包括对现有贝叶斯网络在深度学习领域的拓展、前门标准实践、do-calculus 等核心算法；
- 而第三层级“反事实”是基于基于人的想象力和假设，是人类独有的思考能力，也是令人工智能达到人类智能的关键命门。

![](http://p3-tt.byteimg.com/large/pgc-image/S2ZVU1rE6ABLQW)

- 【2020-9-5】攀上因果关系的阶梯
  - 珀尔描述了从仅仅观察相关性到检验因果性的转变，即从因果关系阶梯的第一级上升到第二级。
  - 摘自：[因果之箭指向何方？| 图灵奖得主珀尔的《为什么》](https://www.toutiao.com/i6755077246928552452)
![](https://p1-tt.byteimg.com/origin/pgc-image/e9f24e01f21f4b2b92c5fd877c9c20e2?from=pc)

- 当前的机器学习无力回答反事实的问题，大多数机器学习模型甚至使用了不可能回答这一问题的表示。
![](https://pic1.zhimg.com/80/v2-4722c095e0b8393476843c8be7704808_1440w.jpg)

![](http://p1-tt.byteimg.com/large/pgc-image/S2ZVU3k8s8s47y)

- Pearl的因果推断理论共有7大支柱：
  - 有意义而紧凑的**因果假设**表示（graphical表示）
  - **混杂因子**控制（back-door、front-door、do-calculus）
  - **反事实**算法（本文重点介绍的内容）
  - 媒介分析（反事实的graphical表示）
  - 学习迁移、外部验证、取样偏差（do-calculus、selection diagrams）
  - 数据缺失（graphical标准）
  - 因果发现（寻找和数据兼容的模型，并紧凑地表示它们）

- Pearl同时开发了**结构化因果模型**（Structural Causal Model, SCM），一个形式化地描述因果推断的框架
![](https://pic2.zhimg.com/80/v2-cde33f828397d5ad19fd5a375c72e0c5_720w.jpg)
- 摘自：[“无人问津”的贝叶斯网络之父Judea Pearl在NIPS 2017上到底报告了啥](https://zhuanlan.zhihu.com/p/31930409)


## 因果前言

因果关系在生活中无处不在。经济、法律、医学、物理、统计、哲学、宗教等众多学科，都与因果的分析密不可分。然而，和其他概念，例如统计的相关性相比，因果（causality）非常难以定义。利用直觉，我们可以轻易判断日常生活中的因果关系；但是，用清晰、没有歧义的语言准确回答「因果关系是什么？」这个问题，往往超出了常人的能力范围。
 
（感兴趣的读者，不妨暂停阅读，然后试着给出一个「因果关系」的定义。）
 
不得不承认，回答这个问题是如此困难，以至于部分哲学家认为，因果关系是不可还原的、最基础的认知公理，无法被用其他方式描述。不过，本文即将描述的众多统计因果模型，将会是针对这一观点的有力反驳。
 
在知乎上，也有一些对于因果关系的探讨，例如哲学话题下的「[因果关系是真实存在，还是我们认识世界的一种方法？](https://www.zhihu.com/question/20318246)」令人遗憾的是，这个问题下的大多数答案，都把重心放在了认知论上，即「如何回应休谟的归纳问题？」以及「我们怎么知道，我们认知的因果关系是可靠的？」大家似乎都默认，「什么是因果关系」是一个琐碎得不需要讨论的前提（但显然并非如此），陷入怀疑论和先验论，从而无法给出一个实用的因果模型。事实上，因果关系是一个本体论的话题：我们需要找到一个符合直觉、足够广泛，但也足够具体的定义来描述因果关系；在此基础之上，我们还需要一套可靠的判定因果的方法。
 
常用的统计因果模型都采用了介入主义（interventionism）的诠释：因果关系的定义依赖于「介入」的概念；外在的介入是因，产生现象的变化是果。
 
在此之前，我们先了解一下其他传统的对于「因果关系」的定义，以及为什么它们不符合直觉。
 
![](https://pic3.zhimg.com/80/v2-7c8f73a1d0f267a00f2b4b1c40c45156_1440w.jpg)
 
大卫·休谟（David Hume）
 
- 休谟：因果就是「经常性联结」（constant conjunction）。如果我们观察到，A总是在B之前发生，事件A与事件B始终联结在一起，那么A就导致了B，或者说A是B的原因。
- 反驳：令A表示公鸡打鸣，令B表示日出。自然条件下，日出之前总有公鸡打鸣，但不会有人认为公鸡打鸣导致了日出。假如我们进行介入，监禁了所有的公鸡，使它们无法打鸣，太阳仍然会照常升起。
 
在这里，有必要注意一个细节：
- 大卫·休谟（David Hume，1711年－1776年）。
- 卡尔·皮尔逊（Karl Pearson，1857年－1936年）。
提出「统计相关性」概念的皮尔逊，比休谟晚出生了一百多年。
 
我们现在的思维方式，并非是自古以来就存在的：我们眼里理所应当的常识，在古人脑中可能从未出现。
 
在统计学成为一门严谨的学科、皮尔逊清晰地分离相关性和因果性之前，大多数人都把相关性和因果性混为一谈。即便到了现在，认为相关就代表因果的人也不在少数。
 
我们没有必要因为休谟的历史地位，就把他下的定义奉为金科玉律。所以，休谟用的经常性联结只能定义相关性，不能定义因果性。
 
![](https://pic4.zhimg.com/80/v2-527cbeca6d5ab2127118ace7d469b087_1440w.jpg)
 
相关性未必意味着因果性
1.  相关性不代表因果性。
2.  相关性是对称的，而因果性是不对称的。如果A是B的原因，那么B是A的结果，但我们绝不会同时说「事件A是事件B的原因，事件A也是事件B的结果」。至于相关性，随机变量X与Y之间的相关性定义为 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm+%7Bcorr%7D+%28X%2CY%29%3D%7B%5Cmathrm+%7Bcov%7D+%28X%2CY%29+%5Cover+%5Csigma+_%7BX%7D%5Csigma+_%7BY%7D%7D%3D%7BE%5B%28X-%5Cmu+_%7BX%7D%29%28Y-%5Cmu+_%7BY%7D%29%5D+%5Cover+%5Csigma+_%7BX%7D%5Csigma+_%7BY%7D%7D) ，所以必然有 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm+%7Bcorr%7D+%28X%2CY%29+%3D+%5Cmathrm+%7Bcorr%7D+%28Y%2CX%29) 。
 
因果关系的不对称性，曾被用于反驳亨佩尔用DN模型定义「科学解释」的做法，但这是属于科学哲学的题外话了。
以上两条直觉，可以反驳以下一系列不使用「介入」概念的因果定义。
*   充分因： ![[公式]](https://www.zhihu.com/equation?tex=A+%5Crightarrow+B)
*   必然因： ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cleftarrow+B)
*   朴素的反事实因果： ![[公式]](https://www.zhihu.com/equation?tex=%28A%E2%86%92B%29%E2%88%A7%28%C2%ACA%E2%86%92%C2%ACB%29)
*   加入概率论，用相关性定义因果性。

一个典型的反例：用事件A表示「冰激凌销量增加」，用B表示「溺水死亡者数量增加」。A与B之间成正相关，但我们都知道，A与B之间不存在因果关系，它们都是由一个共同的因素「夏天」导致的。由此可见，仅仅使用概率统计的工具，并不足以让我们在现实中做出理性的因果推断。
 
*   INUS条件：原因是Insufficient but Necessary parts of a condition which is itself Unnecessary but Sufficient。
    
 
是INUS条件，但不是原因的例子，并不难构造：闪电、干草堆、消防员玩忽职守、空气干燥都是一场火灾的INUS条件。但是，我们知道闪电和雷声永远符合「如果有闪电，那么必然有雷声」；因此，雷声也是火灾的INUS条件，却不是火灾的原因。
 
上述一系列模型/定义，都有一个共同的缺陷：给定一个因果关系，这些模型可以完美套用；然而，给定一个此类模型，我们却无法直接确定不同变量之间的因果关系，因为这样的单个模型可以同时描述多种不同的因果、甚至非因果的关系。
 
哲学家们看似没有对因果关系提出令人满意的诠释。但是，这至多只是一种流行于哲学爱好者之间的误解。普通哲学爱好者们在因果关系方面的了解，通常不会超过休谟与康德，能知道刘易斯、必然论、多元主义之类都极为难得。实际上，在统计、经济等领域，已经有大量成熟且投入使用的因果模型，它们准确反映了我们对因果的直觉认识，而且能被精确的数学语言描述。

 
## 事件性因果
 
当我们说「A是因，B是对应的果」的时候，A和B可以是什么「东西」？
 
一般而言，我们认为A和B是某种事件，而且A必须发生在B之前。因为「因」必须发生在「果」之前，所以如果A导致了B，那么不可能同时有B导致了A——两个事件无法互为因果。由此可见，因果关系存在一种不对称性。
 
针对「在时间上，因必须先于果」这一条件，哲学家们有过大量的讨论（[Backward Causation](https://link.zhihu.com/?target=https%3A//plato.stanford.edu/entries/causation-backwards/)），其中不少还涉及尖端的量子力学。不过，我们仍然没有理由放弃这一条件。因为，不同的模型有不同的适用范围，而因果模型的适用范围主要是宏观现象、经济、医疗、复杂动力/电路系统，不论微观物理的结论如何，它在已知领域的有效性都不受影响。
 
有人或许会质疑，为什么两个东西不能互为因果呢？例如，让A1表示草原上羊的数量，让B1表示草原上狼的数量；其他条件不变，狼的增加会导致羊的减少，羊的减少会导致狼的减少，狼的减少会反而导致羊的增加，羊的增加进而导致狼的增加；A1和B1互为因果。
 
值得注意，A1与B1表示了某种过程，而不是某些固定时间点上的事件，所以A1与B1之间完整的因果关系无法用事件性因果表示。所以，对于这种质疑，我有以下几条回应：
1.  我们可以按照时间顺序，把每个时间点上的A和B拆分为单独的事件，即B1（狼增加）→A1（羊减少）→B2（狼减少）→A2（羊增加）。如此一来，事件性因果也能表达A与B之间的关系。
2.  针对过程性的因果，我们有另一种模型——因果环路图（CLD），将在本文第三章介绍。
3.  过程性因果比事件性因果复杂。在理解过程性因果模型之前，我们需要先理解更简单的事件性因果模型。
    

对于事件性因果，当前最成熟、最广泛的模型是结构因果模型（Structural Causal Model，以下简称SCM）。SCM结合了结构方程（SEM）、虚拟事实模型（RCM）、概率图模型（主要是贝叶斯网络），并将其应用于因果分析。各类常用因果模型，都可以看作SCM的子类。接下来，我将以RCM、贝叶斯网络、SEM的顺序，按照SCM的发展思路，对其进行详细的介绍。
 
2.1. 随机对照试验
 
任何一本初级统计学课本都会提到，基于观测的统计模型无法可靠地识别因果关系。要确定因果关系，必须通过随机对照试验（Randomized Controlled Trial）。
 
在一个简单随机对照试验中，试验对象（通常是参加研究的志愿者，下文每一个对象用u表示）会被随机分入两组：实验组（treatment group，下文用t表示）和对照组（control group，下文用c表示）。
 
我们有多种不同的随机分组方式，例如简单随机分组、随机区组设计、配对设计。使用随机区组设计时，研究者会先根据个体的特征（年龄、性别等）将其分入不同的区组，再在每个区组内实施简单随机分组。使用配对设计时，研究者会把在各方面都非常相似的个体（例如双胞胎、不同时间节点的同一个人）配成对，在每一对个体中随机选一个作为实验组，另一个作为对照组。
 
实验组的对象会接受干预，但对照组的对象不会受到任何干预/介入。在医学实验中，实验组的对象会接受真正的治疗，而对照组的对象只会收到安慰剂。实验结束后，研究者会比较实验组和对照组的结果。
 
如果我们用Y表示我们感兴趣的结果变量，那么我们可以用以下符号表示随机对照试验的结果：
*   ![[公式]](https://www.zhihu.com/equation?tex=Y_c%28u%29) 是在对照组条件下，对象u展现出的结果变量Y。
*   ![[公式]](https://www.zhihu.com/equation?tex=Y_t%28u%29) 是在实验组条件下，对象u展现出的结果变量Y。
 
在研究中，我们通常会探究 ![[公式]](https://www.zhihu.com/equation?tex=Y_t%28u%29) 是否统计显著地不同于 ![[公式]](https://www.zhihu.com/equation?tex=Y_c%28u%29) 。这一过程涉及较为具体的统计假设检验，与本文的主要内容无关。但是，我们至少可以意识到，t与c的区别是因果关系中的「因」， ![[公式]](https://www.zhihu.com/equation?tex=Y_t%28u%29) 与 ![[公式]](https://www.zhihu.com/equation?tex=Y_c%28u%29) 的区别是因果关系中的「果」。
 
2.2. 介入主义的因果观
 
在随机对照实验的基础框架上，我们可以建立起一个介入主义（interventionism）因果观。
 
一个介入主义的因果模型包括三部分：
1.  所有的系统 ![[公式]](https://www.zhihu.com/equation?tex=U) ：一个包含所有系统 ![[公式]](https://www.zhihu.com/equation?tex=u) 的集合。一个系统 ![[公式]](https://www.zhihu.com/equation?tex=u) 我们讨论的对象，可以是人体、机械、星球、化学反应系统、经济实体等。
2.  所有的介入方式 ![[公式]](https://www.zhihu.com/equation?tex=T) ：一个包含所有可能的介入方式 ![[公式]](https://www.zhihu.com/equation?tex=t) 的集合。例如，假设我们讨论的系统 ![[公式]](https://www.zhihu.com/equation?tex=U) 是一个有两个按钮的黑箱，一个按钮是红色的，另一个按钮是绿色的，那么所有可能的介入方式为 {按红按钮，按绿按钮，两个按钮都按，两个按钮都不按} 。（在这个具体的例子里，根据黑箱的结构不同，可能的介入方式或许不止四种，所以这只是一个经过简化，以便直观理解的模型。）
3.  状态函数 ![[公式]](https://www.zhihu.com/equation?tex=Y) ：输入一个系统 ![[公式]](https://www.zhihu.com/equation?tex=u) 和一种介入方式 ![[公式]](https://www.zhihu.com/equation?tex=t) ，输出系统的某个状态 ![[公式]](https://www.zhihu.com/equation?tex=y) ，写作 ![[公式]](https://www.zhihu.com/equation?tex=y%3DY_t%28u%29) 。例如，在一个医疗实验中， ![[公式]](https://www.zhihu.com/equation?tex=Y) 可以反映「u（病人甲）在受到干预t（服用降压药）之后的y（血压）」。注意，y不一定要完整描述u的状态的所有部分，只反映几个变量也是可以的。我们当然可以让y表示某个病人全身所有分子的运动状态，但这类过于复杂的状态函数，往往没有太大的实用价值。可是，在简单电路这样的系统中，完整表达电路每个节点的状态不仅可行，而且有利。因此，在建立因果模型时，我们需要具体问题具体分析，选择一个合适的状态函数。

值得注意的是，因为「果」的定义涉及到 ![[公式]](https://www.zhihu.com/equation?tex=Y_t%28u%29) 与 ![[公式]](https://www.zhihu.com/equation?tex=Y_c%28u%29) 的区别，而单次介入只说明了t却没有说明c，所以 ![[公式]](https://www.zhihu.com/equation?tex=T) 必须包含一种表示「不介入」的介入方式 ![[公式]](https://www.zhihu.com/equation?tex=c) 。也就是说，在一个因果模型中，任何一个系统都必须有一种不受干预的「自然状态」。如果现实情况过于复杂，很难找到不受干预的自然状态，我们可以把某种介入方式 ![[公式]](https://www.zhihu.com/equation?tex=c) 默认为「不介入」。
 
因此：
*   任意一个介入主义的因果模型，都必须明确指出一种代表「不介入」的介入方式。
*   当我们在问「为什么发生了现象 ![[公式]](https://www.zhihu.com/equation?tex=y_1)」的时候，我们其实在问：「在我对世界建立的因果模型中，自然状态的现象是 ![[公式]](https://www.zhihu.com/equation?tex=y_0%3DY_c%28u%29) ，但是我观察到了现象 ![[公式]](https://www.zhihu.com/equation?tex=y1+%5Cne+y0) 。于是，我认为实际发生的情况是 ![[公式]](https://www.zhihu.com/equation?tex=y_1%3DY_t%28u%29) ，其中 ![[公式]](https://www.zhihu.com/equation?tex=t+%5Cne+c) 。 ![[公式]](https://www.zhihu.com/equation?tex=t) 与 ![[公式]](https://www.zhihu.com/equation?tex=c) 之间的区别是什么？」
*   或者，更简单地说，当我们问「为什么A」的时候，我们往往省略了后半句：「为什么A，而不是B？
 
以知乎搜索「为什么」前几个结果为例，我们可以发现，「默认状态」的思维方式的确无处不在。
 
> 例1：[现在的男生为什么不追女生？](https://www.zhihu.com/question/58896903)
 
默认状态：男生应当追女生。
 
> 例2：[为什么有人会点两百多块一杯的猫屎咖啡？](https://www.zhihu.com/question/21128697)
 
默认状态：一般人不会花两百多块买一杯咖啡。
 
另一些情形中，两个对话者可能选择了不同的默认状态，便带来了以下的对话：
- 甲：「你为什么做了A这件事？」（默认「不做A」是自然状态，要求乙为「做A」提供理由）
- 乙：「为什么不呢？」（默认「做A」是自然状态，把论证的责任转移到甲身上）
在下一部分（2.3），我们将把这一系列直觉发展为正式的虚拟事实模型。
 
不过，我希望先对格兰杰因果（Granger causality）做出一些澄清。格兰杰因果的定义：如果得知事件A的发生有助于预测之后的事件B，那么我们说A是B的格兰杰因。然而，格兰杰因果只包含了观测，却没有包含介入，直接操纵A并不一定能影响B，这与我们日常对因果的直觉不符。所以，格兰杰因果虽然名叫「因果」，却只是一个统计相关性的概念，而非真正的因果概念。在下文中，我不会对格兰杰因果做更多讨论。
 
2.3. 虚拟事实模型
 
虚拟事实模型（Rubin Causal Model，简称RCM）由Donald Rubin提出。在RCM中，因果关系「果」的定义是 ![[公式]](https://www.zhihu.com/equation?tex=%5Cdelta%28u%29%3DY_t%28u%29-Y_c%28u%29) 。
 
在实际生活中，我们考虑的系统往往不止一个——对于某个正在研发的药品，我们最感兴趣的无疑是它在所有目标人群上的效果，而不仅仅是某个病人甲。继续采用RCM对于因果的定义，那么一个介入「因」对群体内所有个体的「果」是 ![[公式]](https://www.zhihu.com/equation?tex=E%5B%5Cdelta%28u%29%5D%3DE%5BY_t%28u%29-Y_c%28u%29%5D%3DE%5BY_t%28u%29%5D-E%5BY_c%28u%29%5D) 。（由期望值的线性可得）
 
在上帝视角下，上述定义并不复杂。即使变量 ![[公式]](https://www.zhihu.com/equation?tex=y%3DY_t%28u%29) 不是一个数值变量，我们也可以通过其他方式定义 ![[公式]](https://www.zhihu.com/equation?tex=%5Cdelta%28u%29) 。从更广泛的角度考虑，RCM定义中的减法未必是实数域的减法；针对更复杂的变量y（例如张量、概率分布），我们可以采用其他的减法，只要符合数学规范和具体研究需要即可。
 
可是在实际生活中，我们无法获得完美的信息：
1.  无法同时知晓 ![[公式]](https://www.zhihu.com/equation?tex=Y_c%28u%29) 与 ![[公式]](https://www.zhihu.com/equation?tex=Y_t%28u%29) 。由于每个人都是独一无二的，每个时间节点也是独一无二的，所以在受到了一种介入，并表现出新状态之后，这个系统不可能完美恢复到原来的状态，重新接受另一种介入。这种情况被称为「因果推断的根本问题」（the Fundamental Problem of Causal Inference，以下简称FPCI）。
2.  无法同时知晓每个个体的情况。正如在检测手机在极端条件下的质量时，我们不可能去砸坏每一个手机一样，我们只能随机从群体中抽取样本，再利用样本的统计数据推断群体参数。
    
 
「无法同时知晓每个个体」的问题，已经有常规的统计学手段解决。但为了避免FPCI，我们必须对群体参数的分布做出额外的假设，包括但不限于以下的一种或多种：
1.  个体处理效应稳定假设（Stable unit treatment value assumption，简称SUTVA）：对于任意个体 ![[公式]](https://www.zhihu.com/equation?tex=u_1) 的干预不会影响到另一个任意个体 ![[公式]](https://www.zhihu.com/equation?tex=u_2) 的状态。SUTVA使我们可以把样本中每个个体的反应看作独立事件，从而降低了我们需要的样本体积、模型体积和建模时间。
2.  同效果假设（assumption of constant effect）：对于所有的个体，某种介入方式造成的效果是相同的。例如，某个降压药对所有人的效果都是降低血压，不会产生增高血压的情况——即使有，也只不过是统计的噪声，可以用大样本、大数定理和中心极限定理消解。于是，我们可以得到 ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7B%5Cdelta%7D%28u%29%3D%5Cbar%7BY_t%7D%28u%29-%5Cbar%7BY_c%7D%28u%29) ，用样本内的平均效果估算这一介入方法对所有个体的因果效果。
3.  同质性假设（assumption of homogeneity）：对于任意个体 ![[公式]](https://www.zhihu.com/equation?tex=u_1) 和 ![[公式]](https://www.zhihu.com/equation?tex=u_2) ，以及任意介入方式 ![[公式]](https://www.zhihu.com/equation?tex=t%5E%2A) ，始终有 ![[公式]](https://www.zhihu.com/equation?tex=Y_%7Bt%5E%2A%7D%28u_1%29%3DY_%7Bt%5E%2A%7D%28u_2%29) 。同质性假设强于同效果假设。例如，一个简单的FizzBuzz电脑程序在不同时间点上的性质理应完全相同。虽然在同一时间点上，我们无法同时测试它在不同输入下的输出，但是它在不同时间点上的表现必然相同。如果我们把「不同时间点上的FizzBuzz程序」看作一个群体，那么其中个体「每个时间点上的FizzBuzz程序」均符合同质性假设。
 
2.3.1. 虚拟事实模型的不足
 
虽然RCM提供了一个可以用数学、统计定义的因果模型，但是它的缺点也很明显：在介入时，我们通常一次只能改变一个变量，观测的状态也只有一个变量。如果我们增加变量，模型的体积、需要的训练数据、训练时间都将以指数级增长。在下一部分，我们可以看到，贝叶斯网络先验的条件独立信息可以缓解这一困难。
 
此外，RCM从自变量的「因」到应变量的「果」的结构几乎完全是个黑箱，缺乏更清晰的可解释性。因此，单个RCM所能解决的问题也较为有限。相比之下，结构因果模型能为因果律、多变量之间的因果关系提供更详细的解释。
 
2.4. 贝叶斯网络
 
贝叶斯网络是一种基于有向无环图（directed acyclic graph，简称DAG）的概率图模型。虽然贝叶斯网络并不能直接表示因果，只能表示相关，但是它的图结构是SCM的基础。
 
![](https://pic3.zhimg.com/80/v2-d9b0f455833ccf4bbf4c94feaca40196_1440w.jpg)
 
贝叶斯网络示例
 
在一个贝叶斯网络中，每个节点是一个随机变量，代表一个事件。通常，这个随机变量服从某个离散或连续的分布。一个节点 ![[公式]](https://www.zhihu.com/equation?tex=X) 中，储存了给定它的所有父节点 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28X%29) 时 ![[公式]](https://www.zhihu.com/equation?tex=X) 的分布，即 ![[公式]](https://www.zhihu.com/equation?tex=P%28X%3Dx%7C%5Cmathrm%7Bpa%7D%28x%29%29) 。![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28X%29)表示节点X的所有父节点，即所有「拥有直接指向X的有向边」的节点。以上图为例， ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28Grade%29%3D+%5C%7B%5Ctextit%7BDifficulty%7D%2C+%5Ctextit%7BIntelligence%7D%5C%7D) 。
 
贝叶斯网络（以及其他所有的概率图模型）相比于原始的联合分布模型，最大的优势在于增加了变量之间条件独立的先验信息，从而减小了模型的体积，与模型进行推断、学习的时间。例如，上图共有5个变量，如果用朴素的联合分布模型建模，条件概率表格的体积将会是 ![[公式]](https://www.zhihu.com/equation?tex=2+%5Ctimes3%5Ctimes2%5Ctimes2%5Ctimes2%3D48) ，而采用贝叶斯网络后，条件概率表格的总体积为 ![[公式]](https://www.zhihu.com/equation?tex=2+%2B+2+%2B+4+%5Ctimes+2+%2B+2%5Ctimes+1+%2B+3+%5Ctimes+1+%3D+17) 。在小型的网络中，这种简化的效果尚不明显，但在大型网络中，假设每个变量有a种取值，那么联合分布模型的体积将为 ![[公式]](https://www.zhihu.com/equation?tex=O%28a%5En%29) ，而一个合适的贝叶斯网络或许能把体积复杂度降低到多项式级别。最极端的情况是朴素贝叶斯，即所有的随机变量均独立，此时模型的体积复杂度为 ![[公式]](https://www.zhihu.com/equation?tex=O%28an%29) 。
 
条件独立的信息是先验的，它们往往由任务相关的专家提供，而非从数据中学习得到。这种做法能保证网络结构的可靠。（此处讨论的是parameter learning而非structure learning，网络结构已知而参数未知；对于后者，我们有Chow-Liu算法，但此处不讨论。）之后，我们也会发现，类似的先验因果假设在SCM中有重要地位。
 
2.4.1. d分隔
 
![](https://pic2.zhimg.com/80/v2-92fbac23e221826585c55d4bddb09255_1440w.jpg)
 
如图所示，对于一个贝叶斯网络中的三个节点/变量而言，一共有三种基本的结构。两种不同的条件独立假设。用 ![[公式]](https://www.zhihu.com/equation?tex=X+%5Cperp+Y)表示X与Y之间独立：
 
1.  cascade: ![[公式]](https://www.zhihu.com/equation?tex=A+%5Crightarrow+B+%5Crightarrow+C) ，则必有 ![[公式]](https://www.zhihu.com/equation?tex=%28A%5Cperp+C%29%7CB) 以及 ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cnot%5Cperp+C) 。
2.  common parent: ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cleftarrow+B+%5Crightarrow+C)，同样有 ![[公式]](https://www.zhihu.com/equation?tex=%28A%5Cperp+C%29%7CB) 以及 ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cnot%5Cperp+C) 。
3.  V-structure: ![[公式]](https://www.zhihu.com/equation?tex=A+%5Crightarrow+B+%5Cleftarrow+C) ，必有 ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cperp+C) 与 ![[公式]](https://www.zhihu.com/equation?tex=%28A+%5Cnot%5Cperp+C%29+%7C+B) ，与前两种基本结构的条件独立情况不同。
 
为了回答「给定一个随机变量的集合Z，随机变量A与B之间是否条件独立」这个问题，我们需要引入d分隔的概念。d分隔（d-separation）的全名是「有向分隔」（directed separation）。
 
某个节点集合O能d分隔节点A与节点B，当且仅当：给定O时，A与B之间不存在有效路径（active path）。
 
对于A与B之间的无向无环路径P，如果P上的每三个连续节点，都符合以下四种情况中的一种，那么P就是一条有效路径：
1.  X←Y←Z且Y∉O
2.  X→Y→Z且Y∉O
3.  X←Y→Z且Y∉O
4.  X→Y←Z且Y∈O。这种情况被称为伯克森悖论（Berkson's Paradox）：当两个独立事件的共同结果被观察到时，这两个独立事件就不再相互独立了。例如，扔两个硬币，硬币A朝上的面和硬币B朝上的面之间，应该是相互独立的；然而，如果我们已知「有一个硬币正面朝上」，那么A与B朝上的面之间就不再相互独立了。
    
 
相应地，如果给定O之后，一条路径P不是一条有效路径，那么我们称O节点集合 d分隔 了路径P。d分隔的概念适用于两个节点，也适用于两个节点之间的路径，后者在「后门准则」的定义中非常有用。
 
如果两个变量没有被d分隔，那么它们之间的状态被称为d联结（d-connection）。
 
  
 
d分隔能极大简化贝叶斯网络中 ![[公式]](https://www.zhihu.com/equation?tex=%28X%5Cperp+Y+%29%7C+Z) 等条件独立情况的判定。Pearl将其进一步泛化，提出了拟图（graphoid）的概念。一个graphoid是一组形如「已知变量Z，则变量X与变量Y相互独立」的陈述，服从以下五条拟图公理：
 
![](https://pic3.zhimg.com/80/v2-220c102184781b71c753f20ea7e824da_1440w.jpg)
 
关于graphoid中文翻译的备注：graphoid尚无权威的中文翻译，而且在互联网上几乎没有任何相关的中文材料。我在选择译名时，参考了matroid的翻译。既然matrix是矩阵，而matroid是拟阵，那么graph是图，所以graphoid应该被称为拟图。
 
拟图的概念只出现在Pearl的著作中。不过，如果我们采用概率论对于「独立事件」的定义，那么我们可以把它们当做定理推导得出，可见概率论的「独立」符合拟图公理体系。当然，intersection的成立需要一个额外条件：针对所有的事件A，如果 ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cne+%5Cemptyset) ，那么 ![[公式]](https://www.zhihu.com/equation?tex=P%28A%29%3E0) 。
 
  
 
2.4.2. 为什么贝叶斯网络不适合做因果模型？
 
有了一个学习完毕的贝叶斯网络后，我们可以用它进行各类推断，主要是概率推断![[公式]](https://www.zhihu.com/equation?tex=P%28X_i%7CX_%7Bj_1%7D%2C+X_%7Bj_2%7D%2C+X_%7Bj_3%7D%2C+...%2C+X_%7Bj_k%7D%29) ：已知 ![[公式]](https://www.zhihu.com/equation?tex=X_%7Bj_1%7D%2C+X_%7Bj_2%7D%2C+X_%7Bj_3%7D%2C+...%2C+X_%7Bj_k%7D) 等随机变量的值，求另一随机变量 ![[公式]](https://www.zhihu.com/equation?tex=X_i) 的条件概率。贝叶斯网络的优越性体现于，即使有大量的缺失、未知变量值，它也能利用边缘化操作，毫无障碍地进行概率推断。在SCM中，这一功能仍然有相当重要的地位。
 
如果我们把箭头看作从因指向果，把A→B看作A导致了B，那么贝叶斯网络看起来似乎能表达因果关系。然而，贝叶斯网络本身无法区分出因果的方向。例如，A←B←C与A→B→C的因果方向完全相反，但在贝叶斯网络的模型描述下，它们表达的概率分布和条件独立假设完全相同。
 
此外，概率论「给定/已知随机变量Z」里的「给定/已知」只能用于表达观察，而非介入。例如，P(下雨|地面是湿的)与P(地面是湿的|下雨)的概率值都很高，其中「给定“地面是湿的”」与「给定“下雨”」都是观察而非介入的结果。用do(X)表示「介入，使得事件X发生」，现在考虑另一种情况：P(下雨|do(地面是湿的))。根据直觉，显然P(下雨|do(地面是湿的)) < P(下雨|地面是湿的)，因为把地面弄湿并不能导致下雨。
 
综上所述，贝叶斯网络虽然十分强大，但无法准确描述因果关系。下文的SEM将主要解决这个问题。在学习贝叶斯网络的过程中，我们也应该尽量避免使用「因果」相关的词语——贝叶斯网络中，A→B未必等同于A导致B。
 
  
 
2.5. 结构方程+结构因果模型
 
为了表示因果关系，我们需要对贝叶斯网络进行改进。结构方程模型（Structural Equation Model，简称SEM）在经济与工程领域十分常用。在贝叶斯网络的基础上加入SEM的成分之后，我们就离完善的SCM（结构因果模型）更近了一步。
 
  
 
2.5.1. 打破对称性
 
在贝叶斯网络中，节点 ![[公式]](https://www.zhihu.com/equation?tex=X) 的概率分布 ![[公式]](https://www.zhihu.com/equation?tex=P%28X%3Dx%7C%5Cmathrm%7Bpa%7D%28X%29%29) 由它的父节点 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28x%29) 决定，记录在一个条件概率表格中。然而，条件概率表格和一些简单的连续概率分布都是可逆的。例如，对于随机变量 ![[公式]](https://www.zhihu.com/equation?tex=X) 和 ![[公式]](https://www.zhihu.com/equation?tex=Y) ，如果 ![[公式]](https://www.zhihu.com/equation?tex=Y%3D%5Calpha+X+%2B+%5Cbeta) ，那么我们可以操纵代数表达式，得到 ![[公式]](https://www.zhihu.com/equation?tex=X%3D%5Cfrac%7BY-%5Cbeta%7D%7B%5Calpha%7D) 。然而，这种对称性在因果关系里是不符合直觉的。对称的代数表达式表明，如果我们改变Y，X就会发生相应的改变；可是，修改温度计的读数并不会改变环境温度，调整闹钟的时针并不会改变真正时间的流动。
 
因此，在SEM中，我们用函数式的方程表示某个变量 ![[公式]](https://www.zhihu.com/equation?tex=X) ： ![[公式]](https://www.zhihu.com/equation?tex=X%3Df_X%28%5Cmathrm%7Bpa%7D%28X%29%2C%5Cmathrm%7Bu%7D%28X%29%29) 。其中， ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28X%29) 表示X的父节点中的内生变量（endogenous variable）； ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bu%7D%28X%29) 表示X的父节点中的外生变量（exogenous variable），只有一个。内生变量依赖于其他变量，在SCM中表示为「存在父节点的节点」，即至少有一条边指向该节点；外生变量独立于其他变量，在SCM中表示为「不存在父节点的节点」，即没有边指向该节点。
 
传统的路径分析研究中， ![[公式]](https://www.zhihu.com/equation?tex=f_X) 通常是一个线性函数，因果律的定义也局限与 ![[公式]](https://www.zhihu.com/equation?tex=Y%3D%5Calpha+X+%2B+%5Cbeta) 中的 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha) 。但是，在数据越发复杂的现在，我们完全可以采用非线性函数、非参数模型。相对地，「因果」的定义也从路径参数 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha) 变成了更广义的「变化传递」，参见前文RCM的部分。作为一个广泛的模型框架，SCM可以产生各式各样的复杂模型。
 
在最广泛的条件下，函数 ![[公式]](https://www.zhihu.com/equation?tex=f_X) 是不可逆的。我们需要把 ![[公式]](https://www.zhihu.com/equation?tex=X%3Df_X%28%5Cmathrm%7Bpa%7D%28X%29%2C%5Cmathrm%7Bu%7D%28X%29%29) 理解为「（大自然/模型本身）对X的赋值」，而不仅仅是一个普通的代数等式。SCM要求所有的箭头 ![[公式]](https://www.zhihu.com/equation?tex=A%5Cto+B) 必须表示「A直接导致B」。所以，在因果推断的过程中，我们必须按照因果箭头的方向进行推理，不能颠倒顺序。
 
![](https://pic1.zhimg.com/80/v2-2f59fbad01d5b57d7c151822c14712ac_1440w.jpg)
 
图1：结构因果模型示意图
 
如上图所示， ![[公式]](https://www.zhihu.com/equation?tex=U_X) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Y) 是外生变量， X与Y是内生变量，X可以导致Y。在图(a)中， ![[公式]](https://www.zhihu.com/equation?tex=U_X) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Y) 之间没有边相连，而在图(b)中， ![[公式]](https://www.zhihu.com/equation?tex=U_X) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Y) 之间有一条用虚线表示的双向箭头。在SCM里，我们用单向箭头表达直接的因果关系，用双向箭头表明两个外生变量之间可能存在未知的混杂因素（confounding variable）。
 
![[公式]](https://www.zhihu.com/equation?tex=U_X) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Y) 等外生变量可以表示「模型没有考虑到的环境噪音」，从而为看似非随机的结构方程模型加入随机的成分。因此，SEM并非完全确定，它也可以拥有概率、不确定性等特征；SCM比普通的贝叶斯网络更广泛。此外，一个SCM描述了数据的生成原理，而不仅是表面观测到的概率分布，所以SCM比贝叶斯网络更稳定。
 
  
 
2.5.2. 介入
 
如上文所言，SCM是对于贝叶斯网络的一种泛化。一般的贝叶斯网络可以解答两类问题：
*   条件概率： ![[公式]](https://www.zhihu.com/equation?tex=P%28Y%7CE%3De%29) ，其中Y是我们感兴趣的一组未知变量，E是一组我们观察到的已知变量，e是我们观察到的E的值。E可以是空集，代表「我们没有观察到任何变量」。
*   最大后验概率（MAP）： ![[公式]](https://www.zhihu.com/equation?tex=%5Carg%5Cmax_%7By%7D%7BP%28Y%3Dy%7CE%3De%29%7D) ，我们想要找到的是一组最有可能的Y值。
    
 
如果不考虑算法复杂度，一个能估计条件概率的模型必然能估计MAP，所以下文将只讨论条件概率的情况。
 
在「观察」的基础上，SCM还能做到「介入」： ![[公式]](https://www.zhihu.com/equation?tex=P%28Y%7CE%3De%2C+do%28X%3Dx%29%29) 。其中，我们对系统进行介入，迫使一组变量X拥有值x。在X是一个空集的情况下，SCM与普通的贝叶斯网络差别不大。
 
以下图为例，我将展示SCM实现介入的方法。
 
![](https://pic1.zhimg.com/80/v2-bfddee417c2bc99edd58383eae72548c_1440w.jpg)

图2：一个SCM
 
在这个SCM中，变量X、Y、Z之间的关系可以用以下的结构方程表示：
 
1.  ![[公式]](https://www.zhihu.com/equation?tex=Z%3Df_Z%28U_Z%29)
2.  ![[公式]](https://www.zhihu.com/equation?tex=X%3Df_X%28Z%2C+U_X%29)
3.  ![[公式]](https://www.zhihu.com/equation?tex=Y%3Df_Y%28X%2C+U_Y%29)
    
 
在此模型中，我们假设 ![[公式]](https://www.zhihu.com/equation?tex=U_X) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Y) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Z) 这三个外生变量独立。所以，图(a)与图(b)中的 ![[公式]](https://www.zhihu.com/equation?tex=U_X) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Y) 与 ![[公式]](https://www.zhihu.com/equation?tex=U_Z) 之间均没有边相连。
 
如图(b)所示，当我们进行介入 ![[公式]](https://www.zhihu.com/equation?tex=do%28X%3Dx_0%29) 时，我们切断了所有指向X的边，并将X赋值为 ![[公式]](https://www.zhihu.com/equation?tex=x_0) 。于是，新的SCM包括了一套新的结构方程：
1.  ![[公式]](https://www.zhihu.com/equation?tex=Z%3Df_Z%28U_Z%29)
2.  ![[公式]](https://www.zhihu.com/equation?tex=X%3Dx_0)
3.  ![[公式]](https://www.zhihu.com/equation?tex=Y%3Df_Y%28X%2C+U_Y%29)
    
 
综上所述，一个SCM（写作 ![[公式]](https://www.zhihu.com/equation?tex=M_1) ）估计 ![[公式]](https://www.zhihu.com/equation?tex=P_%7BM_1%7D%28Y%7CE%3De%2Cdo%28X%3Dx%29%29) 的方式为：完成对原有模型 ![[公式]](https://www.zhihu.com/equation?tex=M_1) 的介入 ![[公式]](https://www.zhihu.com/equation?tex=do%28X%3Dx%29) 之后，得到一个新的模型 ![[公式]](https://www.zhihu.com/equation?tex=M_2) 。随后，在 ![[公式]](https://www.zhihu.com/equation?tex=M_2) 上估计 ![[公式]](https://www.zhihu.com/equation?tex=P_%7BM_2%7D%28Y%7CE%3De%29) 。
 
有人可能会产生疑问：「观察和介入，有什么本质区别吗？」
 
一个日常例子式的回答如下：
 
用A代表「环境温度」，用B代表「温度计读数」，A与B之间的因果关系为 ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cto+B) 。在默认状态下，温度计不会受到外在干预。因此，观察到温度计读数升高，我们可以推断出环境温度升高。但是，当我们直接干预温度计时（例如用手握住温度计），我们进行了介入 ![[公式]](https://www.zhihu.com/equation?tex=do%28B%3Db_1%29) ，使温度计的读数变成了 ![[公式]](https://www.zhihu.com/equation?tex=b_1) ；同时，因为是介入而非观察，从A到B的因果箭头被切断了，我们有 ![[公式]](https://www.zhihu.com/equation?tex=A%5Cnot%5Cto+B) 或 ![[公式]](https://www.zhihu.com/equation?tex=A+%5C+%5C+%5C+%5C+%5C+B) 。
 
假设 ![[公式]](https://www.zhihu.com/equation?tex=b_1) 是一个较高的温度，那么 ![[公式]](https://www.zhihu.com/equation?tex=P%28A%3Db_1%7CB%3Db_1%29) 代表「在自然状态下，观察到温度计的读数是 ![[公式]](https://www.zhihu.com/equation?tex=b_1) 时，实际的环境温度为 ![[公式]](https://www.zhihu.com/equation?tex=b_1) 的概率」； ![[公式]](https://www.zhihu.com/equation?tex=P%28A%3Db_1%7Cdo%28B%3Db_1%29%29) 代表「在外在干预使温度计读数成为 ![[公式]](https://www.zhihu.com/equation?tex=b_1) 时，实际的环境温度为 ![[公式]](https://www.zhihu.com/equation?tex=b_1) 的概率」。显然， ![[公式]](https://www.zhihu.com/equation?tex=P%28A%3Db_1%7CB%3Db_1%29+%3E+P%28A%3Db_1%7Cdo%28B%3Db_1%29%29) ，可见观察与介入是两种完全不同的行为。观察不会影响模型的自然状态，但介入会。
 
2.5.3. 因果推断的数学原理
 
在这一部分，我将介绍SCM进行因果推断的数学基础。
 
我们说一个SCM具有马尔可夫性质，当且仅当这个SCM不包含任何的有向环，且所有外生变量均相互独立。因为外生变量通常被理解为某种「误差项」或「噪音项」，所以如果某些外生变量之间存在相关性，那么它们之间可能存在混淆变量。在一个马尔可夫式SCM中，我们可以得到以下的基本定理：
 
因果马尔可夫条件： ![[公式]](https://www.zhihu.com/equation?tex=P%28v_1%2C+v_2%2C+...%2C+v_n%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bn%7DP%28v_i%7C%5Cmathrm%7Bpa%7D%28v_i%29%29)
 
其中， ![[公式]](https://www.zhihu.com/equation?tex=v_i) 代表我们感兴趣的变量， ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28v_i%29) 代表它的父节点中的所有内生变量。利用因果马尔可夫条件，我们可以把一个联合概率分布分解为多个条件概率分布的积。
 
一个符合因果马尔可夫条件的SCM经过介入之后，仍然符合因果马尔可夫条件，条件概率计算如下：
 
![[公式]](https://www.zhihu.com/equation?tex=P%28v_1%2C+v_2%2C+...%2C+v_n%7Cdo%28X%3Dx%29%29%3D%5Cprod_%7Bi%3D1%2C+v_i%5Cnotin+X%7D%5E%7Bn%7DP%28v_i%7C%5Cmathrm%7Bpa%7D%28v_i%29%29%7C_%7BX%3Dx%7D)
 
其中，X是一系列受到干预的变量，x是X中变量受干预之后的数值。 ![[公式]](https://www.zhihu.com/equation?tex=P%28v_i%7C%5Cmathrm%7Bpa%7D%28v_i%29%29%7C_%7BX%3Dx%7D) 表示， ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28v_i%29) 里同时也在X里（即在 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bpa%7D%28v_i%29+%5Ccup+X) 中）的变量将被赋值为 ![[公式]](https://www.zhihu.com/equation?tex=x) 的对应值。
 
![](https://pic1.zhimg.com/80/v2-bfddee417c2bc99edd58383eae72548c_1440w.jpg)

图2
 
以图2为例，在干预之前， ![[公式]](https://www.zhihu.com/equation?tex=P%28Z%2C+Y%2C+X%29+%3D+P%28Z%29P%28X%7CZ%29P%28Y%7CX%29) ，而在干预 ![[公式]](https://www.zhihu.com/equation?tex=do%28X%3Dx_1%29) 之后， ![[公式]](https://www.zhihu.com/equation?tex=P%28Z%2C+Y%7Cdo%28X%3Dx_1%29%29+%3D+P%28Z%29P%28Y%7CX%3Dx_1%29) 。注意，由于从Z到X的因果箭头已经被切断， ![[公式]](https://www.zhihu.com/equation?tex=P%28Z%29%3DP%28Z%7Cdo%28X%3Dx_1%29%29) ，因为直接改变X无法影响Z。
 
在《Causality》中，Pearl证明了一个更广泛的结论：
 
![[公式]](https://www.zhihu.com/equation?tex=P%28Y%3Dy%7Cdo%28X%3Dx%29%29%3D%5Csum_t%7BP%28Y%3Dy%7CT%3Dt%2CX%3Dx%29P%28T%3Dt%29%7D)
 
其中，每一个t都代表X所有父节点的一种可能取值。由于所有直接指向X的箭头已经被切断，所以自然有 ![[公式]](https://www.zhihu.com/equation?tex=P%28T%3Dt%7CX%3Dx%29%3DP%28T%3Dt%29) 。
 
  
 
2.5.4. 后门准则（back-door criterion）
 
考虑如下图3所示的SCM：
 
![](https://pic1.zhimg.com/80/v2-6e12dd916d27ef0130aded624a625500_1440w.jpg)
 
图3
 
在SCM中，如果一条无向连接X与Y的路径有一条指向X的箭头，那么我们把这条路径称为从X到Y的后门路径。按照正常的因果链，「X导致Y」的结构应该是 ![[公式]](https://www.zhihu.com/equation?tex=X%5Cto+V_1+%5Cto+V_2+%5Cto+...+%5Cto+V_%7Bk-1%7D+%5Cto+V_%7Bk%7D+%5Cto+Y) ；然而，如果X与Y之间后门路径存在，那么实际结果中很可能出现虚假的统计相关性。
 
因此，当一个变量集合S符合以下两个条件时，我们称S符合后门准则：
1.  S中不包括X的后代。
2.  S能d分隔所有从X到Y的后门路径。
    
 
例如，在图3里， ![[公式]](https://www.zhihu.com/equation?tex=%5C%7BZ_1%2C+Z_2%2C+Z_3%5C%7D%2C+%5C%7BZ_1%2C+Z_3%5C%7D%2C+%5C%7BW_1%2C+Z_3%5C%7D%2C+%5C%7BW_2%2C+Z_3%5C%7D) 等集合都满足后门准则，但 ![[公式]](https://www.zhihu.com/equation?tex=%5C%7BZ_3%5C%7D) 不满足后门准则。
 
后门准则的重要性在于，它进一步泛化了2.5.3.结尾的公式。如果S满足从X到Y的后门准则，那么，我们可以推导得到：
 
![[公式]](https://www.zhihu.com/equation?tex=P%28Y+%3D+y%7Cdo%28X+%3D+x%29%2C+S+%3D+s%29+%3D+P%28Y+%3D+y%7CX+%3D+x%2C+S+%3D+s%29)
 
![[公式]](https://www.zhihu.com/equation?tex=P%28Y+%3D+y%7Cdo%28X+%3D+x%29%29+%3D+%5Csum_s+P%28Y+%3D+y%7CX+%3D+x%2C+S+%3D+s%29P%28S%3Ds%29%3D%5Csum_s+%5Cfrac%7BP%28Y+%3D+y%2C+X+%3D+x%2C+S+%3D+s%29%7D%7BP%28X%3Dx%2C+S%3Ds%29%7D)
 
这极大简化了SCM推导时的运算。
 
  
 
2.6. SCM的反事实推理
 
反事实推理（counterfactual inference）的核心在于：虽然现实情况下 ![[公式]](https://www.zhihu.com/equation?tex=X%3Dx_1) ，但是假如![[公式]](https://www.zhihu.com/equation?tex=X%3Dx_2) 的话，Y会怎么样呢？
 
有些人后悔，「如果我当年……，那么我现在就能……。」这一思维方式就是反事实推理。
 
反事实推理与FPCI（因果推断的根本问题）息息相关。对于一个已经接受了实验组介入的样本u，我们只能观察到u的 ![[公式]](https://www.zhihu.com/equation?tex=Y_t%28u%29) ，却永远无法观察到 ![[公式]](https://www.zhihu.com/equation?tex=Y_c%28u%29) ，反之亦然。RCM（虚拟事实模型）对反事实推理有一定的描述，但RCM整体不如SCM清晰、明确、易解释。
 
下面，我将用SCM重新表达2.2部分中提到的介入主义因果观。
 
*   RCM考虑的对象是一个种群 ![[公式]](https://www.zhihu.com/equation?tex=U) 内的所有个体 ![[公式]](https://www.zhihu.com/equation?tex=u) 。在很多情形下，同质性假设不成立，每个个体都不尽相同。在SCM中，个体的差异会被误差项 ![[公式]](https://www.zhihu.com/equation?tex=U_V) 表示（外生变量 ![[公式]](https://www.zhihu.com/equation?tex=U_V) 会相对应地影响内生变量 ![[公式]](https://www.zhihu.com/equation?tex=V) ）。除了 ![[公式]](https://www.zhihu.com/equation?tex=U_V) 之外，模型 ![[公式]](https://www.zhihu.com/equation?tex=M) 本身所代表的「自然法则」保持不变。
*   RCM的表达式 ![[公式]](https://www.zhihu.com/equation?tex=Y_t%28u%29) 可以表示为 ![[公式]](https://www.zhihu.com/equation?tex=M.%5Cmathtt%7Bquery%7D%28P%28Y%7Cdo%28T%3Dt%29%2C+U%3Du%29%29) 。即：我们对模型M进行干预，使得变量T赋值为t；同时，我们观察到所有外生变量U的值为u；在此情况下，我们向模型M查询我们感兴趣变量Y的条件概率。
*   RCM要求模型拥有一个「不受介入」的默认状态。显然，SCM符合要求：![[公式]](https://www.zhihu.com/equation?tex=Y_c%28u%29%3DM.%5Cmathtt%7Bquery%7D%28P%28Y%7CU%3Du%29%29)
    
 
因此，SCM可以回答类似「假如 ![[公式]](https://www.zhihu.com/equation?tex=X%3Dx_1) 而非现实中的 ![[公式]](https://www.zhihu.com/equation?tex=X%3Dx_0) ，Y的值是什么？」的反事实问题。但是，在现实生活中，由于个体信息 ![[公式]](https://www.zhihu.com/equation?tex=U%3Du) 通常未知，而复杂的非线性结构方程可能会随着U的分布变化而变化，所以反事实推理普遍比较困难。
 
总而言之，所有RCM均可以用SCM表达，而且SCM的白箱比RCM的黑箱更清晰、更稳定。
 
  
 
## 过程性因果
 
在第二章，我们使用的SCM（结构因果模型）建立在三条基本直觉上：
1.  因和果都是单独时间点上的单独事件
2.  因在前，果在后
3.  （由1和2可得）两个事件无法互为因果
 
不过，在其他一些情境中，例如掠食者的数量与猎物的数量，两个变量似乎「互为因果」。SCM与贝叶斯网络不允许环路的存在，故无法表示此类直觉上的因果关系。所以，我们需要一个更复杂的因果模型——因果环路图（Causal Loop Diagram，简称CLD）。
 
CLD中的变量基于以下的直觉：
1.  因和果是某种过程，有一段持续的时间
2.  因和果的持续时间段可以相互重叠
3.  两个过程可以互为因果，甚至一个过程自身也可以形成因果环路
    
 
![](https://pic4.zhimg.com/v2-2d54fa8887f3ca929ff3d1aca035c6ff_b.webp)
 
因果环路图：银行存款与利息
 
和SCM相比，CLD尚未有那么严谨、广泛的理论框架。我们可以把CLD理解为一个「从时间标量（实数）到一个SCM集」的函数映射。为了方便建模，所有的变量都是数值变量，而且多个过程变量之间的相互影响往往都是线性的，形如 ![[公式]](https://www.zhihu.com/equation?tex=Y%3D%5Calpha+X+%2B+%5Cbeta) 。如果 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha+%3D+%5Cfrac%7BdY%7D%7BdX%7D+%3E+0) ，那么我们说从X到Y的链接是正链接；如果 ![[公式]](https://www.zhihu.com/equation?tex=%5Calpha+%3D+%5Cfrac%7BdY%7D%7BdX%7D+%3C+0) ，那么我们说从X到Y的链接是负链接。
 
![](https://pic3.zhimg.com/v2-793e119dfa33cf7b26893a16572c2de6_b.jpg)
 
正链接（左）与负链接（右）
 
对于因果环路 ![[公式]](https://www.zhihu.com/equation?tex=A+%5Cto+B+%5Cto+A) ：
 
*   如果A起初的一点增加（或减少）会通过因果环路，导致A进一步增加（或减少），那么我们称之为强化反馈回路。
*   如果A起初的一点增加（或减少）会通过因果环路，反而导致A减少（或增加），从而中和最初的增加（减少），那么我们称之为平衡反馈回路。
    
 
假设A>0且B>0，那么：
*   如果 ![[公式]](https://www.zhihu.com/equation?tex=A%5Cto+B) 与 ![[公式]](https://www.zhihu.com/equation?tex=B+%5Cto+A) 的链接正负相同，那么我们通常可以得到一个强化反馈回路。
    
*   如果 ![[公式]](https://www.zhihu.com/equation?tex=A%5Cto+B) 与 ![[公式]](https://www.zhihu.com/equation?tex=B+%5Cto+A) 的链接正负相反，那么我们通常可以得到一个平衡反馈回路。
    
 
更一般地，在一个因果环路图中：
*   如果有偶数个负链接，那么它是一个强化反馈回路。
*   如果有奇数个负链接，那么它是一个平衡反馈回路。
 
反馈回路的实际意义通常如下：
*   强化反馈回路通常意味着指数增加、指数衰减，例如「利滚利」的银行存款与利息、不受限制的人口增长。
*   平衡反馈回路通常意味着达到某个平衡状态，例如洛特卡-沃尔泰拉方程的解。

在未来，一个可能的研究方向是把SCM中较为成熟、广泛的因果推断框架推广到CLD上。研究的重点在于引入非线性、非参数的复杂因果链接。此类研究必然十分困难，但随着电脑计算能力的增强，我们将逐渐有能力构建更复杂的CLD。



## 因果工具

![](http://p6-tt.byteimg.com/large/pgc-image/S2ZVUh471w0ujH)

- 因果模型
  - 当只有蓝色分布中的采样数据时，怎么凭空造出绿色分布中的数据。这时就要用到do-calculus。它允许慢慢探索绿色条件分布，直到可以根据蓝色分布下的各种边际分布、条件分布和期望来表
  - ![](https://pic4.zhimg.com/80/v2-8c82015e505280e3b4c87e0a676d735e_720w.jpg?source=1940ef5c)
- Do-calculus（do算子）
  - 最终如果能获得一个p̃(y\|do(x))的等价公式，（不再有任何do操作符），则因果查询p̃(y\|do(x))是可识别，否则不能识别
  - ![](https://pic1.zhimg.com/80/v2-c995f1ba9331c306f59caa2cf150cc8f_720w.jpg?source=1940ef5c)



# 工程实现

- Whitney:
  - 在某个条件下的 群体的平均ite，w=1表示这个病人采用了这个治疗手段（treatment 组），w=0表示这个病人没采用治疗手段（control 组），Y表示在w干预情况下的outcome。也就是说，假设这个病人在治疗组的outcome 减去 假设这个病人在对照组的outcome。一般只能知道 这个病人在治疗组的outcome 或者 这个病人在对照组的outcome。已知的那个叫事实，另外一个不知道的就叫反事实，要知道这个治疗方案到底有没有效果，就要算ite。所以需要推理反事实

<iframe frameborder="0" style="width:100%;height:811px;" src="https://app.diagrams.net/?lightbox=1&highlight=0000ff&edit=_blank&layers=1&nav=1&title=Untitled%20Diagram.drawio#R1ZdNb9swDIZ%2Fja%2BDLclfxyRrux16WQfsrNmKLVQWA0X52q8fHcuJE7lAgaaB60vMlyJFPXSYOKCLZv9k%2BKp%2BhlKogITlPqDfA0KikGb40SqHTmF53gmVkaVbdBZe5D%2FRRzp1I0uxvlhoAZSVq0uxAK1FYS80bgzsLpctQV3uuuKV8ISXgitf%2FSNLWzs1SvKz44eQVe22zkjaOf7y4rUysNFuv4DQ5fHq3A3vc7mDrmtewm4g0YeALgyA7e6a%2FUKolm2PrYt7fMN7qtsIbd8TQKKYuqAtVxvRV32szR56HhiE6NGYL6VSC1Bgjg76GGZpGKMOK15I27Y7CdFcWwOvol%2BoQbextW0UWlGbBrQdpjleqPv199UJY8V%2BILnzPAlohDUHXOK8lObf4i7IPX00zHpld%2B5mHLoe1INGnkTunqDqlP9MEW8cyLehkg9AjchsNp8W1Ci9hhrdnyn9AFORxQkjk2LKsgkwZR7Tn3qLZ5KgPbh4LuuQuJFNGNpcyUqjUWCYQE7zFoHEYTpzjkaWpbofV5Jfc8UBPQI2ykfApjfiGntcf4ktqM1XBptMAWzigf1teCm%2FMlfmcY3ju3NNPa7PUknLXaYRrB7Gd9AatCJKbkMvTrwxmo%2FRYyPw2I3gZR68BeilkvjXdNrwGLuGx0Z%2FhD4TXu7DqzmsJ07OH4Z3J9enGZBDOlwXYuLs%2FK8sZZ%2FIDs3zG9XRN3htpQ%2F%2FAQ%3D%3D"></iframe>


# [如何在观测数据下进行因果效应评估](https://www.sohu.com/a/426630014_741733)

- 【2020-10-22】[如何在观测数据下进行因果效应评估](https://www.sohu.com/a/426630014_741733)

## 导语
 
- 什么是因果？因果性与相关性的区别是什么？相关性有哪几种来源？如何评估因果效应？在2020年集智-凯风研读营中，浙江大学计算机学院助理教授况琨就上述问题做了系统梳理，本篇是文字整理版。
 - 自9月20日（周日）开始，集智俱乐部联合北京智源人工智能研究院还将举行一系列有关因果推理的读书会，欢迎更多的有兴趣的同学和相关研究者参加，一起迎接因果科学的新时代。
 
## 1. 因果性与相关性
 
### 1.1 什么是因果
 
![](https://p2.itc.cn/q_70/images03/20201023/abf0d82abec84b6aa7f375eb84b8425b.jpeg)
 
什么是因果呢？“因”其实就是引起某种现象发生的原因，而“果”就是某种现象发生后产生的结果。因果问题在我们日常生活中十分常见。
 
- 首先在医疗方面。比如在这次新冠疫情中，各个国家都在争先恐后地研发疫苗，但在疫苗上市之前还需要做很多次单盲实验、双盲实验，其背后就是基于随机对照实验的一些因果推理和因果效应评估，确定药物于病人康复之间的因果效应。
- 其次在社会科学方面。比如在国家出台新的政策前，就要利用因果推理手段来估计这个政策会给民众、经济效应和社会效应带来多大影响。
- 最后在市场营销方面。比如在推广告之前，就需要使用随机对照试验或者A/B测试，选择广告推送的策略以实现效益最大化。
 
### 1.2 因果性与相关性的区别
 
![](http://p5.itc.cn/q_70/images03/20201023/76d7cd05ee374688a3d1510e467888d6.jpeg)
 
- （1）相关性比因果性更缺乏 **可解释性**（Explainability）。这张图中，黑线是肯塔基州的结婚率，而红线是渔船事故死亡人数，两者具有很高的相关性，但两者之间却没有任何因果关系。我们在使用数据的时候就需要知道，这里的相关性是不可靠的、不可解释的。
 
![](http://p6.itc.cn/q_70/images03/20201023/00c9e83da59c454f85593c3522b22e88.jpeg)
 
另外一个例子是太阳镜与冰淇淋的销售量之间的关系，两者之间呈现着明显的正相关性。但如果我们直接关闭太阳镜商店，进行干预，会影响冰淇淋的销量吗？并不会。因为两者之间的虚假相关性是由天气引发的，在太阳炎热时两者的消费量都会提升，强制干预其中一个的销量并不会直接影响另一个。
 
![](http://p5.itc.cn/q_70/images03/20201023/fe9e991d7ddb4707aa503a1adeb609f4.jpeg)
 
- （2）相关性比因果性更缺乏 **稳定性**（Stability）。比如我们训练模型去识别图片中的狗，但数据集中90%的狗都是在草地上的，那么在这个数据集中草地与狗就十分相关。那么如果我们利用传统机器学习的方法，无论是逻辑斯蒂回归还是深度模型，大概率会把草地识别为重要的特征。但如果测试数据集中的狗是在沙滩上或者水中，模型就有很大概率会失败。
 
传统机器学习使基于关联驱动的，对于未知的测试数据集很难达到稳定预测。传统机器学习在关联挖掘中会发现一些非因果特征，比如草地背景与标签的关系，并利用这种强的**虚假相关**（Spurious Correlation）进行预测。如果我们能够发现特征与标签之间的因果关系，比如我们人类在识别狗的时候就会去关注够的鼻子、眼睛和耳朵这些因果特征，那么无论狗是在什么背景下，我们都可以正确识别。
 
![](http://p6.itc.cn/q_70/images03/20201023/9d14e6e0cad6495db4e8b5a17f5e534d.jpeg)
 
- （3）第三个区别是 **可行动性**（Actionability）。比如某个电商在推广某个商品时，需要从两个广告推荐算法中进行选择，看哪个算法能带来的收益更大。
 
如图所示，前期的试验发现，新算法B比旧算法 A 的总体成功率更高。但如果将用户按收入分为两层，却会发现算法A在低收入人群和高收入人群中的效果反而都优于 B 。两个算法的试验对象中，收入分布的差别很大，如果不进行控制，就会产生错误的结果。而除了收入之外，可能还需要考虑地域、年龄等多个变量，否则就会产生算法与成功率之间的虚假相关。
 
这些虚假相关是由混淆变量产生的**混杂偏倚**（Confounding Bias）。这种决策问题实际上是反事实问题，而不是预测问题。
 
![](http://p2.itc.cn/q_70/images03/20201023/953de93e7051456094019c8ee6edb2ac.jpeg)
 
- （4）第四个区别是 **公平性**（Fairness）。Google曾开发了根据人像判断犯罪率的软件，输入为黑人时犯罪率就会比白人更高。而肤色与犯罪率之间不应该存在因果关系，这就出现了公平性的问题。实际上如图所示，真正起决定性作用的变量是“收入”，黑人的收入普遍偏低，而低收入人群的犯罪率较高，因此肤色和犯罪率之间出现了虚假相关。
 
而通过因果评估的框架，我们可以利用**Do-演算**（Do-Calculus）等工具，干预收入的多少，来计算肤色与犯罪率之间真正的因果效应大小。实际上，收入和犯罪率才是强因果相关的，而肤色和犯罪率之间因果效应可以弱到忽略不计。
 
### 1.3 相关性的三种来源
 
![](http://p0.itc.cn/q_70/images03/20201023/1607eaf7a809412d861ab4d0342ccf7e.jpeg)
 
相关性有三种来源：**因果**、**混淆**和**样本选择**。
 
- **因果关联**例子就是天下雨地面会湿，这种关系是能够被人类所理解的、是可解释的、稳定的（无论在任何国家或城市，天下雨地都会湿）。
- **混淆关联**是由混淆偏差（Confounding Bias）造成的。比如图中X是T和Y的共同原因，但如果不对X进行观察，就会发现T和Y是具有相关性的，但T和Y之间是没有直接因果效应的，这就是产生了虚假相关。
- **样本选择偏差**（Selection Bias）也会产生相关性，比如之前的例子中，如果数据集中的狗都出现在沙滩上，而没有狗的图片都是草地，那么训练处的模型就会发现草地与狗之间是负相关的，这也产生了虚假相关。
 
虚假相关与因果关联相比，缺乏可解释性，且容易随着环境变化。在工业界和学术界中，我们都希望能判断两个变量之间的相关究竟是因果关联还是虚假相关。如果是虚假相关的话，可能会给实际的系统带来风险。
 
所以说，恢复因果可以提高可解释性，帮助我们做出决策，并在未来的数据集中做出稳定而鲁棒的预测，防止算法产生的偏差。无论数据集中有什么样的偏差，我们都希望能挖掘出没有偏差的因果关系，来指导算法。
 
### 1.4 符号定义
 
![](http://p8.itc.cn/q_70/images03/20201023/34285df4a17040638815b0ca971c038d.jpeg)
 
这里给出关于因果的一个比较实际的定义：变量 T 的变量 Y 的原因，变量 Y 是变量 T 的结果，当且仅当在控制其他所有变量不变时，改变 T 会引发 Y 的变化。而**因果效应**（Causal Effect）就是改变变量 T 一个单位时，变量 Y 发生改变的大小。这里的两个重点是：一、只修改 T 的值，二、保持其他变量不变。
 
![](http://p2.itc.cn/q_70/images03/20201023/08e7a1c467eb4cc58ded3d1ea80e7afa.jpeg)
 
这里给出**因果效应评估**（Causal Effect Estimation）的数学形式。以评估药物的因果效应为例，**干预变量**（Treatment Variable）T 的值为1时代表吃了药，0代表没吃药，而这对应了两者不同的潜在结果。**平均因果效应**（Average Causal Effect, ATE）就是吃药的潜在结果与不吃药的潜在结果在所有病人上的差值平均值。**个体因果效应**（Individual Causal Effect, ICE）就是吃药的潜在结果与不吃药的潜在结果在某个病人上的差值。
 
这里还涉及反事实的问题：对于某个病人，我们只能观测到他吃药或不吃药其中一种情况的结果，想要探究未发生的另一种情况的结果，就需要假象存在一个平行世界，这个世界里病人做出了与之前不同的选择，除此之外都保持完全一致，对比两个世界的结果进行求解。
 
在实际应用中，**随机化实验**（Randomized Experiments）是因果效应评估的金标准。比如在疫苗研发中，就需要做双盲实验和单盲实验以评估因果效应。在足够大的实验人群中，通过完全随机的方法使其中一半人接种疫苗，这样就排除了其他变量的影响，求得平均因果效应。这种方法在政策评估、健康医疗和市场营销等多个领域都有重要应用，但这种方法的花销巨大，且可能涉及伦理道德问题。那么我们可否在巨量的历史观测数据中进行挖掘，评估出因果效应呢？
 
![](http://p5.itc.cn/q_70/images03/20201023/374bcf917b9840078a24aa2eaf5965da.jpeg)
 
比如在一个数据集中，有吃药和未吃药的两群人。如果在数据收集时是使用单盲或双盲实验，那么就可以直接去计算平均因果效应。但如果没有保证分配药物的随机性，就可能会有体质、性别、年龄等混杂因子 X 使结果产生偏倚。因果推理的本质就是去控制吃药和不吃药的两群人之间其他特征的分布。
 
## 2. 因果效应评估的方法
 
![](http://p3.itc.cn/q_70/images03/20201023/195419e9e0924f50a50262743032e074.jpeg)
 
现在我们考虑干预变量为二值的情况，要去平衡其他变量的分布，再做因果效应评估。在这里介绍三种方法：Matching、Propensity Score Based Methods 和 Directly Confounder Balancing。
 
- 首先给出在观测数据下做因果推理的三个假设：
  - 一、Stable Unit Treatment Value(SUTV) 变量之间是独立的：我是否吃药的结果不受别人是否吃药的影响。
  - 二、Unconfounderness 所有混淆变量都被观测到了。
  - 三、Overlap 各种干预变量的取值概率都应该在0到1之间。
 
### 2.1 Matching
 
![](http://p2.itc.cn/q_70/images03/20201023/31fd0c25335b4be38ec888e86d02268a.jpeg)
 
第一种方法叫 Mathching。在两个不同的处理群体之间，逐一寻找并匹配其他特征变量都相同的个体，如果找不到就舍弃此个体，这样就可以保证有匹配的那些样本中其他特征的分布在一定范围内是相似的，进而初步去评估因果效应。
 
Matching 的问题就是如何去评估两个个体的相似度，并需要设定可以接受的差异阈值，在舍弃样本数和相似度之间进行平衡。其次对于高维数据，很难找到相似样本：比如有10个二值变量，就需要至少1025个样本才能保证找到相同个体。
 
### 2.2 Propensity Score Based Methods
 
![](http://p9.itc.cn/q_70/images03/20201023/bbfabb89f29a48aa98f9645ba8101980.jpeg)
 
第二类方法是基于倾向指数/倾向得分（Propensity Score）的。倾向指数的定义就是在干预变量之外的其他特征变量为一定值的条件下，个体被处理的概率。Rubin 证明了在给定倾向指数的情况下，Unconfounderness 假设就可以满足。倾向指数其实概括了群体的特征变量，如果两个群体的倾向指数相同，那他们的干预变量就是与其他特征变量相独立的。
 
比如说，如果能保证两群人的他吃药的概率完全一样，那么可以说这两群人其他特征分布也是一样。
 
![](http://p3.itc.cn/q_70/images03/20201023/82377c908ed14366a41456128b0e8850.jpeg)
 
倾向指数在实际应用中是观测不到的，但可以使用有监督学习的方法进行估计。根据估计到的倾向指数，第一种方法就是去做 Matching，这样能解决在高维数据中难以找到相似样本的问题。
 
![](http://p8.itc.cn/q_70/images03/20201023/c12e3f6f4c204a2d93717faad04249f8.jpeg)
 
![](http://p0.itc.cn/q_70/images03/20201023/bfd5bac5adce4f7798f8ecdc4eb355a3.jpeg)
 
![](http://p7.itc.cn/q_70/images03/20201023/a58e43d94704412cb0a9bc4600e9ebf3.jpeg)
 
第二种是使用 Inverse of Propensity Weighting 方法，对于干预变量为1的样本使用倾向指数的倒数进行加权，而对于为0的样本使用（1-倾向指数）的倒数进行加权，两类样本的加权平均值之差就是平均因果效应的大小。这里有一个假设，就是估计出的倾向指数与真实的倾向指数是相等的。
 
因此这个方法有两个弱点，一是需要对倾向指数的估计足够精确；二是如果倾向指数过于趋近0或1，就会导致某些权重的值过高，使估计出的平均因果效应的方差过大。
 
![](http://p5.itc.cn/q_70/images03/20201023/7dd746d458784ac1b14a7e70cb39e204.jpeg)
 
第三种方法叫 Doubly Robust。这个方法需要根据已有数据，再学习一个预测的模型，反事实评估某个个体在干预变量变化后，结果变量的期望值。只要倾向指数的估计模型和反事实预测模型中有一个是对的，计算出的平均因果效应就是无偏的；但如果两个模型估计都是错误的，那产生的误差可能会非常大。
 
![](http://p8.itc.cn/q_70/images03/20201023/f381c9a03e8d4e61bd8dbfc82d5a18d4.jpeg)
 
以上的这三种基于倾向指数的方法比较粗暴，把干预变量和结果变量之外的所有变量都当作混淆变量。而在高维数据中，我们需要精准地找出那些真正需要控制的混淆变量。我们提出了一种数据驱动的变量分解算法（D²VD），将干预变量和结果变量之外的其他变量分为了三类：
1. **混淆**变量（Confounders）：既会影响到干预变量，还会影响到结果变量
2. **调整**变量（Adjustment Variables）：与干预变量独立，但会影响到结果变量
3. **无关**变量：不会直接影响到干预变量与结果变量
 
进行分类之后，就可以只用混淆变量集去估计倾向指数。而调整变量集会被视为对结果变量的噪声，进行消减。最后使用经过调整的结果，去估计平均因果效应。我们从理论上证明了，使用这种方法可以得到无偏的平均因果效应估计，而且估计结果的方差不会大于 Inverse of Propensity Weighting 方法。
 
![](http://p2.itc.cn/q_70/images03/20201023/7b32806ae2754a14920f5df48350fb73.jpeg)
 
我的学生又拓展了我的工作，与表征学习相结合，提出了 Decomposed Representation。其中增加了一类变量：

4. 工具变量：与结果变量独立，但会影响到干预变量
 
通过实验发现，与传统方法相比，此方法可以很准确地把变量分离出来，提高平均因果效应的准确性。
 
![](http://p9.itc.cn/q_70/images03/20201023/5e0c1611b9fb4402a6e60f913eb404eb.jpeg)
 
### 2.3 Directly Confounder Balancing
 
总的来说，基于倾向指数的方法还是需要估计倾向指数的模型是准确的。既然倾向指数就是用于计算权重的，我们可不可以直接去估计权重呢？
 
第三类方法就是 Directly Confounder Balancing，直接对样本权重进行学习。这类方法的动机就是去控制在干预变量下其他特征变量的分布。而一个变量的所有阶的矩（moment）可以唯一确定它的分布，所以只需要去控制它所有阶的矩（比如一阶矩就是均值，二阶矩就是方差）就可了。在实验中我们发现，只考虑一阶矩就可以达到很好的效果，因此这里先不考虑二阶及以上的矩。通过这个手段就可以直接学习样本权重，进行平均因果效应估计了。
 
![](http://p2.itc.cn/q_70/images03/20201023/90f132e406c444ed92a047c1fd171284.jpeg)
 
这个概念首先出现于 Entrophy Balancing 方法之中，通过学习样本权重，使特征变量的分布在一阶矩上一致，同时还约束了权重的熵（Entropy）。但这个方法的问题也是将所有变量都同等对待了，把过多变量考虑为混杂变量。
 
![](http://p0.itc.cn/q_70/images03/20201023/fe2f9012ce0148f6af689919f650ed96.jpeg)
 
第二种方法叫 Approximate Residual Balancing。第一步也是通过计算样本权重使得一阶矩一致，第二步与 Doubly Robust 的思想一致，加入了回归模型，并在第三步结合了前两步的结果估计平均因果效应。只要样本权重的估计和反事实预测模型中有一个是对的，计算出的平均因果效应就是无偏的。但这里也是将所有变量都同等对待了。
 
![](http://p7.itc.cn/q_70/images03/20201023/daec4a16db754c18bd8603f0e7c0e890.jpeg)
 
![](http://p9.itc.cn/q_70/images03/20201023/c845c7c6a91a43a085a0a1c02fe0ee4f.jpeg)
 
我们提出的方法叫做混淆变量区分性平衡（Differentiated Confounder Balancing, DCB），考虑到的就是不同的特征变量对于平均因果效应的影响是不同的。我们在传统方法上加入了混淆变量权重（Confounder Weights）β：当β为0时，代表所对应的变量不是混淆变量，对因果效应不会带来影响；当β较大时，说明此变量对因果效应的影响较大。其中的β正好是从干预变量的增广到结果变量的回归系数。通过一系列实验发现，我们的方法在高维数据下对平均因果效应的估计偏差几乎为0，优于其他方法。
 
![](http://p2.itc.cn/q_70/images03/20201023/7eed17426c9648248047a6756bd743c0.jpeg)
 
### 2.4 Generative Adversial De-confounding
 
上述的所有方法中，干预变量都是二值的，那如何去处理多值的或者连续的干预变量呢？我们今年的一个工作 Generative Adversial De-confounding 就尝试估计这类复杂情况下干预变量与结果变量之间的因果效应。这里的核心思想就是如何保证干预变量与其他特征变量的分布相独立。我们利用了 GAN 的思想，去凭空构造出另一个干预变量与其他特征变量相独立的分布。
 
![](http://p2.itc.cn/q_70/images03/20201023/295cfe1f99ff47348fb5e610c61f1881.jpeg)
 
我们使用了随机打乱（Random Shuffle）的方法，只打乱干预变量，这样就可以使干预变量与其他特征变量相独，并保留了两者的分布。我们再使用样本权重估计的方法，使原来数据集的加权分布结果与构造出的分布相一致。在实验中，可以发现我们的方法成功降低了干预变量与其他特征变量的相关性，并有效提高了因果效应评估的准确性。
 
![](http://p1.itc.cn/q_70/images03/20201023/368e1e83dd6e4f75ada8add246a19404.jpeg)


# 因果科学实践


## 阿里飞猪广告预算分配里的因果推断技术

- 【2021-3-14】datafun 2020 [资料](https://share.weiyun.com/iq15TqNg)
- ![](https://p1.pstatp.com/large/tos-cn-i-0022/7fd84dbd0b2b4df081755f66cbc6f9c5)
- 基本思想：控制其他因子，只留一个因子
  - ①切断X→T：**随机试验**，若T的分配随机，则与任何变量独立
  - ②切断X→T和X→Y：**特征工程**，若X包含所有confounder（同时影响T和Y的变量），给定X，不同treatment group下影响Y的协变量分布一样
- ![](https://p1.pstatp.com/large/tos-cn-i-0022/87e5e67231594ca8937681135ccc3b8c)
- ![](https://p1.pstatp.com/large/tos-cn-i-0022/43a127d581bf4a6f85be14f27e214eea)

## 因果工具包

- 【2021-1-5】[awesome-causality-algorithms](https://github.com/rguo12/awesome-causality-algorithms)
- [DoWhy工具](https://github.com/microsoft/dowhy) An end-to-end library for causal inference
  - 微软的DoWhy是一个基于python的因果推理和分析库，它试图简化在机器学习应用程序中采用因果推理的过程。受到朱迪亚·珀尔的因果推理演算的启发，DoWhy在一个简单的编程模型下结合了几种因果推理方法，消除了传统方法的许多复杂性。
  - DoWhy将工作流中的任何因果推理问题建模为四个基本步骤: **建模**、**识别**、**估计**和**反驳**。
    - **模型**: DoWhy使用因果关系图对每个问题建模。DoWhy的当前版本支持两种图形输入格式:`gml`(首选)和`dot`。图中可能包含了变量之间因果关系的先验知识，但DoWhy不做任何直接的假设。
    - **标识**: 使用**输入图**，DoWhy根据图形模型找到所有可能的方法来标识期望的因果关系。它使用基于图的标准和do-calculus来寻找潜在的方法，找到能够识别因果关系的表达式
    - **估计**: DoWhy使用匹配或工具变量等统计方法估计因果效应。DoWhy的当前版本支持基于倾向性分层或倾向性评分匹配的估计方法，这些方法侧重于估计处理任务，以及侧重于估计响应面的回归技术。
    - **验证**: 最后，DoWhy使用不同的robustness methods（鲁棒性方法）验证因果效应的有效性。
  - [Jupyter notebook示例](https://github.com/microsoft/dowhy/blob/master/docs/source/example_notebooks/dowhy_simple_example.ipynb)
  - ![](https://raw.githubusercontent.com/microsoft/dowhy/master/docs/images/dowhy-schematic.png)

- [微软因果推理框架DoWhy入门](http://www.atyun.com/41349.html)
- 代码示例

```python
import numpy as np
from dowhy import CausalModel
import dowhy.datasets

# 加载数据，DoWhy依赖于panda dataframes来捕获输入数据
rvar = 1 if np.random.uniform() >0.5 else 0
data_dict = dowhy.datasets.xy_dataset(10000, effect=rvar, sd_error=0.2)
df = data_dict['df']
print(df[["Treatment", "Outcome", "w0"]].head())

# 因果推理
model= CausalModel(
  data=df,
  treatment=data_dict["treatment_name"],
  outcome=data_dict["outcome_name"],
  common_causes=data_dict["common_causes_names"],
  instruments=data_dict["instrument_names"])

model.view_model(layout="dot")

from IPython.display import Image, display
display(Image(filename="causal_model.png"))

# 确定图标中的因果关系
identified_estimand = model.identify_effect()

# 估计因果关系
estimate = model.estimate_effect(identified_estimand,
method_name="backdoor.linear_regression")
# Plot Slope of line between treamtent and outcome =causal effect
dowhy.plotter.plot_causal_effect(estimate, df[data_dict["treatment_name"]], df[data_dict["outcome_name"]])

# 反驳因果估计
res_random=model.refute_estimate(identified_estimand, estimate, method_name="random_common_cause")

```

- 结果
  - ![](http://imgcdn.atyun.com/2019/06/4-6.png)
  - ![](http://imgcdn.atyun.com/2019/06/5-5.png)


- [justcause](https://github.com/inovex/justcause)

其它工具包
1. [causalml]: causal inference with machine learning algorithms in Python
2. [DoWhy]: causal inference using graphs for identification
3. [EconML]: Heterogeneous Effect Estimation in Python
4. [awesome-list]: A very extensive list of causal methods and respective code
5. [IBM-Causal-Inference-Benchmarking-Framework]: Causal Inference Benchmarking Framework by IBM
6. [CausalNex]: Bayesian Networks to combine machine learning and domain expertise for causal reasoning.

# 资料

- [贝叶斯网络之父Judea Pearl：新因果科学与数据科学、人工智能的思考](https://www.toutiao.com/i6840890758732448270/)
- 更多[Demo地址](http://wqw547243068.github.io/demo)

# 结束


