---
layout: post
title:  "数据库及SQL-database&sql-note"
date:   2013-11-01 23:02:00
categories: 数据挖掘
tags: 数据库 SQL python pymysql sqlite redis
excerpt: 数据挖掘知识点、经验总结
author: 鹤啸九天
mathjax: true
---

* content
{:toc}

> 数据挖掘方向知识点、经验总结

# 总结

- 

# 数据库介绍


## 类型

（1）关系型数据库，是指采用了**关系模型**来组织数据的数据库。关系模型指的就是二维表格模型，而一个关系型数据库就是由二维表及其之间的联系所组成的一个数据组织。银行系统会大量的用关系数据库.比如大家经常用的MySQL就是典型的关系数据库.

优点：
- 容易理解：二维表结构是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型来说更容易理解
- 使用方便：通用的SQL语言使得操作关系型数据库非常方便
- 易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率

（2）非关系数据库

关系数据库虽然很好，但是随着互联网大规模的爆发，弱点也越来越明显，比如事务的**一致性**，**多表**联查,**高并发**等等瓶颈很明显。

于是NoSQL一词横空出世，以键值对存储，且结构不固定，每一个元组可以有不一样的字段，每个元组可以根据需要增加一些自己的键值对，这样就不会局限于固定的结构，可以减少一些时间和空间的开销。比如MongoDb就是典型的NoSQL型数据库(键值对大家想到了什么，对json格式).


# 关系型数据库 SQL

主流的数据库有Oracle,MySQL,Mongodb,Redis,SQLite，SQL Server等等

注：关系型数据库其实不擅长处理关系型数据

## SQL语法



# 非关系型数据库 NoSQL


## Redis

![](https://img.php.cn/upload/article/000/000/024/618345258e588958.jpg)

Redis是当前比较热门的NOSQL系统之一，它是一个key-value存储系统。和 Memcache 类似，但很大程度补偿了Memcache的不足，它支持存储的value类型相对更多，包括string、list、set、zset和hash。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作。在此基础上，Redis支持各种不同方式的排序。

常见的内存型数据库，除 Redis 之外，还有 Oracle Berkeley DB（甲骨文旗下的一款产品）、SQlite（轻量级内存数据库）、Memcache（键值型分布式缓存数据库）、Altibase（基于内存的高性能数据库）。

与其他内存型数据库相比，Redis 具有以下特点：
- Redis 不仅可以将数据完全保存在**内存**中，还可以通过磁盘实现数据的**持久存储**；
- Redis 支持丰富的**数据类型**，包括 string、list、set、zset、hash 等多种数据类型，因此它也被称为“数据结构服务器”；
- Redis 支持**主从**同步，即 master-slave 主从复制模式。数据可以从主服务器向任意数量的从服务器上同步，有效地保证数据的安全性；
- Redis 支持多种编程语言，包括 C、C++、Python、Java、PHP、Ruby、Lua 等语言。

与 SQL 型数据库截然不同，Redis 没有提供新建数据库的操作，因为它自带了 **16** （0—15）个数据库（默认使用 0 库）。在同一个库中，key 是唯一存在的、不允许重复的，它就像一把“密钥”，只能打开一把“锁”。键值存储的本质就是使用 key 来标识 value，当想要检索 value 时，必须使用与 value 相对应的 key 进行查找。

Redis 数据库**没有“表”的概念**，它通过不同的数据类型来实现存储数据的需求，不同的数据类型能够适应不同的应用场景，从而满足开发者的需求。

Redis 的优势进行了简单总结：
- **性能极高**：Redis 基于内存实现数据存储，它的读取速度是 110000次/s，写速度是 81000次/s；
- **多用途**工具： Redis 有很多的用途，比如可以用作缓存、消息队列、搭建 Redis 集群等；
- 命令**提示**功能：Redis 客户端拥有强大的命令提示功能，使用起来非常的方便，降低了学习门槛；
- 可移植性：Redis 使用用标准 C语言编写的，能够在大多数操作系统上运行，比如 Linux，Mac，Solaris 等。


Redis与其他数据库对比

|名称	|类型	|数据存储选项	|附加功能|
|---|---|---|---|
|Redis	|基于内存存储的键值非关系型数据库|	字符串、列表、散列、有序集合、无序集合|	发布与订阅、主从复制、持久化存储等|
|Memcached	|基于内存存储的键值缓存型数据库|	键值之间的映射|	为提升性能构建了多线程服务器|
|MySQL	|基于磁盘的关系型数据库|	每个数据库可以包含多个表，每个表可以包含多条记录；支持第三方扩展。|	支持 ACID 性质、主从复制和主主复制|
|MongoDB	|基于磁盘存储的非关系文档型数据库|	每个数据库可以包含多个集合，每个集合可以插入多个文档	|支持聚合操作、主从复制、分片和空间索引|

Redis 不适合存储较大的文件或者二进制数据，否则会出现错误，Redis 适合存储较小的文本信息。理论上 Redis 的每个 key、value 的大小不超过 512 MB。

### 安装

linux中安装：[Linux 安装 Redis](https://www.redis.com.cn/linux-install-redis.html)

```shell
wget http://download.redis.io/redis-stable.tar.gz
tar xzf redis-6.0.8.tar.gz
cd redis-6.0.8
make
# 启动服务
cd src
./redis-server # 默认配置
./redis-server ../redis.conf # 指定配置

# 客户端连接
redis-cli
redis-cli -h host -p port -a password
# redis> set foo bar
# OK
# redis> get foo
# "bar"
```

执行完 make 命令后，redis-6.0.8 目录下会出现编译后的 redis 服务程序 **redis-server**，还有用于测试的客户端程序 **redis-cli**，两个程序位于安装目录 src 目录下
- 配置 Redis 为后台服务 将配置文件中的 daemonize no 改成 daemonize yes，配置 redis 为后台启动。
- Redis 设置访问密码 在配置文件中找到 requirepass，去掉前面的注释，并修改后面的密码。

常用配置文件例子 redis.conf

```shell
#默认端口6379
port 6379
#绑定ip，如果是内网可以直接绑定 127.0.0.1, 或者忽略, 0.0.0.0是外网
bind 0.0.0.0
#守护进程启动
daemonize yes
#超时
timeout 300
loglevel notice
#分区
databases 16
save 900 1
save 300 10
save 60 10000
rdbcompression yes
#存储文件
dbfilename dump.rdb
#密码 abcd123
requirepass abcd123
```

### 数据类型

[文档](http://c.biancheng.net/redis/strings.html)

Redis 为了存储不同类型的数据，提供了五种常用数据类型，如下所示：
- string（字符串）: 二进制安全（binary safe）特性，长度是已知的，不由任何其他终止字符决定的，一个字符串类型的值最多能够存储 512 MB 的内容
- hash（哈希散列）: 由字符串类型的 field 和 value 组成的映射表；一个 Hash 中最多包含 2^32-1 个键值对。
- list（列表）： List 中的元素是字符串类型，其中的元素按照插入顺序进行排列，允许重复插入，最多可插入的元素个数为 2^32 -1 个（大约40亿个），可以添加一个元素到列表的头部（左边）或者尾部（右边）。
- set（集合）：字符串类型元素构成的无序集合。在 Redis 中，集合是通过哈希映射表实现的，所以无论是添加元素、删除元素，亦或是查找元素，它们的时间复杂度都为 O(1)。
  - 集合成员具有唯一性，所以重复插入元素不会成功，集合的同样可容纳  2^32 -1 个元素
- zset（sorted set：有序集合）：有序集合，集合中的元素不仅具有唯一性，而且每个元素还会关联一 个 double 类型的分数，该分数允许重复。Redis 正是通过这个分数来为集合中的成员排序。
除了上述五种类型之外，Redis 还支持 HyperLogLog 类型，以及 Redis 5.0 提供的 Stream 类型。

Redis 允许为 key 设置一个过期时间（使用 EXPIRE 等命令），也就是“到点自动删除”，这在实际业务中是非常有用的，一是它可以避免使用频率不高的 key 长期存在，从而占用内存资源；二是控制缓存的失效时间。

```shell
# 设置一个值
set test 123
type test # 查看key类型，string
# 一次设置多个值
mset x 34 y 22
# 查询某个key
get test
# 查询多个key
mget x y
del x # 删除key

# 设置散列key：user1
HMSET user1 username xiaoming password 123456 website www.biancheng.net
# 获取散列值
hgetall user1

# list
LPUSH z Java
LPUSH z C
LPUSH z B
LRANGE z 0 6 # 查看 前6个元素

# set
SADD s JAVA # 插入元素
SADD s HTML
SMEMBERS s # 查看集合元素

# 有序集合
zadd t 0 Python
zadd t 1 java
zadd t 1 php
ZSCORE t Redis # 查看元素分数值
zrange biancheng 0 4 # 查看所有成员

# ---------
expire test 2 # 设置test过期时间（s）
exist test # key是否存在
dump test # 序列化
keys te* # 寻找匹配的key
RANDOMKEY # 随机返回一个key
rename test new # 重命名
move test 2 # key移动到指定库

```

### redis集群架构

几种模式
- 主从模式
- 哨兵模式

#### 主从模式

[Redis Cluster主从模式详解](http://c.biancheng.net/redis/slaveof.html)

软件架构中，**主从**模式（Master-Slave）是使用较多的一种架构。**主**（Master）和**从**（Slave）分别部署在不同的服务器上，当主节点服务器写入数据时，同时也会将数据同步至从节点服务器，通常情况下，主节点负责写入数据，而从节点负责读取数据。
- ![](http://c.biancheng.net/uploads/allimg/210913/16133214H-0.gif)
- Redis 主机会一直将自己的数据复制给 Redis 从机，从而实现主从同步。在这个过程中，只有 master 主机可执行**写**命令，其他 salve 从机只能只能执行**读**命令，这种**读写分离**的模式可以大大减轻 Redis 主机的数据读取压力，从而提高了Redis 的效率，并同时提供了多个数据备份。
主从模式是搭建 Redis Cluster 集群最简单的一种方式。

主从模式并不完美，它也存在许多不足之处，下面做了简单地总结：
- 1) Redis 主从模式不具备**自动容错和恢复**功能，如果主节点宕机，Redis 集群将无法工作，此时需要人为干预，将从节点提升为主节点。
- 2) 如果主机宕机前有一部分数据未能及时同步到从机，即使切换主机后也会造成数据不一致的问题，从而降低了系统的可用性。
- 3) 因为只有**一个主节点**，所以其写入能力和存储能力都受到一定程度地限制。
- 4) 在进行数据**全量同步**时，若同步的数据量较大可能会造卡顿的现象。

#### 哨兵模式

- Redis **主从**模式不具备自动恢复的功能，所以当**主服务器**（master）宕机后，需要手动把一台**从服务器**（slave）切换为主服务器。在这个过程中，不仅需要人为干预，而且还会造成一段时间内服务器处于不可用状态，同时数据安全性也得不到保障，因此主从模式的可用性较低，不适用于线上生产环境。
- Redis Sentinel **哨兵**模式（官方推荐），弥补了主从模式的不足。Sentinel 通过监控的方式获取主机的工作状态是否正常，当主机发生故障时， Sentinel 会自动进行 Failover（即**故障转移**），并将其监控的**从机**提升**主服务器**（master），从而保证了系统的高可用性。

哨兵模式是一种特殊的模式，Redis 为其提供了专属的哨兵命令，它是一个独立的进程，能够独立运行。下面使用 Sentinel 搭建 Redis 集群，基本结构图如下所示：
- ![](http://c.biancheng.net/uploads/allimg/210913/1K00M955-0.gif)
哨兵主要有两个重要作用：
- 第一：哨兵节点会以每秒一次的频率对每个 Redis 节点发送PING命令，并通过 Redis 节点的回复来判断其运行状态。
- 第二：当哨兵监测到主服务器发生故障时，会自动在从节点中选择一台将机器，并其提升为主服务器，然后使用 PubSub 发布订阅模式，通知其他的从节点，修改配置文件，跟随新的主服务器。
Redis Sentinel 是集群的高可用的保障，为避免 Sentinel 发生意外，一般是由 3～5 个节点组成
- ![](http://c.biancheng.net/uploads/allimg/210913/1K00HQ5-1.gif)
- Sentinel 负责监控主从节点的“健康”状态。当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接 Redis 集群时，会首先连接 Sentinel，通过 Sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 Sentinel 要地址，Sentinel 会将最新的主节点地址告诉客户端。因此应用程序无需重启即可自动完成主从节点切换。

多个哨兵之间也存在互相监控，这就形成了多哨兵模式，现在对该模式的工作过程进行讲解，介绍如下：
- 1) **主观**下线
  - 主观下线，适用于主服务器和从服务器。如果在规定的时间内(配置参数：down-after-milliseconds)，Sentinel 节点没有收到目标服务器的有效回复，则判定该服务器为“主观下线”。比如 Sentinel1 向主服务发送了PING命令，在规定时间内没收到主服务器PONG回复，则 Sentinel1 判定主服务器为“主观下线”。
- 2) **客观**下线
  - 客观下线，只适用于主服务器。 Sentinel1 发现主服务器出现了故障，它会通过相应的命令，询问其它 Sentinel 节点对主服务器的状态判断。如果超过半数以上的  Sentinel 节点认为主服务器 down 掉，则 Sentinel1 节点判定主服务为“客观下线”。
- 3) **投票选举**
  - 投票选举，所有 Sentinel 节点会通过投票机制，按照谁发现谁去处理的原则，选举 Sentinel1 为领头节点去做 Failover（故障转移）操作。Sentinel1 节点则按照一定的规则在所有从节点中选择一个最优的作为主服务器，然后通过发布订功能通知其余的从节点（slave）更改配置文件，跟随新上任的主服务器（master）。至此就完成了主从切换的操作。

#### 消息队列 Stream （redis 5）

[Redis Stream消息队列](http://c.biancheng.net/redis/streams.html)

Stream 实际上是一个具有消息发布/订阅功能的组件，也就常说的**消息队列**。其实这种类似于 broker/consumer(生产者/消费者)的数据结构很常见，比如 RabbitMQ 消息中间件、Celery 消息中间件，以及 Kafka 分布式消息系统等，而 Redis Stream 正是借鉴了 Kafaka 系统。

Stream 除了拥有很高的性能和内存利用率外, 最大的特点就是提供了消息的**持久化**存储，以及**主从复制**功能，从而解决了网络断开、Redis 宕机情况下，消息丢失的问题，即便是重启 Redis，存储的内容也会存在。

Stream 消息队列主要由四部分组成，分别是：消息本身、生产者、消费者和消费组
- 一个 Stream 队列可以拥有多个消费组，每个消费组中又包含了多个消费者，组内消费者之间存在竞争关系。当某个消费者消费了一条消息时，同组消费者，都不会再次消费这条消息。被消费的消息 ID 会被放入等待处理的 Pending_ids 中。每消费完一条信息，消费组的游标就会向前移动一位，组内消费者就继续去争抢下消息。

Redis Stream 消息队列结构
- ![](http://c.biancheng.net/uploads/allimg/210913/15253613F-0.gif)

简单解释：
- Stream direction：表示数据流，它是一个消息链，将所有的消息都串起来，每个消息都有一个唯一标识 ID 和对应的消息内容（Message content）。
- Consumer Group ：表示消费组，拥有唯一的组名，使用 XGROUP CREATE 命令创建。一个 Stream 消息链上可以有多个消费组，一个消费组内拥有多个消费者，每一个消费者也有一个唯一的 ID 标识。
- last_delivered_id ：表示消费组游标，每个消费组都会有一个游标 last_delivered_id，任意一个消费者读取了消息都会使游标 last_delivered_id - 往前移动。
- pending_ids ：Redis 官方称为 PEL，表示消费者的状态变量，它记录了当前已经被客户端读取的消息 ID，但是这些消息没有被 ACK(确认字符)。如果客户端没有 ACK，那么这个变量中的消息 ID 会越来越多，一旦被某个消息被 ACK，它就开始减少。

创建消息
- Redis Stream通过XGROUP CREATE指令创建消费组(Consumer Group)，在创建时，需要传递起始消息的 ID 用来初始化 last_delivered_id 变量。

消费消息
- Redis Stream 通过XREADGROUP命令使消费组消费信息，它和XREAD命令一样，都可以阻塞等待新消息。读到新消息后，对应的消息 ID 就会进入消费者的 PLE（正在处理的消息）结构里，客户端处理完毕后使用 XACK 命令通知 Redis 服务器，本条消息已经处理完毕，该消息的 ID 就会从 PEL 中移除。
- ![](http://c.biancheng.net/uploads/allimg/210913/1525361596-1.gif)

常用命令

| 命令 |	说明|
|---|---|
| XADD |	添加消息到末尾。|
| XTRIM |	对|
| XDEL |	删除指定的消息。|
| XLEN |	获取流包含的元素数量，即消息长度。|
| XRANGE |	获取消息列表，会自动过滤已经删除的消息。|
| XREVRANGE |	反向获取消息列表，ID|
| XREAD |	以阻塞或非阻塞方式获取消息列表。|
| XGROUP |	CREATE|
| XREADGROUP |	GROUP|
| XACK |	将消息标记为"已处理"。|
| XGROUP |	SETID|
| XGROUP |	DELCONSUMER|
| XGROUP |	DESTROY|
| XPENDING |	显示待处理消息的相关信息。|
| XCLAIM |	转移消息的归属权。|
| XINFO |	查看|
| XINFO |	GROUPS|
| XINFO |	STREAM|
| XINFO |	CONSUMERS|

#### 布隆过滤器（redis 4）

布隆过滤器（Bloom Filter）是一个高空间利用率的概率性数据结构，由二进制向量（即位数组）和一系列随机映射函数（即哈希函数）两部分组成。

布隆过滤器使用exists()来判断某个元素是否存在于自身结构中。当布隆过滤器判定某个值存在时，其实这个值只是有可能存在；当它说某个值不存在时，那这个值肯定不存在，这个误判概率大约在 1% 左右。

工作流：
- ![](http://c.biancheng.net/uploads/allimg/210913/152TA292-0.gif)

布隆过滤器（Bloom Filter）是 Redis 4.0 版本提供的新功能，它被作为插件加载到 Redis 服务器中，给 Redis 提供强大的去重功能。

相比于 Set 集合的去重功能而言，布隆过滤器在**空间**上能节省 **90%** 以上，但是它的不足之处是去重率大约在 **99%** 左右，也就是说有 1% 左右的误判率，这种误差是由布隆过滤器的自身结构决定的。俗话说“鱼与熊掌不可兼得”，如果想要节省空间，就需要牺牲 1% 的误判率，而且这种误判率，在处理海量数据时，几乎可以忽略。

常用命令

| 命令 |	说明|
|---|---|
| bf.add |	只能添加元素到布隆过滤器。|
| bf.exists |	判断某个元素是否在于布隆过滤器中。|
| bf.madd |	同时添加多个元素到布隆过滤器。|
| bf.mexists |	同时判断多个元素是否存在于布隆过滤器中。|
| bf.reserve |	以自定义的方式设置布隆过滤器参数值，共有|


```python
import redis
size=10000
r = redis.Redis()
count = 0
for i in range(size):
    #添加元素，key为userid，值为user0...user9999
    r.execute_command("bf.add", "userid", "user%d" % i)
    #判断元素是否存在，此处切记 i+1
    res = r.execute_command("bf.exists", "userid", "user%d" % (i + 1))
    if res == 1:
        print(i)
        count += 1
#求误判率，round()中的5表示保留的小数点位数
print("size: {} ,error rate:{}%".format(size, round(count / size * 100, 5)))
```

#### 分布式锁

在分布式系统中，当不同进程或线程一起访问共享资源时，会造成资源争抢，如果不加以控制的话，就会引发程序错乱。此时使用分布式锁能够非常有效的解决这个问题，它采用了一种互斥机制来防止线程或进程间相互干扰，从而保证了数据的一致性。

分布式锁并非是 Redis 独有，比如 MySQL 关系型数据库，以及 Zookeeper 分布式服务应用，它们都实现分布式锁，只不过 Redis 是基于缓存实现的。

[Redis分布式锁](http://c.biancheng.net/redis/distributed-lock.html)有很对应用场景，举个简单的例子，比如春运时，您需要在 12306 上抢购回家火车票，但 Redis 数据库中只剩一张票了，此时有多个用户来预订购买，那么这张票会被谁抢走呢？Redis 服务器又是如何处理这种情景的呢？在这个过程中就需要使用分布式锁。

Redis 分布式锁主要有以下特点：
- 第一：互斥性是分布式锁的重要特点，在任意时刻，只有一个线程能够持有锁；
- 第二：锁的超时时间，一个线程在持锁期间挂掉了而没主动释放锁，此时通过超时时间来保证该线程在超时后可以释放锁，这样其他线程才可以继续获取锁；
- 第三：加锁和解锁必须是由同一个线程来设置；
- 第四：Redis 是缓存型数据库，拥有很高的性能，因此加锁和释放锁开销较小，并且能够很轻易地实现分布式锁。


#### 缓存问题

在实际的业务场景中，Redis 一般和其他数据库搭配使用，用来减轻后端数据库的压力，比如和关系型数据库 MySQL 配合使用。
- Redis 会把 MySQL 中经常被查询的数据缓存起来，比如热点数据，这样当用户来访问的时候，就不需要到 MySQL 中去查询了，而是直接获取 Redis 中的缓存数据，从而降低了后端数据库的读取压力。如果说用户查询的数据 Redis 没有，此时用户的查询请求就会转到 MySQL 数据库，当 MySQL 将数据返回给客户端时，同时会将数据缓存到 Redis 中，这样用户再次读取时，就可以直接从 Redis 中获取数据。
- ![](http://c.biancheng.net/uploads/allimg/210913/1K924O02-0.gif)

用 Redis 作为缓存数据库的过程中，有时会遇到一些棘手问题，比如常见缓存**穿透**、缓存**击穿**和缓存**雪崩**等问题
- （1）缓存**穿透**：当用户查询某个数据时，Redis 中不存在该数据，也就是缓存没有命中，此时查询请求就会转向持久层数据库 MySQL，结果发现 MySQL 中也不存在该数据，MySQL 只能返回一个空对象，代表此次查询失败。如果这种类请求非常多，或者用户利用这种请求进行恶意攻击，就会给 MySQL 数据库造成很大压力，甚至于崩溃，这种现象就叫缓存穿透。解决方法：
  - ① 缓存空对象：当 MySQL 返回空对象时， Redis 将该对象缓存起来，同时为其设置一个过期时间
  - ② 布隆过滤器：布隆过滤器判定不存在的数据，那么该数据一定不存在。首先将用户可能会访问的热点数据存储在布隆过滤器中（也称缓存预热），当有一个用户请求到来时会先经过布隆过滤器，如果请求的数据，布隆过滤器中不存在，那么该请求将直接被拒绝，否则将继续执行查询。相较于第一种方法，用布隆过滤器方法更为高效、实用
    - ![](http://c.biancheng.net/uploads/allimg/210913/1K924O21-1.gif)
- （2）缓存**击穿**：用户查询的数据缓存中不存在，但是后端数据库却存在，这种现象原因是一般是由缓存中 **key 过期**导致的。比如一个热点数据 key，它无时无刻都在接受大量的并发访问，如果某一时刻这个 key 突然失效了，就致使大量的并发请求进入后端数据库，导致其压力瞬间增大。这种现象被称为缓存击穿。解决方法：
  - ① 改变过期时间：设置热点数据永不过期。
  - ② 分布式锁：上锁、解锁
- （3）缓存**雪崩**：缓存中大批量的 key **同时过期**，而此时数据访问量又非常大，从而导致后端数据库压力突然暴增，甚至会挂掉，这种现象被称为缓存雪崩。它和缓存击穿不同，缓存击穿是在并发量特别大时，某一个热点 key 突然过期，而缓存雪崩则是大量的 key 同时过期，因此它们根本不是一个量级。解决方案
  - 缓存雪崩和缓存击穿有相似之处，所以也可以采用热点数据永不过期的方法，来减少大批量的 key 同时过期。再者就是为 key 设置随机过期时间，避免 key 集中过期。

### redis可视化

[总结分享几款实用Redis可视化工具](https://www.php.cn/redis/483824.html)

- （1）命令行工具
  - [iredis](https://iredis.io/), 利用iredis，用\|将redis通过pipe用shell的其他工具，比如jq/fx/rg/sort/uniq/cut/sed/awk等处理。还能自动补全，高亮显示，功能很多。
- （2）桌面软件
  - [Redis Desktop Manager](https://redisdesktop.com/) 使用率最广的可视化工具。存在时间很久。经过了数次迭代。跨平台支持。以前是免费的，现在为收费工具。试用可以有半个月的时间。
    - key的显示可以支持按冒号分割的键名空间，除了基本的五大数据类型之外，还支持redis 5.0新出的Stream数据类型。在value的显示方面。支持多达9种的数据显示方式。
  - [medis](http://getmedis.com/), 界面符合个人审美。布局简洁。跨平台支持，关键是免费。
    - 颜值挺高，功能符合日常使用要求。对key有颜色鲜明的图标标识。在key的搜索上挺方便的，可以模糊搜索出匹配的key，渐进式的scan，无明显卡顿。在搜索的体验上还是比较出色的。
    - 缺点是不支持key的命名空间展示，不支持redis 5.0的stream数据类型，命令行比较单一，不支持自动匹配和提示。支持的value的展现方式也只有3种
  - [RedisPlus](https://gitee.com/MaxBill/RedisPlus): 一款开源的免费桌面客户端软件。
  - Another Redis Desktop Manager：一款比较稳定简洁的redis UI工具 。
    - [GitHub 地址](https://github.com/qishibo/AnotherRedisDesktopManager)
- （3）Web软件
  - Redis Insight: redis labs出的一款监控分析级别的redis可视化工具。这款软件是web版的。redis labs创立于2011年，公司致力于为Redis、Memcached等流行的NoSQL开源数据库提供云托管服务, 专门致力于redis云的一家专业公司。除了可以连接企业私有的redis服务，也可以连接他们的redis云。
  - 基于浏览器的管理界面检查Redis数据，监视运行状况并执行运行时服务器配置，以进行Redis部署
  - ![](https://img.ifuntools.cn/images/1575208443700.png)

探索您的Redis数据并与之交互 使用基于Web的CLI扫描和查看您的Redis密钥并执行CRUD操作。

官网地址：https://redislabs.com/redisinsight/


### Python使用redis

安装：pip install redis

redis 模块采用了两种连接模式：**直接**模式和**连接池**模式
- 连接池模式：redis 模块使用 connection pool（连接池）来管理 redis server 的所有连接，每个 Redis 实例都会维护一个属于自己的连接池，这样做的目的是为了减少每次连接或断开的性能消耗。
- 连接池的作用：当有新的客户端请求连接时，只需要去连接池获取一个连接即可，实际上就是把一个连接共享给多个客户端使用，这样就节省了每次连接所耗费的时间。

```python
import redis

# 本地连接，创建数据库连接对象
#    db 表示当前选择的库，其参数值可以是 0-15；如果设置连接数据库的密码，那么就需要使用 password 进行验证，否则可以省略。
# ----- 直接连接 ------
r = redis.Redis(host='127.0.0.1', port=6379, db=0, password='123456')
# ----- 连接池 -------
#创建连接池并连接到redis，并设置最大连接数量;
conn_pool = redis.ConnectionPool(host='127.0.0.1',port=6379,max_connections=10)
# 第一个客户端访问
re_pool = redis.Redis(connection_pool=conn_pool)
# 第二个客户端访问
re_pool2 = redis.Redis(connection_pool=conn_pool)

# ----- 字符串 ------
print(r.keys('*'))
key_list = r.keys('*')
#转换为字符串
for key in key_list:
  print(key.decode())
#查看key类型
print(r.type('webname'))
# 返回值: 0 或者 1
print(r.exists('username'))
# 删除key
r.delete('webname')
if "age"  in key_list:
    print("删除失败")
else:
    print("删除成功")

# ----- 列表 ------
r.lpush('database','sql','mysql','redis')
r.linsert('database','before','mysql',',mongodb')
print(r.llen('database'))
print(r.lrange('database',0,-1))
print(r.rpop('database'))
#保留指定区间内元素，返回True
print(r.ltrim('database',0,1))
while True:
  # 如果列表中为空时,则返回None
  result = r.brpop('database',1)
  if result:
      print(result)
  else:
      break
r.delete('database')

# ------- 散列 ------
# 1、更新一条数据的value，若不存在时，则新建这条数据
hset(key, field, value)
# 2、读取数据的指定字段属性，返回值为字符串类型
hget(key, field)
# 3、批量更新字段属性,参数mapping为字典类型
hmset(key, mapping)
# 4、批量读取数据的字段属性
hmget(key, fields)
# 5、获取这条数据的所有属性字段和对应的值，返回值为字典类型
hgetall(key)
# 6、获取这条数据的所有属性字段，返回值为列表类型
hkeys(key)
# 7、删除这条数据的指定字段
hdel(key, field)

# 设置一条数据
r.hset('user1','name','www.baidu.com')
# 更新数据
r.hset('user1','name','www.biancheng.net')
# 获取数据
print(r.hget('user1','name'))
# 一次性设置多个field和value
user_dict = {
  'password':'123',
  'gender':'M',
  'height':'175cm'
}
r.hmset('user1',user_dict)
# 获取所有数据,字典类型
print(r.hgetall('user1'))
# 获取所有fields字段和所有values值
print(r.hkeys('user1'))
print(r.hvals('user1'))

# ---- 集合 -----
#1、给name对应的集合中添加元素
sadd(name,values)
r.sadd("set_name","tom")
r.sadd("set_name","tom","jim")
​
#2、获取name对应的集合的所有成员
smembers(name)
r.smembers('set_name')
​
#3、获取name对应的集合中的元素个数
scard(name)
r.scard("set_name")
​
#4、检查value是否是name对应的集合内的元素，返回值为True或False
sismember(name, value)
r.sismember('set_name','tom')
​
#5、随机删除并返回指定集合的一个元素
spop(name)
member = r.spop('set_name')
​
#6、删除集合中的某个元素
srem(name, value)
r.srem("set_name", "tom")
​
#7、获取多个name对应集合的交集
sinter(keys, *args)
r.sadd("set_name","a","b")
r.sadd("set_name1","b","c")
r.sadd("set_name2","b","c","d")
​
print(r.sinter("set_name","set_name1","set_name2"))
#输出:｛b'b'｝
​
#8、获取多个name对应的集合的并集
sunion(keys, *args)
r.sunion("set_name","set_name1","set_name2")
```


# 工程实践

## Python数据库操作

没有Python DB API之前，接口程序混乱。Python分别于数据库（MySQL/Oracle/SQLServer）交互
- ![](https://images2017.cnblogs.com/blog/1048215/201801/1048215-20180117220059787-746351865.png)
当应用程序想切换不同的的数据库时，由于程序接口的混乱所带来的代价是非常大的。为此，Python 官方规范访问数据库的接口，防止在使用不同数据库时造成的问题。这个官方规范的接口叫做 Python DB API 。该接口的说明文档
- ![](https://images2017.cnblogs.com/blog/1048215/201801/1048215-20180117220117896-339776325.png)
Python DB API包含的内容. API中主要的模块如下
- （1）Connection
  - 参数信息：db_connection = pymysql.connect(host='127.0.0.1', user='xxxx', password='xxxx', database='python2test', charset='utf8')
  - 支持的方法：cursor(), commit(), rollback(), close()
- （2）Cursor: 游标对象：用于执行查询和获取结果
  - 执行SQL将结果从数据库获取到客户端的过程
    - ![](https://images2017.cnblogs.com/blog/1048215/201801/1048215-20180117220305521-36664649.png)
  - 支持的方法：execute(), fetchone(), fetchmany(), fetchall(), rowcount(), close()
    - ![](https://images2017.cnblogs.com/blog/1048215/201801/1048215-20180117220318178-1845492928.png)
- （3）Exceptions
各模块的作用:
- ![](https://images2017.cnblogs.com/blog/1048215/201801/1048215-20180117220143396-1740022108.png)
Python DB API访问数据库流程：
- ![](https://images2017.cnblogs.com/blog/1048215/201801/1048215-20180117220156037-994551768.png)

Python DB-API使用流程也非常简单：
- a).引入 API 模块
- b).获取与数据库的连接
- c).执行相关的语句进行查询，搜索和存储过程
- d).关闭数据库连接
![](https://pic1.zhimg.com/80/v2-b93743ec29973c460180df5c884271e8_720w.png)

pymysql 和 MySQLdb（仅python2）
- pymysql 是在 Python3.x 和 2.x 版本中用于连接 MySQL 服务器的一个库，Python2中则使用mysqldb。
- pymysql 遵循 Python 数据库 API v2.0 规范，并包含了 pure-Python MySQL 客户端库。下面便以 pymysql 为例，对于其他数据库同样的有着 pysql、pymongo 等等。
- pymysql [下载地址](https://github.com/PyMySQL/PyMySQL)
- 安装：pip install pymysql



## SQLite——Python内置

SQLite是一种用C写的小巧的嵌入式数据库，它的数据库就是一个文件。SQLite 不需要一个单独的服务器进程或操作的系统，不需要配置，这意味着不需要安装或管理，所有的维护都来自于SQLite 软件本身。

### 可视化管理

[参考](https://zhuanlan.zhihu.com/p/28058586), DB Browser for SQLite
- ![](https://pic2.zhimg.com/80/v2-ca28f22c91c989898f9656bbf84f6275_720w.png)

免费可视化工具

|工具名|介绍|下载|备注|
|---|---|---|---|
|[sqliteStudio](https://sqlitestudio.pl/)|开源，支持多平台|[下载](https://github.com/pawelsalawa/sqlitestudio/releases)||
|[DB Browser](https://sqlitebrowser.org/)|开源，支持多平台|[下载](https://sqlitebrowser.org/dl/)||
|[SQLPro](https://www.sqlitepro.com/)|开源，只支持mac OS|||
|[Sqlite Expert](http://www.sqliteexpert.com/download.html)|有开原版，支持 Windows|||

### 命令行

```shell
.tables # 显示表
select * from demo; # sql语句一定以;结尾
```

### 代码

```python
import sqlite3 

# 创建与数据库的连接 
# - 数据库文件的格式是test.db，如果该数据库文件不存在，那么它会被自动创建。
# - 返回一个Connection对象
conn = sqlite3.connect('test.db') # 文件形式的数据库
conn = sqlite3.connect(':memory:')  # 内存中创建数据库
#创建一个游标 cursor 
cur = conn.cursor() 

# 建表的sql语句 
sql_text_1 = '''CREATE TABLE scores 
           (姓名 TEXT, 
            班级 TEXT, 
            性别 TEXT, 
            语文 NUMBER, 
            数学 NUMBER, 
            英语 NUMBER);''' 
# 执行sql语句 
cur.execute(sql_text_1) 
# 插入单条数据 
sql_text_2 = "INSERT INTO scores VALUES('A', '一班', '男', 96, 94, 98)" 
cur.execute(sql_text_2) 
# 插入多条数据
data = [('B', '一班', '女', 78, 87, 85), 
        ('C', '一班', '男', 98, 84, 90), 
        ] 
cur.executemany('INSERT INTO scores VALUES (?,?,?,?,?,?)', data) 
# 连接完数据库并不会自动提交，所以需要手动 commit 你的改动conn.commit() 

# 查询数学成绩大于90分的学生 
sql_text_3 = "SELECT * FROM scores WHERE 数学>90" 
cur.execute(sql_text_3) 
# 获取查询结果 
cur.fetchall() # .fetchone()方法(获取第一条)

# 提交改动的方法：对数据库做改动后(比如建表、插数等)，都需要手动提交改动，否则无法将数据保存到数据库。
conn.commit() 

# 使用完数据库之后，需要关闭游标和连接
cur.close() # 关闭游标 
conn.close() # 关闭连接

```

## MySQL

[Python数据库编程(MySQL)](https://www.cnblogs.com/weizt/p/8432734.html)

Python查询Mysql使用 fetchone() 方法获取单条数据, 使用fetchall() 方法获取多条数据。
- fetchone(): 该方法获取下一个查询结果集。结果集是一个对象
- fetchall(): 接收全部的返回结果行.
- rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。

事务机制可以确保数据一致性。

事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。
- 原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。
- 一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。
- 隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
- 持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。

Python DB API 2.0 的事务提供了两个方法 commit 或 rollback。Python数据库编程中，当游标建立之时，就自动开始了一个隐形的数据库事务。
- commit()方法游标的所有更新操作
- rollback（）方法回滚当前游标的所有操作。
每一个方法都开始了一个新的事务。

### 代码

```python
# -*- coding: utf-8 -*-

import pymysql

# ------ 连接 ------
db = pymysql.connect(
                    host='127.0.0.1',
                    user='XXXX',
                    password='XXXX',
                    database='python2test',
                    charset='utf8'
                    )

# 使用 cursor() 方法创建一个游标对象 cursor
cursor = db.cursor()

# -------- 创建 --------
# 使用 execute() 方法执行 SQL，如果表存在则删除
cursor.execute("DROP TABLE IF EXISTS EMPLOYEE")

# 使用预处理语句创建表
sql = """CREATE TABLE EMPLOYEE (
            FIRST_NAME  CHAR(20) NOT NULL,
            LAST_NAME   CHAR(20),
            AGE         INT,
            SEX         CHAR(1),
            INCOME      FLOAT
            )"""

cursor.execute(sql)

# -------- 插入 ---------
# SQL 插入语句
sql = """INSERT INTO EMPLOYEE(FIRST_NAME,
         LAST_NAME, AGE, SEX, INCOME)
         VALUES ('Mac', 'Mohan', 20, 'M', 2000)"""
try:
    # 执行sql语句
    cursor.execute(sql)
    # 提交到数据库执行
    db.commit()
    print("插入成功！")
except:
    # 如果发生错误则回滚
    db.rollback()
    print("插入失败！")

# --------- 更新 -----------
# SQL 更新语句
sql = "UPDATE EMPLOYEE SET INCOME = INCOME * 1.2 WHERE SEX = '%c'" % ('M')
try:
    # 执行SQL语句
    cursor.execute(sql)
    # 提交到数据库执行
    db.commit()
except:
    # 发生错误时回滚
    db.rollback()

# ----------- 查询 ----------
# SQL 查询语句
sql = "SELECT * FROM EMPLOYEE \
       WHERE INCOME > '%d'" % (1000)
try:
    # 执行SQL语句
    cursor.execute(sql)
    # 获取所有记录列表
    results = cursor.fetchall()
    print("FIRST_NAME\tLAST_NAME\tAGE\tSEX\tINCOME |")
    for row in results:
        fname = row[0]
        lname = row[1]
        age = row[2]
        sex = row[3]
        income = row[4]
        # 打印结果
        print("%s\t\t\t%s\t\t\t%d\t%s\t%d" %
              (fname, lname, age, sex, income))
except:
    print("Error: unable to fetch data")

# ----------- 删除 -----------
# SQL 删除语句
sql = "DELETE FROM EMPLOYEE WHERE AGE > '%d'" % (20)
try:
    # 执行SQL语句
    cursor.execute(sql)
    # 提交修改
    db.commit()
except:
    # 发生错误时回滚
    db.rollback()

#  ---------- 关闭 ----------
db.close()
```



# 结束


