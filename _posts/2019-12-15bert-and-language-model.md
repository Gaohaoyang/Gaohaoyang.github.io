---
layout: post
title:  BERT及预训练语言模型-BERT-and-Language-Model
date:   2019-12-10 16:52:00
categories: 深度学习 
tags: 深度学习 自然语言处理 NLP Transformer BERT GPT Attention 
excerpt: Attention is all you need!
mathjax: true
---

# BERT及预训练语言模型



- [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html),Harvard NLP出品，含pytorch版代码实现
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Transformer模型的PyTorch实现](https://luozhouyang.github.io/transformer/),[A PyTorch implementation of the Transformer model in "Attention is All You Need"](https://github.com/jadore801120/attention-is-all-you-need-pytorch)

## 总结

- 占坑

## 预训练语言模型

- 占坑

## BERT

- 占坑



# 资料










