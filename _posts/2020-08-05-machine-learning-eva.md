---
layout: post
title:  "机器学习模型评估方法-The-Evaluation-of-Machine Learning"
date:   2020-08-05 14:56:00
categories: 机器学习
tags: 机器学习 AUC PR 混淆矩阵 NCE 评分卡 评价 KL散度 风控 互联网金融 交叉熵
author : 鹤啸九天
excerpt: 机器学习项目开始前的核心问题：如何设置指标，评价模型效果？
mathjax: true
---

* content
{:toc}

# 总结


## 回归MSE/分类CE？

回归、分类的损失函数：
- 回归问题常用mse作为损失函数，隐含的预设是数据误差符合高斯分布。
- 交叉熵则是以数据分布服从多项式分布为前提。

回归问题能用交叉熵吗
- 可以，虽然交叉熵用在回归问题看起来有些越俎代庖，「狗拿耗子多管闲事」，但「黑猫白猫能捉老鼠就是好猫」，搞清楚数据特点、使用场景，loss选择就能更贴合实际，最终的效果才是硬道理。

本质上回归应该**用什么样的损失函数取决于数据分布**。损失函数的选择本身也是一种先验偏好，选择mse意味着你认为数据误差符合高斯分布，选择交叉熵则表示你倾向于认为数据接近多项式分布。如果你的先验直觉比较准确，符合实际情况，那模型效果应该会更好一些。 多项式分布一般和离散数据相关，但如果连续数据分桶后接近多项式分布，那选用mse可能就不合时宜了。

本质上，损失函数的选择是取决于对数据分布的假设，不同的loss形式隐式地有对数据分布的要求，需要仔细分析数据特点进行判断。至于为什么A分布对应甲损失函数，B分布却对应乙损失函数，这也是一个值得展开的话题，简单来说这是最大熵原理约束下的选择。如对于高斯噪音分布，选择mse是满足最大熵要求的，它没有在高斯分布的假设之外增加额外的先验偏好。

[知乎](https://zhuanlan.zhihu.com/p/362496849)


# 分类

- 参考：[深入理解AUC](https://tracholar.github.io/machine-learning/2018/01/26/auc.html)
- 在机器学习的评估指标中，AUC是一个最常见也是最常用的指标之一。
- AUC本身的定义是基于几何的，但是其意义十分重要，应用十分广泛。

## 总结

- auc只能用于binary classifier 评价
- 分类器只需要计算出预测概率分数，不需要自己设置threshold。 一个threshold会算出一个点，一般会自动尝试所有threshold，最后形成一个曲线。以下就不考虑threshold。
- Auc变化其实等价于左上角的面积（绿色部分）变化。 这个面积和两类数据的概率分布的重叠面积成正比 （容易分错类的部分）。 根各数据分布的重叠部分成正比。（这个数据不一定是原始数据，而是通过特征工程和模型高纬投影后的，各类数据分布）好的分类器，把两类分的很开，概率分布重叠小，左上面积小，auc大。最坏的情况是随机，概率分布完全重叠，auc是直线。
- ![](https://pic3.zhimg.com/80/v2-ee0d1b124bae822d1e9bb5784d63e051_720w.jpg)
    - 转自：知乎[xixihaha912](https://www.zhihu.com/question/39840928/answer/342874215)


# 损失函数

## NCE Loss

- 当分类的类别很多时，模型很难训练，而且训练速度很慢，nec_loss可以解决这种问题，在word2vec模型训练过程中，不同的词向量的个数可能有上百万个，这样直接采用softmax分类的方式是不太可行的，nce_loss可以采用随机负采样，相比hierarhical softmax可以大幅度提高性能。

- 参考：知乎[qiao](https://www.zhihu.com/question/50043438/answer/586659546)
- ![](https://pic2.zhimg.com/80/v2-e936075c894a5f9833419944acbfde4b_720w.jpg)


## ROC

- 在试图弄懂AUC和ROC曲线之前，一定要彻底理解混淆矩阵的定义
- 混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下：
    - 称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。
    - 预测正确的为True（真），预测错误的为False（伪）。
- 对上述概念进行组合，就产生了如下的混淆矩阵：
    - ![](https://pic1.zhimg.com/80/v2-a253b01cf7f141b9ad11eefdf3cf58d3_720w.jpg?source=1940ef5c)
- 由此引出True Positive Rate（真阳率）、False Positive（伪阳率）两个概念
    - ![](https://www.zhihu.com/equation?tex=TPRate%3D%5Cfrac%7BTP%7D%7BTP%2BFN%7D)
- 其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下：
    - TPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。
    - FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。
- AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图:
    - ![](https://pic3.zhimg.com/80/v2-41b0ea9ac4ae69eb2b09ccb69d01e083_720w.jpg?source=1940ef5c)
    - 分类器对于正例和负例毫无区分能力，和抛硬币没什么区别——最差情况
    - 认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）
- 希望得到的效果
    - 对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x
    - ![](https://pic2.zhimg.com/80/v2-1dbbadf0c8c8d83aa9b1caafd98758a2_720w.jpg?source=1940ef5c)
- 最理想：既没有真实类别为1而错分为0的样本——TPRate一直为1，也没有真实类别为0而错分为1的样本——FP rate一直为0，AUC为1，这便是AUC的极大值。
    - 摘自：[如何理解机器学习和统计中的AUC？](https://www.zhihu.com/question/39840928/answer/241440370)

## AUC是什么

- 在统计和机器学习中，常常用AUC来评估二分类模型的性能。AUC的全称是 area under the curve，即曲线下的面积。
- 通常这里的曲线指的是[受试者操作曲线(Receiver operating characteristic, ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)。
- 相比于准确率、召回率、F1值等依赖于判决阈值的评估指标，AUC则没有这个问题。

ROC曲线早在第二次世界大战期间就被使用在电子工程和雷达工程当中，被用于军事目标检测。
后来，ROC曲线也被应用到心理学、医学、机器学习和数据挖掘等领域的模型性能评估。

对于二分类问题，预测模型会对每一个样本预测一个得分s或者一个概率p。
然后，可以选取一个阈值t，让得分s>t的样本预测为正，而得分s<t的样本预测为负。
这样一来，根据预测的结果和实际的标签可以把样本分为4类：

|     | 正样本 |  负样本
|-----|--------|--------
|预测为正|  TP(真正例) |  FP(假正例)
|预测为负|  FN(假负例) |  TN(真负例)

随着阈值t选取的不同，这四类样本的比例各不相同。定义真正例率TPR和假正例率FPR为：

$$
\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}} \\
\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}
$$

对于真正例率TPR，分子是得分>t里面正样本的数目，分母是总的正样本数目。
而对于假正例率FPR，分子是得分>t里面负样本的数目，分母是总的负样本数目。
因此，如果定义$N_+(t), N_-(t)$分别为得分大于t的样本中正负样本数目，$N_+, N_-$为总的正负样本数目，
那么TPR和FPR可以表达为阈值t的函数

$$
\text{TPR}(t) = \frac{N_+(t)}{N_+} \\
\text{FPR}(t) = \frac{N_-(t)}{N_-}
$$

随着阈值t的变化，TPR和FPR在坐标图上形成一条曲线，这条曲线就是ROC曲线。
显然，如果模型是随机的，模型得分对正负样本没有区分性，那么得分大于t的样本中，正负样本比例和总体的正负样本比例应该基本一致。
也就是说

$$
\frac{N_+(t)}{N_-(t)} = \frac{N_+}{N_-}
$$

结合上面的式子可知TPR和FPR相等，对应的ROC曲线是一条直线！

反之，如果模型的区分性非常理想，也就是说正负样本的得分可以完全分开，所有的正样本都比负样本得分高，此时ROC曲线表现为「 字形。
因为正例得分都比负例搞，所以要么TPR=0要么FPR=0！

![ROC曲线](/assets/images/ROC_curves.svg)

实际的模型的ROC曲线则是一条上凸的曲线，介于随机和理想的ROC曲线之间。而ROC曲线下的面积，即为AUC！

$$
\text{AUC} = \int_{t=\infty}^{-\infty} y(t) d x(t)
$$

这里的x和y分别对应TPR和FPR，也是ROC曲线的横纵坐标。

## AUC的概率解释

### 概率解释的证明
AUC常常被用来作为模型排序好坏的指标，原因在于AUC可以看做随机从正负样本中选取一对正负样本，其中正样本的得分大于负样本的概率！
这个结论很容易证明，考虑随机取得这对正负样本中，负样本得分在$[t, t+\Delta t]$之间的概率为

$$
\begin{align*}
& P(t \le s_- < t+\Delta t) \\
    = &P( s_- \gt t) - P(s_- > t+\Delta t) \\
    = & \frac{N_-(t)  - N_-(t+\Delta t)}{N_-} \\
    = & x(t) - x(t +\Delta t) =  - \Delta x(t)
\end{align*}
$$

如果$\Delta t$很小，那么该正样本得分大于该负样本的概率为

$$
P(s_+ > s_- | t \le s_- < t+\Delta t) \\
\approx P(s_+ > t) = \frac{N_+(t)}{N_+} = y(t)
$$

所以，

$$
\begin{align*}
 & P(s_+ > s_- )  \\
= & \sum P(t \le s_- < t+\Delta t) P(s_+ > s_- | t \le s_- < t+\Delta t) \\
= & -\sum y(t) \Delta x(t) \\
= & -\int_{t=-\infty}^{\infty} y(t) d x(t) \\
= & \int_{t=\infty}^{-\infty} y(t) d x(t)
\end{align*}
$$

注意积分区间，$t=-\infty$对应ROC图像最右上角的点，而$t=\infty$对应ROC图像最左下角的点。所以，计算面积是$\int_{t=\infty}^{-\infty}$。
可以看出，积分项里面实际上是这样一个事件的概率：**随机取一对正负样本，负样本得分为t且正样本大于t！**
因此，对这个概率微元积分就可以到正样本得分大于负样本的概率！

### AUC的排序特性

根据上述概率解释，AUC实际上在说一个模型把正样本排在负样本前面的概率！
所以，AUC常用在排序场景的模型评估，比如搜索和推荐等场景！
这个解释还表明，如果将所有的样本的得分都加上一个额外的常数，并不改变这个概率，因此AUC不变！
因此，在广告等需要绝对的点击率场景下，AUC并不适合作为评估指标，而是用logloss等指标。

### AUC对正负样本比例不敏感

利用概率解释，还可以得到AUC另外一个性质，对正负样本比例不敏感。
在训练模型的时候，如果正负比例差异比较大，例如正负比例为1:1000，训练模型的时候通常要对负样本进行下采样。当一个模型训练完了之后，用负样本下采样后的测试集计算出来的AUC和未采样的测试集计算的AUC基本一致，或者说前者是后者的无偏估计！
如果采样是随机的，对于给定的正样本，假定得分为$s_+$，那么得分小于$s_+$的负样本比例不会因为采样而改变！
例如，假设采样前负样本里面得分小于$s_+$的样本占比为70%，如果采样是均匀的，即$>s_+$的负样本和$<s_+$的负样本留下的概率是相同的，那么显然采样后这个比例仍然是70%！
这表明，该正样本得分大于选取的负样本的概率不会因为采样而改变，也就是$y(t)dx(t)$是不变的，因此，AUC也不变！

相比于其他评估指标，例如准确率、召回率和F1值，负样本下采样相当于只将一部分真实的负例排除掉了，然而模型并不能准确地识别出这些负例，所以用下采样后的样本来评估会高估准确率；因为采样只对负样本采样，正样本都在，所以采样对召回率并没什么影响。这两者结合起来，最终导致高估F1值！

## AUC的计算

AUC可以直接根据ROC曲线，利用梯形积分进行计算。此外，还有一个比较有意思的是，可以
利用AUC与Wilcoxon-Mann-Whitney测试的U统计量的关系，来计算AUC。这可以从AUC的概率意义推导而来。

假设我们将测试集的正负样本按照模型预测得分 **从小到大** 排序，对于第$j$个正样本，假设它的排序为 $r_j$，
那么说明排在这个正样本前面的总样本有 $r_j - 1$个，其中正样本有 $j-1$个（因为这个正样本在所有的正样本里面排第j），
所以排在第j个正样本前面(得分比它小)的负样本个数为 $r_j - j$个。也就是说，对于第j个正样本来说，其得分比随机取的一个负样本大(排序比它靠后)的概率是 $(r_j - j) / N_-$,其中$N_-$是总的负样本数目。所以，平均下来，随机取的正样本得分比负样本大的概率为

$$
\frac{1}{N_+} \sum_{j=1}^{N_+}(r_j - j)/N_- = \frac{\sum_{j=1}^{N_+}r_j - N_+(N_+ + 1)/2}{N_+N_-}
$$


所以

$$
AUC = \frac{\sum_{j =1}^{N_+} r_j - N_+(N_+ + 1)/2}{N_+ N_-}
$$

因此，很容易写出计算AUC的SQL代码

```sql
select
	(ry - 0.5*n1*(n1+1))/n0/n1 as auc
from(
	select
		sum(if(y=0, 1, 0)) as n0,
		sum(if(y=1, 1, 0)) as n1,
		sum(if(y=1, r, 0)) as ry
	from(
		select y, row_number() over(order by score asc) as r
		from(
			select y, score
			from some.table
		)A
	)B
)C
```

## AUC的优化

采用极大似然估计对应的损失函数是logloss，因此极大似然估计的优化目标并不是AUC。
在一些排序场景下，AUC比logloss更贴近目标，因此直接优化AUC可以达到比极大似然估计更好的效果。
实际上，pairwise的目标函数就可以看做一种对AUC的近似。因为损失函数都是作用与正负样本得分差之上！
例如，

|类型|公式|
-----------|--------------------------------------
|rank-SVM   | $\max(0, - s_+ + s_- + \Delta)$ |
|rank-net   | $\log (1 + \exp(- (s_+ - s_-)))$|
|指数损失    |  $\exp(- (s_+ - s_-))$|
|TOP 损失   |  $\sum_s \max(0, - s_c + s + \Delta)$|

显然，这些损失函数都是对$$s_+<s_-$$的正负样本对进行惩罚！
此外，也有一些其它对AUC近似度更好的损失函数，例如

$$
\mathbf{E} \left[ (1-w^T(s_+ - s_-))^2 \right] = \frac{1}{n_+n_-} \sum_{i=1}^{n_+} \sum_{j=1}^{n_-}  (1-w^T(s_{i}^+ - s_{j}^-))^2
$$

$s_i^+, s_j^-$分别表示正例和负例的得分。
这解释了为什么某些问题中，利用排序损失函数比logloss效果更好，**因为在这些问题中排序比概率更重要**！

## AUC要到多少才算好的模型
AUC越大表示模型区分正例和负例的能力越强，那么AUC要达到多少才表示模型拟合的比较好呢？在实际建模中发现，预测点击的模型比预测下单的模型AUC要低很多，在月活用户里面预测下单和日活用户里面预测下单的AUC差异也很明显，预测用户未来1小时下单和预测未来1天的下单模型AUC差异也很大。这表明，AUC非常依赖于具体任务。

以预测点击和预测下单为例，下单通常决策成本比点击高很多，这使得点击行为比下单显得更加随意，也更加难以预测，所以导致点击率模型的AUC通常比下单率模型低很多。

那么月活用户和日活用户那个更容易区分下单与不下单用户呢？显然月活用户要容易一些，因为里面包含很多最近不活跃的用户，所以前者的AUC通常要高一些。

对于预测1小时和预测1天的模型，哪一个更加困难？因为时间越长，用户可能发生的意料之外的事情越多，也越难预测。举个极端的例子，预测用户下一秒中内会干啥，直接预测他会做正在干的事情即可，这个模型的准确率就会很高，但是预测长期会干啥就很困难了。所以对于这两个模型，后者更加困难，所以AUC也越低。



# 回归

- 待定


# 评分

- KDD的2019年会上，俄罗斯联邦储蓄银行（Sberbank）发布的论文《[E.T.-RNN: Applying Deep Learning to Credit Loan Applications](https://www.kdd.org/kdd2019/accepted-papers/view/e.t.-rnn-applying-deep-learning-to-credit-loan-applications)》，这是一篇将深度学习应用于风控领域的一个不错的探索
  - 传统**评分卡**方法: 信用评分是银行业务基础指标，经典的信用评分方法基于用户的申请单信息，用户的信用历史和其他关联的金融信息。传统的评分卡多采用经典的机器学习算法比如逻辑回归，GBDT，LighgtGBM等算法预测用户的贷后表现。
  - 尽管经典机器学习算法广泛应用且效果不错，但有以下不足：
    - 需要大量的特征工程工作和行业领域知识
    - 对于白户（无信用历史）的用户，很难给定评分
    - 传统算法模型没有充分利用用户数据
  - 论文提出了一种基于深度学习的评分卡算法，该方法基于到户交易数据利用RNN模型预测申请贷款用户的信用分。算法名称**ETRNN**全称Embedding Transactional Recurrent Neural Network，主要是利用用户的借记卡和信用卡的交易数据，只要用户有信用卡或者借记卡，就可以利用该方法。与传统的信用评分方法相比，ETRNN算法有以下有点：
    - 首先该方法效果超过了传统的方法。
    - 该方法基于用户的交易数据，不需要大量的特征工程方法和领域知识。
    - 该方法并部需要申请人除交易数据之外的其他数据，这意味着可以快速授信，改善用户体验。
    - 用户交易数据很难仿造。
    - 即使白户也可以利用交易数据评分。
  - 传统的评分卡方法，往往是对用户的交易流水历史做一些聚合，得到一些特征；而深度学习方法直接利用用户的交易流水数据，更好的利用用户消费的时序信息。

## 评分效果评估

专家训练场的评估分为三段：房源自述、小贝问答、推荐房源。最终的评分结果根据上述三个部分加权得到，现阶段没有完整数据可以标注，需要对各个阶段先进行评估，确保各阶段的评估合理。其中，推荐房源可以根据经纪人推荐的房源和系统候选房源进行对比，这个指标不需要评估，另外两个指标涉及意图识别及加权策略，需要进行评估。

评估使用基于pair-wise的方式，通过分析对比结果与评分之间的关系得出评估是否合理：
- 如果相对好的数据评分相对高，则评价合理
- 如果相对好的数据评分相对低，则评价不合理

文本为VR带看经纪人训练场中经纪人的文本，标注目标为标注文本A相对于文本B的好坏程度，数字的含义如下：
- -2（很差），-1（较差），0（差不多），1（较好），2（很好）

标注的数据有两个部分：
- （1）房源自述，对应的title为narrate，比较的时候参考以下标准：
  - 基础素质（讲解房源、小区、配套等）
- （2）小贝问答，对应的title为show，比较的时候参考以下标准：
  - 服务态度（标注开场白、结束语等）
  - 需求理解与挖掘（理解客户需求，挖掘客户需求，比如购房意愿、金额等）

评分结果的验证分为以下几个方面：
- （1）分数**分布**验证，检验是否为正态分布。如VR带看里，房源自述+小贝问答两种语料，检查概率分布
- （2）**一致性**检验，即**定性**检验，检查标注的好坏是否与分差保持一致
  - 例如：文本A相对于文本B是1，文本A的分数是90，文本B是80，因为90 > 80，所以这条数据是通过一致性检验的。
  - 房源自述和小贝问答的一致率均大于 90%，说明一致率很高，简单理解评分的好坏准确率为90%以上。
- （3）**分值**检验，即**定量**检验，检查标注的好坏程度是否与分差保持正比关系
  - 如果标注结果与**分差**正相关，那么打分的结果是比较合理的。
  - 例如：标注结果为文本A1相对于文本B1是1，实际分差为10分，标注结果为文本A2相对于文本B2是2，实际分差为20分，标注结果与分差是正相关的，说明评分的分数合理。

- [参考](https://wiki.lianjia.com/pages/viewpage.action?pageId=711844107)


## 评分卡模型

- 【2021-3-21】[深入浅出评分卡的逻辑回归原理](https://zhuanlan.zhihu.com/p/104599677)
- 信贷评分卡的建模过程中，使用最多的算法就是逻辑回归（logistics regression）函数。下面，我们将围绕下面几点详细地讲述逻辑回归的数学来源和业务用途：
  - 什么是逻辑回归函数?
    - ![](https://pic1.zhimg.com/80/v2-036cc92debe28b75c8d4f5d093a9a8e0_1440w.jpg)
  - 为什么评分卡要使用逻辑回归函数？
  - 经济意义下逻辑回归函数的由来？（从金融角度揭示）
  - 怎么产生标准评分卡？（评分卡分数的线性转换）
    - 模型最终的产出还得是分数，上述的 s(x) 为对数比率分数，想要转化为千分制的分数还必须进行分数线性转化：![](https://www.zhihu.com/equation?tex=S_%7Bscale%7D%3Da%2Bb%2AS_%7BlogOdds%7D)
    - 以下2个假设用于定义分数刻度：
      - log 比率为 1:1的时候，分数为500分；![](https://www.zhihu.com/equation?tex=500%3Da%2Bb%2Aln%281%29)
      - 好坏比（odds)每增加一倍，分数增加20分。![](https://www.zhihu.com/equation?tex=520%3Da%2Bb%2Aln%282%29)
    - 解出![](https://www.zhihu.com/equation?tex=a%3D500%2Cb%3D20%2Fln2)，所以![](https://www.zhihu.com/equation?tex=S_%7Bscale%7D%3D500%2B%2820%2Fln2%29%2AS_%7BlogOdds%7D)![](https://www.zhihu.com/equation?tex=%5CRightarrow+S_%7Bscale%7D%3D500%2B%2820%2Fln2%29%2A%28a%2B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bw%28x_%7Bi%7D%29%7D%29%3D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%5Cfrac%7B500%7D%7Bn%7D%2B%5Cfrac%7B20%7D%7Bln2%7Dw%28x_%7Bi%7D%29%7D)
    - 分数输出: 经过特征筛选、证据权重的计算、系数的回归，对每个特征分组都计算出一个分数，得出如下标准评分卡格式
  - 逻辑回归-标准评分卡的实操。
- 银行决定是否给个人或企业贷款的关键因素是对未来违约概率的预测，逻辑回归函数能提供此技术支持。假设某银行挑选了 n 个特征进入评分卡给客户进行准入评分，且这 n 个特征包含了能判断客户是好还是坏的充分信息![](https://www.zhihu.com/equation?tex=X%3D%28x_%7B1%7D%2Cx_%7B2%7D%2C...%2Cx_%7Bn%7D%29)，若是想预测某个客户在将来违约的概率，那么只需要收集该客户的n个特征信息，代入公式![](https://www.zhihu.com/equation?tex=p%28z%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D)，就得到一个介于(0,1)之间的值，称为好客户的概率。
- 在逻辑回归函数的作用下，可以将客户的特征信息（如婚姻、年龄、历史以往信贷表现等）综合起来并转化为一个概率值，该值给银行预测客户好坏提供了一个直观依据。即 p(z) 值越大，证明该客户在将来违约的概率越小。


## 基本流程

- （1）是否有label，如果有，需要先做特征分析，剔除无关特征
  - 正式建模之前，一般会对特征工程挖掘到的特征集进行筛选，以选择相关性高、稳定性强的特征，作为入模变量。
  - 常用特征筛选一般会考虑如下几方面：
    - 1）特征**覆盖率**(cover rate)，选取覆盖率达到一定阈值的特征；
    - 2）特征**相关性**：如根据特征本身的KS值、IV或卡方值，选择与建模label相关性高的特征；
    - 3）特征**稳定性**：比如通过衡量特征的PSI，选择随时间波动性尽可能小的特征。
    - 此外，还可以通过VIF、相关性系数等指标，排除特征之间的共线性。
- （2）特征重要度数值+专家经验，制定组合方式，得到初步分数
- （3）全局分布调整，转换到正太分布N（u，σ），u＜及格线，保证分数具备区分度
- （4）打分反馈闭环，根据用户反馈，补充到label中，回到（1）

无监督评分卡也有些方法，如基于专家经验的层次分析法，熵权法等


## 评分卡建模

- [机器学习在信用评分卡中的应用](https://zhuanlan.zhihu.com/p/49818814)
- 特征和样本标签准备好后，评分卡建模的过程则比较自然。虽然深度学习等技术在互联网领域已大行其道，在信用评分卡建模中，逻辑回归或GBDT等仍然是目前主流的建模算法。一方面是金融领域对特征的可解释性要求会更高，通过LR或GBDT建模，比较容易直观得到每个特征在模型结果中的权重，并根据业务经验解释权重系数的合理性。另一方面，实际评分卡建模中，一般入模特征维度并不高。在低维度建模中，LR和GBDT已经可以取得比较可观的效果。


## 模型评估

- 模型建立后，需要对模型的预测能力、稳定性进行评估。信用评分模型常用的评估指标为KS、AUC等。 考虑到金融业务反馈周期长的特点，除了划分训练集、测试集外，通常会预留一段训练样本时间段之外的数据集，作为OOT（跨时间）集合，以测量模型在时间上的稳定性。
- 评分分布图的区分度
  - 如果通过评分能将**好坏用户完全区隔**开来，那是理想中最好的评分卡模型，但实际情况中好坏用户的评分会有一定程度的重叠，我们要做的就是尽量减小重叠程度。
  - 好坏用户的得分分布最好都是**正态分布**，如果呈双峰或多峰分布，那么很有可能是某个变量的得分过高导致，这样对评分卡的稳定性会有影响。
  - ![](https://pic1.zhimg.com/80/v2-4819c26a5036036ce54e9f602327b564_1440w.jpg)
  - 摘自：[评分卡模型的评估方法论](https://zhuanlan.zhihu.com/p/56738542), [github 代码](https://github.com/taenggu0309/Scorecard--Assessment)
- [一文读懂评分卡的IV、KS、AUC、GINI指标](https://zhuanlan.zhihu.com/p/119282743)
- 当一张评分卡构建完成时，筛选出一组特征生成了分数，我们会想要知道这个分数是否靠谱，即是否可以依赖这个分数将好坏客户区分开来，这个时候就需要评判评分卡有效性的指标。
- 测量评分卡好坏区分能力的指标有许多，本文就为大家介绍几个常用的定量指标：
  - ① **散度**（分数为连续函数）与**信息比率**（IV);
  - ② **KS值**
  - ③ ROC曲线、AUROC值与GINI系数。

### 散度与信息比率

- 散度为信息比率的连续版本。而评分卡分数是基于有限样本计算出的分数分布，并不一定是完全连续函数，所以就衍生出了离散版本的散度----信息比率IV。
- 在实际应用当中，IV值通常用来筛选变量，IV值越大，该变量的好坏区分能力越强。在评分卡建模的过程中，利用IV值筛选变量也是非常重要的一个环节。
- 从IV值的公式中，易得变量的分组越多，IV值越大。但是分组分的太多，就会使得每个分组的数据量变少，导致细项分组的分布不稳定。所以，我们在使用IV值筛选变量的时候，不能为了提高IV值一味地将分箱的数目提高，也要兼顾变量的业务含义和分布的稳定性。

### KS值

- KS值是一个衡量好坏客户分数距离的上限值，具体做法为将对于各个分数区间对应的好坏客户累计占比进行相减，取最大值。
- ![](https://pic2.zhimg.com/80/v2-d1afba6dc7f1d022a722d3c55d4f23a9_1440w.jpg)
  - 为什么F(s\|B)为凹函数、F(s\|G)为凸函数？
  - 为什么F(s\|B)-F(s\|G)存在极大值（最大值）？
  - 为什么F(s\|B)曲线在F(s\|G)曲线之上？
- ![](https://pic1.zhimg.com/80/v2-4c73cebb1eb9cf2497993b98e10042f8_1440w.jpg)



### ROC曲线与AUROC值

- ROC曲线也是评分卡度量指标中常用的指标工具，在介绍KS统计量的时候，其分布函数是由好客户和坏客户对应的累计概率密度函数F(s|B)与F(s|G)随着分数s变化的图形，而ROC曲线是好客户的累计概率密度相对于坏客户的累计概率密度函数的图形
  - ![](https://pic4.zhimg.com/80/v2-1e5953e490b27a7f1f225b83850a6f4f_1440w.jpg)
- 根据上文的分析，得出越接近B点的曲线，好坏客户的区分能力越强，这个时候，ROC曲线与X轴围成的面积就越大。由此，衍生出ROC曲线关于X轴面积的指标AUROC（Area under the ROC curve)。

### GINI曲线

- AUROC值是ROC曲线和X轴的面积，GINI系数定义为ROC曲线和对角线AC之间的面积占对角线AC曲线围成面积比，即 ![](https://pic1.zhimg.com/80/v2-b808e5dc8bbb7400944eac704d797bd8_1440w.jpg) 。
  - 如果该评分系统异常完美，AUC曲线过点B(0,1)，这个时候GINI=1；
  - 如果评分卡毫无区分度，那么AUC曲线即为AC曲线，这时GINI=0;
- 所以，GINI系数是一个介于(0,1)之间的函数，该值越大，模型的区分能力越强。


## 金融风控

- 互联网金融，特别是P2P信贷在过去几年可以说经历了大起大落的过山车。在经历了2016、2017年的高速发展后，随着整体经济环境遇冷、政策层面监管趋严，行业已进入洗牌周期。特别是随着18年7月P2P暴雷潮的出现，更是为行业前途蒙上一层迷雾。
- 一个典型的风控体系，包含了贷前、贷中和贷后三个阶段，每个阶段都有相应的研究问题。
- （1）**贷前**主要解决用户准入和风险定价问题，即面对一个新申请的进件用户，判断用户是否符合产品的放款条件及相应的放款额度、价格、期限等问题。主要包括三类问题：
    - 1）反欺诈识别：根据用户提交的材料进行身份核实，确保用户不存在欺诈行为；
    - 2）信用评级：与传统银行的信用评分卡原理一致，综合用户的社交数据、行为数据、收入数据等，判定用户的信用风险等级，评估用户的履约能力；
    - 3）风险定价：根据用户的负债能力和收入稳定性，判断用户可承担的月供金额，确定用户的放款额度、偿还期限等，并根据用户风险等级确定用户的费率。这三个问题往往是互相影响、互为前提的。比如，对一个月收入3000的用户来说，月供在1000左右，用户可能履约良好，信用等级良好；但如果月供提高到4000，严重超出了其收入水平，即便不是有意欺诈，也可能出现断供的情况，从而得到比较差的信用等级。
- （2）**贷中**一般是针对已放款用户展开。主要研究问题包括：
    - 1）还款风险监控：比如用户会否因失业、过度举债、家庭突发状况等一些突发原因导致还款能力降低，出现逾期风险；
    - 2）贷中风险的政策制定：当用户出现逾期风险时，如何根据用户风险原因制定相应的策略，减少机构损失。如为经济暂时困难的用户主动延长还款期限、减少月供，甚至提供延期还款服务；
    - 3）用户复贷：对履约良好，且收入水平明显改善的用户，提供增信服务，以满足其更高水平的消费信贷需求；或在其授信额度范围内，提供循环信贷服务。
- （3）**贷后**一般是针对逾期用户展开。由于用户已经出现逾期，贷后风控的目标是如何刺激用户还款减少损失。主要研究问题包括：
    - 1）催收评分卡：将用户按照催收难度划分等级，并制定相应的催收策略。如对偶然逾期、出现暂时性困难的用户，主动沟通帮助其度过眼前困难，一方面减少了机构损失，另一方面也有助于与用户建立长远的信任关系；而对严重逾期的用户，可能需要让更有催收经验的人员介入沟通，甚至采取必要的法律途径；
    - 2）催收策略制定：由于互联网金融主要进行电话催收，而用户提供的通话记录或联系人往往内容复杂且包含大量噪音，如何从中准确找出联系紧密的电话，提升催收效率；
    - 3）失联修复：对已经失联用户，如何触达，进行用户找回；
- 其中，贷前反欺诈评分卡一般称为F卡；信用评分卡一般称为A卡；贷中评分卡称为B卡；贷后催收评分卡称为C卡。
- A卡的建模过程
  - ![](https://pic4.zhimg.com/80/v2-75f98569de6b6bbfb00d3624a49c2207_1440w.jpg)

## 实战

- [Python实现的半自动评分](https://zhuanlan.zhihu.com/p/92916332)，[github地址](https://github.com/taenggu0309/Semi-auto-modeling)，整个脚本的大概流程是：
  - PSI预筛选 --> 特征分箱 --> IV筛选特征 --> 相关性/多重共线性筛选 --> woe单调调整 -- > 显著性筛选 --> 系数一致筛选 --> 建模 --> 模型评估 --> 标准评分转换



# 结束
















