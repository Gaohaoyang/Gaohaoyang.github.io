---
layout: post
title:  "搜索引擎-Search-Engine"
date:   2021-07-20 21:05:00
categories: 技术工具
tags: 搜索 索引 正排 倒排 pagerank 谷歌 Google 百度
excerpt: 搜索引擎技术汇总
author: 鹤啸九天
mathjax: true
---

* content
{:toc}

# 总结

- 待定

# 搜索引擎简介

[搜索引擎技术之概要预览](https://blog.csdn.net/v_july_v/article/details/6827391)

从最基本的搜索引擎的概念谈起，到全文检索的概念，由网络蜘蛛，分词技术，系统架构，排序的讲解（结合google搜索引擎的技术原理），而后到图片搜索的原理，最后是几个开源搜索引擎软件的介绍。

## 什么是搜索引擎

搜索引擎指自动从因特网搜集信息，经过一定整理以后，提供给用户进行查询的系统。因特网上的信息浩瀚万千，而且毫无秩序，所有的信息像汪洋上的一个个小岛，网页链接是这些小岛之间纵横交错的桥梁，而搜索引擎，则为用户绘制一幅一目了然的信息地图，供用户随时查阅。

![](http://hi.csdn.net/attachment/201109/28/0_1317169776VVsR.gif)

工作原理以最简单的语言描述，即是：
- **搜集**信息：首先通过一个称为网络蜘蛛的机器人程序来追踪互联网上每一个网页的超链接，由于互联网上每一个网页都不是单独存在的（必存在到其它网页的链接），然后这个机器人程序便由原始网页链接到其它网页，一链十，十链百，至此，网络蜘蛛便爬满了绝大多数网页。
- **整理**信息：搜索引擎整理信息的过程称为“创建索引”。搜索引擎不仅要保存搜集起来的信息，还要将它们按照一定的规则进行编排。这样，搜索引擎根本不用重新翻查它所有保存的信息而迅速找到所要的资料。
- 接受**查询**：用户向搜索引擎发出查询，搜索引擎接受查询并向用户返回资料。搜索引擎每时每刻都要接到来自大量用户的几乎是同时发出的查询，它按照每个用户的要求检查自己的索引，在极短时间内找到用户需要的资料，并返回给用户。

## 网络蜘蛛
    
网络蜘蛛即Web Spider，是一个很形象的名字。把互联网比喻成一个蜘蛛网，那么Spider就是在网上爬来爬去的蜘蛛。网络蜘蛛是通过网页的链接地址来寻找网页，从网站某一个页面（通常是首页）开始，读取网页的内容，找到在网页中的其它链接地址，然后通过这些链接地址寻找下一个网页，这样一直循环下去，直到把这个网站所有的网页都抓取完为止。如果把整个互联网当成一个网站，那么网络蜘蛛就可以用这个原理把互联网上所有的网页都抓取下来。

在抓取网页的时候，网络蜘蛛一般有两种策略：广度优先和深度优先（如下图所示）。广度优先是指网络蜘蛛会先抓取起始网页中链接的所有网页，然后再选择其中的一个链接网页，继续抓取在此网页中链接的所有网页。这是最常用的方式，因为这个方法可以让网络蜘蛛并行处理，提高其抓取速度。深度优先是指网络蜘蛛会从起始页开始，一个链接一个链接跟踪下去，处理完这条线路之后再转入下一个起始页，继续跟踪链接。这个方法有个优点是网络蜘蛛在设计的时候比较容易。至于两种策略的区别，下图的说明会更加明确。

![](http://hi.csdn.net/attachment/201109/27/0_1317124906YudU.gif)

由于不可能抓取所有的网页，有些网络蜘蛛对一些不太重要的网站，设置了访问的层数。例如，在上图中，A为起始网页，属于0层，B、C、D、E、F属于第1层，G、H属于第2层，I属于第3层。如果网络蜘蛛设置的访问层数为2的话，网页I是不会被访问到的。这也让有些网站上一部分网页能够在搜索引擎上搜索到，另外一部分不能被搜索到。 对于网站设计者来说，扁平化的网站结构设计有助于搜索引擎抓取其更多的网页。



## 网页排序 Page Rank

到2004年为止，Google（ http://www.google.com ）已经连续两年被评为全球第一品牌，Google成立仅五年时间，最初只是两个斯坦福大学学生的研究项目。这不能不说是一个奇迹，就像比尔?盖茨创制奇迹一样。比尔?盖茨能创造奇迹，是因为他看准了个人计算机软件市场的趋势，所以创建的公司叫Microsoft（微软）：Micro（小）Soft（软件）。那么Google呢？在Google出来之前已经有一些很有成就的搜索引擎公司，其实力也很强，看来不只是Google看见了搜索的趋势。Google究竟成功的秘密在哪儿？

Google的成功有许多因素，最重要的是Google对搜索结果的排序比其它搜索引擎都要好。Google保证让绝大部分用搜索的人，都能在搜索结果的第一页找到他想要的结果。客户得到了满足，下一次还过来，而且会向其他人介绍，这一来一往，使用的人就多了。所以Google在没有做任何广告的前提下，让自己成为了全球最大的品牌。Google究竟采用了哪种排序技术？PageRank，即网页级别。

Google有一个创始人叫Larry Page，据说PageRank的专利是他申请的，于是依据他的名字就有了Page Rank。国内也有一家很成功的搜索引擎公司，叫百度（ http://www.baidu.com ）。百度的创始人李彦宏说，早在1996年他就申请了名为超链分析的专利，PageRank的原理和超链分析的原理是一样的，而且PageRank目前还在Paten-pending（专利申请中）。言下之意是这里面存在专利所有权的问题。这里不讨论专利所有权，只是从中可看出，成功搜索引擎的排序技术，就其原理上来说都差不多，那就是链接分析。超链分析和PageRank都属于链接分析。

PageRank的原理类似于科技论文中的引用机制：**谁的论文被引用次数多，谁就是权威**。说的更白话一点：张三在谈话中提到了张曼玉，李四在谈话中也提到张曼玉，王五在谈话中还提到张曼玉，这就说明张曼玉一定是很有名的人。在互联网上，链接就相当于“引用”，在B网页中链接了A，相当于B在谈话时提到了A，如果在C、D、E、F中都链接了A，那么说明A网页是最重要的，A网页的PageRank值也就最高。

计算PageRank值有一个简单的公式
- ![](http://hi.csdn.net/attachment/201109/27/0_1317127645254s.gif)
- 系数为一个大于0，小于1的数。一般设置为0.85。网页1、网页2至网页N表示所有链接指向A的网页。
可以看出：
- 链接指向A的网页越多，A的级别越高。即A的级别和指向A的网页个数成正比，在公式中表示，N越大， A的级别越高；
- 链接指向A的网页，其网页级别越高， A的级别也越高。即A的级别和指向A的网页自己的网页级别成正比，在公式中表示，网页N级别越高， A的级别也越高；
- 链接指向A的网页，其链出的个数越多，A的级别越低。即A的级别和指向A的网页自己的网页链出个数成反比，在公式中现实，网页N链出个数越多，A的级别越低。

每个网页有一个PageRank值，这样形成一个巨大的方程组，对这个方程组求解，就能得到每个网页的PageRank值。互联网上有上百亿个网页，那么这个方程组就有上百亿个未知数，这个方程虽然是有解，但计算毕竟太复杂了，不可能把这所有的页面放在一起去求解的。



# 相关功能


## 输入提示

- [github](https://github.com/wklken/suggestion)

![](https://raw.githubusercontent.com/wklken/gallery/master/suggestion/suggestion.gif)

```python
git clone https://github.com/wklken/suggestion.git
cd suggestion/easymap
python suggest.py
```

## 自动纠错

- 待补充

## 图片搜索

阮一峰介绍了一个简单的图片搜索原理，可分为下面几步：
- 缩小尺寸。将图片缩小到8x8的尺寸，总共64个像素。这一步的作用是去除图片的细节，只保留结构、明暗等基本信息，摒弃不同尺寸、比例带来的图片差异。
- 简化色彩。将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。
- 计算平均值。计算所有64个像素的灰度平均值。
- 比较像素的灰度。将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。
- 计算哈希值。将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。

这种方法对于寻找一模一样的图片是有效的，但并不能够去搜索“相似”的照片，也不能局部搜索，比如从一个人的单人照找到这个人与别人的合影。这些Google Images都能做到。

其实早在2008年，Google公布了一篇图片搜索的论文（PDF版），和文本搜索的思路是一样的：
- 对于每张图片，抽取其特征。这和文本搜索对于网页进行分词类似。
- 对于两张图片，其相关性定义为其特征的相似度。这和文本搜索里的文本相关性也是差不多的。
- 图片一样有image rank。文本搜索中的page rank依靠文本之间的超链接。图片之间并不存在这样的超链接，image rank主要依靠图片之间的相似性（两张图片相似，便认为它们之间存在超链接）。具有更多相似图片的图片，其image rank更高一些。

# 开源搜索引擎
 
## 全文检索引擎 Sphinx
 
不知是否还记得曾经出现在这篇文章从几幅架构图中偷得半点海量数据处理经验中的两幅图，如下所示：
- [gif](http://hi.csdn.net/attachment/201108/15/0_1313408597ZuQQ.gif) ![](http://hi.csdn.net/attachment/201108/15/0_1313408597ZuQQ.gif)

上图出自俄罗斯的开源全文搜索引擎软件Sphinx，单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒。
 
基于以上几点，一网友 回忆未来-张宴设计出了这套搜索引擎架构。在生产环境运行了一周，效果非常不错。有时间我会专为配合Sphinx搜索引擎，开发一个逻辑简单、速度快、占用内存低、非表锁的MySQL存储引擎插件，用来代替MyISAM引擎，以解决MyISAM存储引擎在频繁更新操作时的锁表延迟问题。另外，分布式搜索技术上已无任何题。
 
[gif](http://hi.csdn.net/attachment/201108/15/0_13134093364uuG.gif) ![](http://hi.csdn.net/attachment/201108/15/0_13134093364uuG.gif)

Sphinx是一个基于SQL的全文检索引擎，可以结合MySQL,PostgreSQL做全文搜索，它可以提供比数据库本身更专业的搜索功能，使得应用程序更容易实现专业化的全文检索。Sphinx特别为一些脚本语言设计搜索API接口，如PHP,Python,Perl,Ruby等，同时为MySQL也设计了一个存储引擎插件。
 
## C++检索引擎 Xapian
 
Xapian 是一个用C++编写的全文检索程序，他的作用类似于Java的lucene。尽管在Java世界lucene已经是标准的全文检索程序，但是C/C++世界并没有相应的工具，而 Xapian 则填补了这个缺憾。 
 
Xapian 的api和检索原理和lucene在很多方面都很相似，但是也有一些地方存在不同，具体请看 Xapian 自己的文档:http://www. xapian .org/docs/ 
 
Xapian 除了提供原生的C++编程接口之外，还提供了Perl，PHP，Python和Ruby编程接口和相应的类库，所以你可以直接从自己喜欢的脚本编程语言当中使用 Xapian 进行全文检索了。

[xunsearch github](https://github.com/hightman/xunsearch)
 
## Java搜索引擎 Lucene
 
Lucene是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单确强大的应用程式接口，能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放源代码工具;就其本身而论，Lucene是现在并且是这几年，最受欢迎的免费java资讯检索程式库。人们经常提到资讯检索程式库，就像是搜寻引擎，但是不应该将资讯检索程式库与网搜索引擎相混淆。

Lucene最初是由Doug Cutting所撰写的，是一位资深全文索引/检索专家，曾经是V-Twin搜索引擎的主要开发者，后来在Excite担任高级系统架构设计师，目前从事 于一些INTERNET底层架构的研究。他贡献出Lucene的目标是为各种中小型应用程式加入全文检索功能。
 
  
 
## C++搜索引擎 CLucene
 
CLucene是Lucene的一个C++端口，Lucene即是上面所讲到的一个基于java的高性能的全文搜索引擎。CLucene因为使用C++编写，所以理论上要比lucene快。
 
## 搜索引擎 Nutch
 
Nutch 是一个开源Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具。包括全文搜索和Web爬虫。
 
  
 
尽管Web搜索是漫游Internet的基本要求, 但是现有web搜索引擎的数目却在下降. 并且这很有可能进一步演变成为一个公司垄断了几乎所有的web搜索为其谋取商业利益.这显然 不利于广大Internet用户.
 
  
Nutch为我们提供了这样一个不同的选择. 相对于那些商用的搜索引擎, Nutch作为开放源代码 搜索引擎将会更加透明, 从而更值得大家信赖. 现在所有主要的搜索引擎都采用私有的排序算法, 而不会解释为什么一个网页会排在一个特定的位置. 除此之外, 有的搜索引擎依照网站所付的 费用, 而不是根据它们本身的价值进行排序. 与它们不同, Nucth没有什么需要隐瞒, 也没有 动机去扭曲搜索的结果. Nutch将尽自己最大的努力为用户提供最好的搜索结果.
 
  
Nutch 致力于让每个人能很容易, 同时花费很少就可以配置世界一流的Web搜索引擎. 为了完成这一宏伟的目标, Nutch必须能够做到:
- 每个月取几十亿网页
- 为这些网页维护一个索引
- 对索引文件进行每秒上千次的搜索
- 提供高质量的搜索结果
- 以最小的成本运作




# 结束


